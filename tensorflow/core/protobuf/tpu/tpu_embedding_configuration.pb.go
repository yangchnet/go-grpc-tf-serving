// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.28.1
// 	protoc        (unknown)
// source: tensorflow/core/protobuf/tpu/tpu_embedding_configuration.proto

package tpu

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// Mode. Should the embedding layer program be run for inference (just forward
// pass), training (both forward and backward pass) or just the backward_pass.
type TPUEmbeddingConfiguration_Mode int32

const (
	TPUEmbeddingConfiguration_UNSPECIFIED        TPUEmbeddingConfiguration_Mode = 0
	TPUEmbeddingConfiguration_INFERENCE          TPUEmbeddingConfiguration_Mode = 1
	TPUEmbeddingConfiguration_TRAINING           TPUEmbeddingConfiguration_Mode = 2
	TPUEmbeddingConfiguration_BACKWARD_PASS_ONLY TPUEmbeddingConfiguration_Mode = 3
)

// Enum value maps for TPUEmbeddingConfiguration_Mode.
var (
	TPUEmbeddingConfiguration_Mode_name = map[int32]string{
		0: "UNSPECIFIED",
		1: "INFERENCE",
		2: "TRAINING",
		3: "BACKWARD_PASS_ONLY",
	}
	TPUEmbeddingConfiguration_Mode_value = map[string]int32{
		"UNSPECIFIED":        0,
		"INFERENCE":          1,
		"TRAINING":           2,
		"BACKWARD_PASS_ONLY": 3,
	}
)

func (x TPUEmbeddingConfiguration_Mode) Enum() *TPUEmbeddingConfiguration_Mode {
	p := new(TPUEmbeddingConfiguration_Mode)
	*p = x
	return p
}

func (x TPUEmbeddingConfiguration_Mode) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (TPUEmbeddingConfiguration_Mode) Descriptor() protoreflect.EnumDescriptor {
	return file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_enumTypes[0].Descriptor()
}

func (TPUEmbeddingConfiguration_Mode) Type() protoreflect.EnumType {
	return &file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_enumTypes[0]
}

func (x TPUEmbeddingConfiguration_Mode) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use TPUEmbeddingConfiguration_Mode.Descriptor instead.
func (TPUEmbeddingConfiguration_Mode) EnumDescriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_rawDescGZIP(), []int{0, 0}
}

// Sharding strategy of the embedding tables among the hosts.
// If the sharding_strategy is "mod", each id is assigned to host
// "id % num_hosts". For instance, 13 ids are split across 5 hosts as:
// [[0, 5, 10], [1, 6, 11], [2, 7, 12], [3, 8], [4, 9]].
// If the sharding_strategy is "div", ids are assigned to hosts in a
// contiguous manner. In this case, 13 ids are split across 5 hosts as:
// [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12]].
// In both the strategies, if the id space does not evenly divide the number
// of hosts, each of the first "table_descriptor.vocabulary_size % num_hosts"
// hosts will be assigned one more id.
// This partitioning strategy exactly follows that in the embedding_lookup
// TensorFlow function at tensorflow/python/ops/embedding_ops.py.
type TPUEmbeddingConfiguration_ShardingStrategy int32

const (
	TPUEmbeddingConfiguration_DIV_DEFAULT TPUEmbeddingConfiguration_ShardingStrategy = 0
	TPUEmbeddingConfiguration_MOD         TPUEmbeddingConfiguration_ShardingStrategy = 1
)

// Enum value maps for TPUEmbeddingConfiguration_ShardingStrategy.
var (
	TPUEmbeddingConfiguration_ShardingStrategy_name = map[int32]string{
		0: "DIV_DEFAULT",
		1: "MOD",
	}
	TPUEmbeddingConfiguration_ShardingStrategy_value = map[string]int32{
		"DIV_DEFAULT": 0,
		"MOD":         1,
	}
)

func (x TPUEmbeddingConfiguration_ShardingStrategy) Enum() *TPUEmbeddingConfiguration_ShardingStrategy {
	p := new(TPUEmbeddingConfiguration_ShardingStrategy)
	*p = x
	return p
}

func (x TPUEmbeddingConfiguration_ShardingStrategy) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (TPUEmbeddingConfiguration_ShardingStrategy) Descriptor() protoreflect.EnumDescriptor {
	return file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_enumTypes[1].Descriptor()
}

func (TPUEmbeddingConfiguration_ShardingStrategy) Type() protoreflect.EnumType {
	return &file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_enumTypes[1]
}

func (x TPUEmbeddingConfiguration_ShardingStrategy) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use TPUEmbeddingConfiguration_ShardingStrategy.Descriptor instead.
func (TPUEmbeddingConfiguration_ShardingStrategy) EnumDescriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_rawDescGZIP(), []int{0, 1}
}

type TPUEmbeddingConfiguration struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	TableDescriptor []*TPUEmbeddingConfiguration_TableDescriptor `protobuf:"bytes,1,rep,name=table_descriptor,json=tableDescriptor,proto3" json:"table_descriptor,omitempty"`
	Mode            TPUEmbeddingConfiguration_Mode               `protobuf:"varint,2,opt,name=mode,proto3,enum=tensorflow.tpu.TPUEmbeddingConfiguration_Mode" json:"mode,omitempty"`
	// Number of samples in each batch of embedding layer activations sent to
	// the TensorCore.
	BatchSizePerTensorCore int32 `protobuf:"varint,3,opt,name=batch_size_per_tensor_core,json=batchSizePerTensorCore,proto3" json:"batch_size_per_tensor_core,omitempty"`
	// Number of TPU hosts used for inference/training.
	NumHosts int32 `protobuf:"varint,4,opt,name=num_hosts,json=numHosts,proto3" json:"num_hosts,omitempty"`
	// Number of TensorCore used for inference/training.
	NumTensorCores   int32                                      `protobuf:"varint,5,opt,name=num_tensor_cores,json=numTensorCores,proto3" json:"num_tensor_cores,omitempty"`
	ShardingStrategy TPUEmbeddingConfiguration_ShardingStrategy `protobuf:"varint,6,opt,name=sharding_strategy,json=shardingStrategy,proto3,enum=tensorflow.tpu.TPUEmbeddingConfiguration_ShardingStrategy" json:"sharding_strategy,omitempty"`
	// This parameter determines if the execution of the sparse core will be
	// pipelined with that of the TensorCore. This parameter only affects results
	// when mode=TRAINING. If mode=INFERENCE or BACKWARD_PASS_ONLY, this parameter
	// does not affect execution and hence, is a don't care value.
	//
	// false: The execution of the sparse core is not pipelined with that of the
	// TensorCore. The forward pass of every step on the sparse core is executed
	// only after the backward pass of the previous step is complete. And the
	// backward pass on the sparse core is executed only after the embedding
	// gradients have been computed on the TensorCore on every step. This ensures
	// that the activations on every step observe the gradient updates from the
	// previous step on both the sparse core and the TensorCore.
	//
	// true: The execution of the sparse core is pipelined with that of the
	// TensorCore. The forward pass of every step on the sparse core can be
	// executed after the forward pass of the previous step is complete without
	// waiting for the backward pass. This improves the utilization of the sparse
	// core allowing it to process step N+1 while the embedding gradients for step
	// N are computed on the TensorCore. The backward pass of every step on the
	// sparse core is executed directly after the forward pass for the next step
	// is complete. The drawback is that embedding activations for step N+1 do not
	// observe the embedding gradient updates from step N. This could affect model
	// quality if step N and N+1 involve the same set of embedding IDs. However,
	// since the embedding updates are sparse, this is generally not considered a
	// problem.
	PipelineExecutionWithTensorCore bool `protobuf:"varint,7,opt,name=pipeline_execution_with_tensor_core,json=pipelineExecutionWithTensorCore,proto3" json:"pipeline_execution_with_tensor_core,omitempty"`
	// Directory where embedding lookup statistics are stored. These statistics
	// summarize information about the inputs to the embedding lookup
	// operation, in particular, the average number of embedding IDs per example
	// and how well the embedding IDs are load balanced across the system. The
	// lookup statistics are used during TPU initialization for embedding table
	// partitioning. Collection of lookup statistics is done at runtime by
	// profiling the embedding inputs: only 3% of input samples are profiled to
	// minimize host CPU overhead. Once a suitable number of samples are
	// profiled, the lookup statistics are saved to table-specific files in the
	// profile data directory generally at the end of a TPU training loop. The
	// filename corresponding to each table is obtained by hashing table specific
	// parameters (e.g., table name and number of features) and global
	// configuration parameters (e.g., sharding strategy and TPU worker task
	// count). The same profile data directory can be shared amongst several
	// models to reuse embedding lookup statistics.
	ProfileDataDirectory string `protobuf:"bytes,9,opt,name=profile_data_directory,json=profileDataDirectory,proto3" json:"profile_data_directory,omitempty"`
	// If the feature_descriptor field is populated, the model should NOT populate
	// TableDescriptor.num_features and batch_size_per_tensor_core. These two
	// fields will be auto-populated by the TPUEmbedding rewrite passes.
	FeatureDescriptor []*TPUEmbeddingConfiguration_FeatureDescriptor `protobuf:"bytes,10,rep,name=feature_descriptor,json=featureDescriptor,proto3" json:"feature_descriptor,omitempty"`
	SpmdSharding      *TPUEmbeddingConfiguration_SpmdSharding        `protobuf:"bytes,11,opt,name=spmd_sharding,json=spmdSharding,proto3" json:"spmd_sharding,omitempty"`
}

func (x *TPUEmbeddingConfiguration) Reset() {
	*x = TPUEmbeddingConfiguration{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_msgTypes[0]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *TPUEmbeddingConfiguration) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TPUEmbeddingConfiguration) ProtoMessage() {}

func (x *TPUEmbeddingConfiguration) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_msgTypes[0]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TPUEmbeddingConfiguration.ProtoReflect.Descriptor instead.
func (*TPUEmbeddingConfiguration) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_rawDescGZIP(), []int{0}
}

func (x *TPUEmbeddingConfiguration) GetTableDescriptor() []*TPUEmbeddingConfiguration_TableDescriptor {
	if x != nil {
		return x.TableDescriptor
	}
	return nil
}

func (x *TPUEmbeddingConfiguration) GetMode() TPUEmbeddingConfiguration_Mode {
	if x != nil {
		return x.Mode
	}
	return TPUEmbeddingConfiguration_UNSPECIFIED
}

func (x *TPUEmbeddingConfiguration) GetBatchSizePerTensorCore() int32 {
	if x != nil {
		return x.BatchSizePerTensorCore
	}
	return 0
}

func (x *TPUEmbeddingConfiguration) GetNumHosts() int32 {
	if x != nil {
		return x.NumHosts
	}
	return 0
}

func (x *TPUEmbeddingConfiguration) GetNumTensorCores() int32 {
	if x != nil {
		return x.NumTensorCores
	}
	return 0
}

func (x *TPUEmbeddingConfiguration) GetShardingStrategy() TPUEmbeddingConfiguration_ShardingStrategy {
	if x != nil {
		return x.ShardingStrategy
	}
	return TPUEmbeddingConfiguration_DIV_DEFAULT
}

func (x *TPUEmbeddingConfiguration) GetPipelineExecutionWithTensorCore() bool {
	if x != nil {
		return x.PipelineExecutionWithTensorCore
	}
	return false
}

func (x *TPUEmbeddingConfiguration) GetProfileDataDirectory() string {
	if x != nil {
		return x.ProfileDataDirectory
	}
	return ""
}

func (x *TPUEmbeddingConfiguration) GetFeatureDescriptor() []*TPUEmbeddingConfiguration_FeatureDescriptor {
	if x != nil {
		return x.FeatureDescriptor
	}
	return nil
}

func (x *TPUEmbeddingConfiguration) GetSpmdSharding() *TPUEmbeddingConfiguration_SpmdSharding {
	if x != nil {
		return x.SpmdSharding
	}
	return nil
}

// A placeholder message that is used to define a unique Status payload
// URL for TPU embedding errors.
type TPUEmbeddingError struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields
}

func (x *TPUEmbeddingError) Reset() {
	*x = TPUEmbeddingError{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_msgTypes[1]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *TPUEmbeddingError) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TPUEmbeddingError) ProtoMessage() {}

func (x *TPUEmbeddingError) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_msgTypes[1]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TPUEmbeddingError.ProtoReflect.Descriptor instead.
func (*TPUEmbeddingError) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_rawDescGZIP(), []int{1}
}

// Description of the various embedding tables.
type TPUEmbeddingConfiguration_TableDescriptor struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// Name of the table.
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// Size of the vocabulary (i.e., number of rows) in the table.
	VocabularySize int64 `protobuf:"varint,2,opt,name=vocabulary_size,json=vocabularySize,proto3" json:"vocabulary_size,omitempty"`
	// The embedding dimension (i.e., the width of the embedding table).
	Dimension int32 `protobuf:"varint,3,opt,name=dimension,proto3" json:"dimension,omitempty"`
	// Number of features mapped to this table.
	NumFeatures int32 `protobuf:"varint,4,opt,name=num_features,json=numFeatures,proto3" json:"num_features,omitempty"`
	// Details of the learning algorithm used to update the embedding
	// parameters.
	OptimizationParameters *OptimizationParameters `protobuf:"bytes,5,opt,name=optimization_parameters,json=optimizationParameters,proto3" json:"optimization_parameters,omitempty"`
}

func (x *TPUEmbeddingConfiguration_TableDescriptor) Reset() {
	*x = TPUEmbeddingConfiguration_TableDescriptor{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_msgTypes[2]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *TPUEmbeddingConfiguration_TableDescriptor) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TPUEmbeddingConfiguration_TableDescriptor) ProtoMessage() {}

func (x *TPUEmbeddingConfiguration_TableDescriptor) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_msgTypes[2]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TPUEmbeddingConfiguration_TableDescriptor.ProtoReflect.Descriptor instead.
func (*TPUEmbeddingConfiguration_TableDescriptor) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_rawDescGZIP(), []int{0, 0}
}

func (x *TPUEmbeddingConfiguration_TableDescriptor) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *TPUEmbeddingConfiguration_TableDescriptor) GetVocabularySize() int64 {
	if x != nil {
		return x.VocabularySize
	}
	return 0
}

func (x *TPUEmbeddingConfiguration_TableDescriptor) GetDimension() int32 {
	if x != nil {
		return x.Dimension
	}
	return 0
}

func (x *TPUEmbeddingConfiguration_TableDescriptor) GetNumFeatures() int32 {
	if x != nil {
		return x.NumFeatures
	}
	return 0
}

func (x *TPUEmbeddingConfiguration_TableDescriptor) GetOptimizationParameters() *OptimizationParameters {
	if x != nil {
		return x.OptimizationParameters
	}
	return nil
}

// Description of different input features.
type TPUEmbeddingConfiguration_FeatureDescriptor struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// Name of the input feature.
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// Index of the corresponding table in the TableDescriptor list.
	TableId int32 `protobuf:"varint,2,opt,name=table_id,json=tableId,proto3" json:"table_id,omitempty"`
	// Static shape of the inputs (excluding the reduction axis). Note that
	// the shape of the actual inputs provided using the infeed op must be
	// strictly smaller than input_shape. The outputs received at the TensorCore
	// will have rank = input_shape.size() + 1. The innermost axis corresponds
	// to the embedding dimension. If the input has shape [m, n, k] (excluding
	// the reduction axis) and the embedding dimension is d, the output received
	// at the TensorCore will have shape [m, n, k, d].
	InputShape []int32 `protobuf:"varint,3,rep,packed,name=input_shape,json=inputShape,proto3" json:"input_shape,omitempty"`
}

func (x *TPUEmbeddingConfiguration_FeatureDescriptor) Reset() {
	*x = TPUEmbeddingConfiguration_FeatureDescriptor{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_msgTypes[3]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *TPUEmbeddingConfiguration_FeatureDescriptor) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TPUEmbeddingConfiguration_FeatureDescriptor) ProtoMessage() {}

func (x *TPUEmbeddingConfiguration_FeatureDescriptor) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_msgTypes[3]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TPUEmbeddingConfiguration_FeatureDescriptor.ProtoReflect.Descriptor instead.
func (*TPUEmbeddingConfiguration_FeatureDescriptor) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_rawDescGZIP(), []int{0, 1}
}

func (x *TPUEmbeddingConfiguration_FeatureDescriptor) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *TPUEmbeddingConfiguration_FeatureDescriptor) GetTableId() int32 {
	if x != nil {
		return x.TableId
	}
	return 0
}

func (x *TPUEmbeddingConfiguration_FeatureDescriptor) GetInputShape() []int32 {
	if x != nil {
		return x.InputShape
	}
	return nil
}

// SPMD (Single Program Multiple Data) sharding configuration for
// TPUEmbedding. When model parallelism is used on the TensorCore, the number
// of cores per replica must be passed to TPUEmbedding so that the right
// shapes can be computed in the TF/XLA bridge.
type TPUEmbeddingConfiguration_SpmdSharding struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// Whether SPMD sharding is enabled.
	Enabled bool `protobuf:"varint,1,opt,name=enabled,proto3" json:"enabled,omitempty"`
	// Number of cores per replica.
	NumCoresPerReplica int32 `protobuf:"varint,2,opt,name=num_cores_per_replica,json=numCoresPerReplica,proto3" json:"num_cores_per_replica,omitempty"`
}

func (x *TPUEmbeddingConfiguration_SpmdSharding) Reset() {
	*x = TPUEmbeddingConfiguration_SpmdSharding{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_msgTypes[4]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *TPUEmbeddingConfiguration_SpmdSharding) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TPUEmbeddingConfiguration_SpmdSharding) ProtoMessage() {}

func (x *TPUEmbeddingConfiguration_SpmdSharding) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_msgTypes[4]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TPUEmbeddingConfiguration_SpmdSharding.ProtoReflect.Descriptor instead.
func (*TPUEmbeddingConfiguration_SpmdSharding) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_rawDescGZIP(), []int{0, 2}
}

func (x *TPUEmbeddingConfiguration_SpmdSharding) GetEnabled() bool {
	if x != nil {
		return x.Enabled
	}
	return false
}

func (x *TPUEmbeddingConfiguration_SpmdSharding) GetNumCoresPerReplica() int32 {
	if x != nil {
		return x.NumCoresPerReplica
	}
	return 0
}

var File_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto protoreflect.FileDescriptor

var file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_rawDesc = []byte{
	0x0a, 0x3e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2f, 0x63, 0x6f, 0x72,
	0x65, 0x2f, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x62, 0x75, 0x66, 0x2f, 0x74, 0x70, 0x75, 0x2f, 0x74,
	0x70, 0x75, 0x5f, 0x65, 0x6d, 0x62, 0x65, 0x64, 0x64, 0x69, 0x6e, 0x67, 0x5f, 0x63, 0x6f, 0x6e,
	0x66, 0x69, 0x67, 0x75, 0x72, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f,
	0x12, 0x0e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x74, 0x70, 0x75,
	0x1a, 0x3a, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2f, 0x63, 0x6f, 0x72,
	0x65, 0x2f, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x62, 0x75, 0x66, 0x2f, 0x74, 0x70, 0x75, 0x2f, 0x6f,
	0x70, 0x74, 0x69, 0x6d, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x5f, 0x70, 0x61, 0x72, 0x61,
	0x6d, 0x65, 0x74, 0x65, 0x72, 0x73, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x22, 0xc4, 0x0a, 0x0a,
	0x19, 0x54, 0x50, 0x55, 0x45, 0x6d, 0x62, 0x65, 0x64, 0x64, 0x69, 0x6e, 0x67, 0x43, 0x6f, 0x6e,
	0x66, 0x69, 0x67, 0x75, 0x72, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x12, 0x64, 0x0a, 0x10, 0x74, 0x61,
	0x62, 0x6c, 0x65, 0x5f, 0x64, 0x65, 0x73, 0x63, 0x72, 0x69, 0x70, 0x74, 0x6f, 0x72, 0x18, 0x01,
	0x20, 0x03, 0x28, 0x0b, 0x32, 0x39, 0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f,
	0x77, 0x2e, 0x74, 0x70, 0x75, 0x2e, 0x54, 0x50, 0x55, 0x45, 0x6d, 0x62, 0x65, 0x64, 0x64, 0x69,
	0x6e, 0x67, 0x43, 0x6f, 0x6e, 0x66, 0x69, 0x67, 0x75, 0x72, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x2e,
	0x54, 0x61, 0x62, 0x6c, 0x65, 0x44, 0x65, 0x73, 0x63, 0x72, 0x69, 0x70, 0x74, 0x6f, 0x72, 0x52,
	0x0f, 0x74, 0x61, 0x62, 0x6c, 0x65, 0x44, 0x65, 0x73, 0x63, 0x72, 0x69, 0x70, 0x74, 0x6f, 0x72,
	0x12, 0x42, 0x0a, 0x04, 0x6d, 0x6f, 0x64, 0x65, 0x18, 0x02, 0x20, 0x01, 0x28, 0x0e, 0x32, 0x2e,
	0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x74, 0x70, 0x75, 0x2e,
	0x54, 0x50, 0x55, 0x45, 0x6d, 0x62, 0x65, 0x64, 0x64, 0x69, 0x6e, 0x67, 0x43, 0x6f, 0x6e, 0x66,
	0x69, 0x67, 0x75, 0x72, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x2e, 0x4d, 0x6f, 0x64, 0x65, 0x52, 0x04,
	0x6d, 0x6f, 0x64, 0x65, 0x12, 0x3a, 0x0a, 0x1a, 0x62, 0x61, 0x74, 0x63, 0x68, 0x5f, 0x73, 0x69,
	0x7a, 0x65, 0x5f, 0x70, 0x65, 0x72, 0x5f, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x5f, 0x63, 0x6f,
	0x72, 0x65, 0x18, 0x03, 0x20, 0x01, 0x28, 0x05, 0x52, 0x16, 0x62, 0x61, 0x74, 0x63, 0x68, 0x53,
	0x69, 0x7a, 0x65, 0x50, 0x65, 0x72, 0x54, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x43, 0x6f, 0x72, 0x65,
	0x12, 0x1b, 0x0a, 0x09, 0x6e, 0x75, 0x6d, 0x5f, 0x68, 0x6f, 0x73, 0x74, 0x73, 0x18, 0x04, 0x20,
	0x01, 0x28, 0x05, 0x52, 0x08, 0x6e, 0x75, 0x6d, 0x48, 0x6f, 0x73, 0x74, 0x73, 0x12, 0x28, 0x0a,
	0x10, 0x6e, 0x75, 0x6d, 0x5f, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x5f, 0x63, 0x6f, 0x72, 0x65,
	0x73, 0x18, 0x05, 0x20, 0x01, 0x28, 0x05, 0x52, 0x0e, 0x6e, 0x75, 0x6d, 0x54, 0x65, 0x6e, 0x73,
	0x6f, 0x72, 0x43, 0x6f, 0x72, 0x65, 0x73, 0x12, 0x67, 0x0a, 0x11, 0x73, 0x68, 0x61, 0x72, 0x64,
	0x69, 0x6e, 0x67, 0x5f, 0x73, 0x74, 0x72, 0x61, 0x74, 0x65, 0x67, 0x79, 0x18, 0x06, 0x20, 0x01,
	0x28, 0x0e, 0x32, 0x3a, 0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e,
	0x74, 0x70, 0x75, 0x2e, 0x54, 0x50, 0x55, 0x45, 0x6d, 0x62, 0x65, 0x64, 0x64, 0x69, 0x6e, 0x67,
	0x43, 0x6f, 0x6e, 0x66, 0x69, 0x67, 0x75, 0x72, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x2e, 0x53, 0x68,
	0x61, 0x72, 0x64, 0x69, 0x6e, 0x67, 0x53, 0x74, 0x72, 0x61, 0x74, 0x65, 0x67, 0x79, 0x52, 0x10,
	0x73, 0x68, 0x61, 0x72, 0x64, 0x69, 0x6e, 0x67, 0x53, 0x74, 0x72, 0x61, 0x74, 0x65, 0x67, 0x79,
	0x12, 0x4c, 0x0a, 0x23, 0x70, 0x69, 0x70, 0x65, 0x6c, 0x69, 0x6e, 0x65, 0x5f, 0x65, 0x78, 0x65,
	0x63, 0x75, 0x74, 0x69, 0x6f, 0x6e, 0x5f, 0x77, 0x69, 0x74, 0x68, 0x5f, 0x74, 0x65, 0x6e, 0x73,
	0x6f, 0x72, 0x5f, 0x63, 0x6f, 0x72, 0x65, 0x18, 0x07, 0x20, 0x01, 0x28, 0x08, 0x52, 0x1f, 0x70,
	0x69, 0x70, 0x65, 0x6c, 0x69, 0x6e, 0x65, 0x45, 0x78, 0x65, 0x63, 0x75, 0x74, 0x69, 0x6f, 0x6e,
	0x57, 0x69, 0x74, 0x68, 0x54, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x43, 0x6f, 0x72, 0x65, 0x12, 0x34,
	0x0a, 0x16, 0x70, 0x72, 0x6f, 0x66, 0x69, 0x6c, 0x65, 0x5f, 0x64, 0x61, 0x74, 0x61, 0x5f, 0x64,
	0x69, 0x72, 0x65, 0x63, 0x74, 0x6f, 0x72, 0x79, 0x18, 0x09, 0x20, 0x01, 0x28, 0x09, 0x52, 0x14,
	0x70, 0x72, 0x6f, 0x66, 0x69, 0x6c, 0x65, 0x44, 0x61, 0x74, 0x61, 0x44, 0x69, 0x72, 0x65, 0x63,
	0x74, 0x6f, 0x72, 0x79, 0x12, 0x6a, 0x0a, 0x12, 0x66, 0x65, 0x61, 0x74, 0x75, 0x72, 0x65, 0x5f,
	0x64, 0x65, 0x73, 0x63, 0x72, 0x69, 0x70, 0x74, 0x6f, 0x72, 0x18, 0x0a, 0x20, 0x03, 0x28, 0x0b,
	0x32, 0x3b, 0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x74, 0x70,
	0x75, 0x2e, 0x54, 0x50, 0x55, 0x45, 0x6d, 0x62, 0x65, 0x64, 0x64, 0x69, 0x6e, 0x67, 0x43, 0x6f,
	0x6e, 0x66, 0x69, 0x67, 0x75, 0x72, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x2e, 0x46, 0x65, 0x61, 0x74,
	0x75, 0x72, 0x65, 0x44, 0x65, 0x73, 0x63, 0x72, 0x69, 0x70, 0x74, 0x6f, 0x72, 0x52, 0x11, 0x66,
	0x65, 0x61, 0x74, 0x75, 0x72, 0x65, 0x44, 0x65, 0x73, 0x63, 0x72, 0x69, 0x70, 0x74, 0x6f, 0x72,
	0x12, 0x5b, 0x0a, 0x0d, 0x73, 0x70, 0x6d, 0x64, 0x5f, 0x73, 0x68, 0x61, 0x72, 0x64, 0x69, 0x6e,
	0x67, 0x18, 0x0b, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x36, 0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72,
	0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x74, 0x70, 0x75, 0x2e, 0x54, 0x50, 0x55, 0x45, 0x6d, 0x62, 0x65,
	0x64, 0x64, 0x69, 0x6e, 0x67, 0x43, 0x6f, 0x6e, 0x66, 0x69, 0x67, 0x75, 0x72, 0x61, 0x74, 0x69,
	0x6f, 0x6e, 0x2e, 0x53, 0x70, 0x6d, 0x64, 0x53, 0x68, 0x61, 0x72, 0x64, 0x69, 0x6e, 0x67, 0x52,
	0x0c, 0x73, 0x70, 0x6d, 0x64, 0x53, 0x68, 0x61, 0x72, 0x64, 0x69, 0x6e, 0x67, 0x1a, 0xf0, 0x01,
	0x0a, 0x0f, 0x54, 0x61, 0x62, 0x6c, 0x65, 0x44, 0x65, 0x73, 0x63, 0x72, 0x69, 0x70, 0x74, 0x6f,
	0x72, 0x12, 0x12, 0x0a, 0x04, 0x6e, 0x61, 0x6d, 0x65, 0x18, 0x01, 0x20, 0x01, 0x28, 0x09, 0x52,
	0x04, 0x6e, 0x61, 0x6d, 0x65, 0x12, 0x27, 0x0a, 0x0f, 0x76, 0x6f, 0x63, 0x61, 0x62, 0x75, 0x6c,
	0x61, 0x72, 0x79, 0x5f, 0x73, 0x69, 0x7a, 0x65, 0x18, 0x02, 0x20, 0x01, 0x28, 0x03, 0x52, 0x0e,
	0x76, 0x6f, 0x63, 0x61, 0x62, 0x75, 0x6c, 0x61, 0x72, 0x79, 0x53, 0x69, 0x7a, 0x65, 0x12, 0x1c,
	0x0a, 0x09, 0x64, 0x69, 0x6d, 0x65, 0x6e, 0x73, 0x69, 0x6f, 0x6e, 0x18, 0x03, 0x20, 0x01, 0x28,
	0x05, 0x52, 0x09, 0x64, 0x69, 0x6d, 0x65, 0x6e, 0x73, 0x69, 0x6f, 0x6e, 0x12, 0x21, 0x0a, 0x0c,
	0x6e, 0x75, 0x6d, 0x5f, 0x66, 0x65, 0x61, 0x74, 0x75, 0x72, 0x65, 0x73, 0x18, 0x04, 0x20, 0x01,
	0x28, 0x05, 0x52, 0x0b, 0x6e, 0x75, 0x6d, 0x46, 0x65, 0x61, 0x74, 0x75, 0x72, 0x65, 0x73, 0x12,
	0x5f, 0x0a, 0x17, 0x6f, 0x70, 0x74, 0x69, 0x6d, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x5f,
	0x70, 0x61, 0x72, 0x61, 0x6d, 0x65, 0x74, 0x65, 0x72, 0x73, 0x18, 0x05, 0x20, 0x01, 0x28, 0x0b,
	0x32, 0x26, 0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x74, 0x70,
	0x75, 0x2e, 0x4f, 0x70, 0x74, 0x69, 0x6d, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x50, 0x61,
	0x72, 0x61, 0x6d, 0x65, 0x74, 0x65, 0x72, 0x73, 0x52, 0x16, 0x6f, 0x70, 0x74, 0x69, 0x6d, 0x69,
	0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x50, 0x61, 0x72, 0x61, 0x6d, 0x65, 0x74, 0x65, 0x72, 0x73,
	0x1a, 0x63, 0x0a, 0x11, 0x46, 0x65, 0x61, 0x74, 0x75, 0x72, 0x65, 0x44, 0x65, 0x73, 0x63, 0x72,
	0x69, 0x70, 0x74, 0x6f, 0x72, 0x12, 0x12, 0x0a, 0x04, 0x6e, 0x61, 0x6d, 0x65, 0x18, 0x01, 0x20,
	0x01, 0x28, 0x09, 0x52, 0x04, 0x6e, 0x61, 0x6d, 0x65, 0x12, 0x19, 0x0a, 0x08, 0x74, 0x61, 0x62,
	0x6c, 0x65, 0x5f, 0x69, 0x64, 0x18, 0x02, 0x20, 0x01, 0x28, 0x05, 0x52, 0x07, 0x74, 0x61, 0x62,
	0x6c, 0x65, 0x49, 0x64, 0x12, 0x1f, 0x0a, 0x0b, 0x69, 0x6e, 0x70, 0x75, 0x74, 0x5f, 0x73, 0x68,
	0x61, 0x70, 0x65, 0x18, 0x03, 0x20, 0x03, 0x28, 0x05, 0x52, 0x0a, 0x69, 0x6e, 0x70, 0x75, 0x74,
	0x53, 0x68, 0x61, 0x70, 0x65, 0x1a, 0x5b, 0x0a, 0x0c, 0x53, 0x70, 0x6d, 0x64, 0x53, 0x68, 0x61,
	0x72, 0x64, 0x69, 0x6e, 0x67, 0x12, 0x18, 0x0a, 0x07, 0x65, 0x6e, 0x61, 0x62, 0x6c, 0x65, 0x64,
	0x18, 0x01, 0x20, 0x01, 0x28, 0x08, 0x52, 0x07, 0x65, 0x6e, 0x61, 0x62, 0x6c, 0x65, 0x64, 0x12,
	0x31, 0x0a, 0x15, 0x6e, 0x75, 0x6d, 0x5f, 0x63, 0x6f, 0x72, 0x65, 0x73, 0x5f, 0x70, 0x65, 0x72,
	0x5f, 0x72, 0x65, 0x70, 0x6c, 0x69, 0x63, 0x61, 0x18, 0x02, 0x20, 0x01, 0x28, 0x05, 0x52, 0x12,
	0x6e, 0x75, 0x6d, 0x43, 0x6f, 0x72, 0x65, 0x73, 0x50, 0x65, 0x72, 0x52, 0x65, 0x70, 0x6c, 0x69,
	0x63, 0x61, 0x22, 0x4c, 0x0a, 0x04, 0x4d, 0x6f, 0x64, 0x65, 0x12, 0x0f, 0x0a, 0x0b, 0x55, 0x4e,
	0x53, 0x50, 0x45, 0x43, 0x49, 0x46, 0x49, 0x45, 0x44, 0x10, 0x00, 0x12, 0x0d, 0x0a, 0x09, 0x49,
	0x4e, 0x46, 0x45, 0x52, 0x45, 0x4e, 0x43, 0x45, 0x10, 0x01, 0x12, 0x0c, 0x0a, 0x08, 0x54, 0x52,
	0x41, 0x49, 0x4e, 0x49, 0x4e, 0x47, 0x10, 0x02, 0x12, 0x16, 0x0a, 0x12, 0x42, 0x41, 0x43, 0x4b,
	0x57, 0x41, 0x52, 0x44, 0x5f, 0x50, 0x41, 0x53, 0x53, 0x5f, 0x4f, 0x4e, 0x4c, 0x59, 0x10, 0x03,
	0x22, 0x2c, 0x0a, 0x10, 0x53, 0x68, 0x61, 0x72, 0x64, 0x69, 0x6e, 0x67, 0x53, 0x74, 0x72, 0x61,
	0x74, 0x65, 0x67, 0x79, 0x12, 0x0f, 0x0a, 0x0b, 0x44, 0x49, 0x56, 0x5f, 0x44, 0x45, 0x46, 0x41,
	0x55, 0x4c, 0x54, 0x10, 0x00, 0x12, 0x07, 0x0a, 0x03, 0x4d, 0x4f, 0x44, 0x10, 0x01, 0x4a, 0x04,
	0x08, 0x08, 0x10, 0x09, 0x52, 0x0d, 0x6f, 0x75, 0x74, 0x70, 0x75, 0x74, 0x5f, 0x6c, 0x61, 0x79,
	0x6f, 0x75, 0x74, 0x22, 0x13, 0x0a, 0x11, 0x54, 0x50, 0x55, 0x45, 0x6d, 0x62, 0x65, 0x64, 0x64,
	0x69, 0x6e, 0x67, 0x45, 0x72, 0x72, 0x6f, 0x72, 0x42, 0xcc, 0x01, 0x0a, 0x12, 0x63, 0x6f, 0x6d,
	0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x74, 0x70, 0x75, 0x42,
	0x1e, 0x54, 0x70, 0x75, 0x45, 0x6d, 0x62, 0x65, 0x64, 0x64, 0x69, 0x6e, 0x67, 0x43, 0x6f, 0x6e,
	0x66, 0x69, 0x67, 0x75, 0x72, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x50, 0x72, 0x6f, 0x74, 0x6f, 0x48,
	0x02, 0x50, 0x01, 0x5a, 0x3b, 0x67, 0x69, 0x74, 0x65, 0x65, 0x2e, 0x63, 0x6f, 0x6d, 0x2f, 0x71,
	0x63, 0x69, 0x69, 0x70, 0x2d, 0x69, 0x63, 0x70, 0x2f, 0x74, 0x66, 0x2d, 0x73, 0x65, 0x72, 0x76,
	0x69, 0x6e, 0x67, 0x2f, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2f, 0x63,
	0x6f, 0x72, 0x65, 0x2f, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x62, 0x75, 0x66, 0x2f, 0x74, 0x70, 0x75,
	0xa2, 0x02, 0x03, 0x54, 0x54, 0x58, 0xaa, 0x02, 0x0e, 0x54, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66,
	0x6c, 0x6f, 0x77, 0x2e, 0x54, 0x70, 0x75, 0xca, 0x02, 0x0e, 0x54, 0x65, 0x6e, 0x73, 0x6f, 0x72,
	0x66, 0x6c, 0x6f, 0x77, 0x5c, 0x54, 0x70, 0x75, 0xe2, 0x02, 0x1a, 0x54, 0x65, 0x6e, 0x73, 0x6f,
	0x72, 0x66, 0x6c, 0x6f, 0x77, 0x5c, 0x54, 0x70, 0x75, 0x5c, 0x47, 0x50, 0x42, 0x4d, 0x65, 0x74,
	0x61, 0x64, 0x61, 0x74, 0x61, 0xea, 0x02, 0x0f, 0x54, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c,
	0x6f, 0x77, 0x3a, 0x3a, 0x54, 0x70, 0x75, 0x62, 0x06, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x33,
}

var (
	file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_rawDescOnce sync.Once
	file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_rawDescData = file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_rawDesc
)

func file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_rawDescGZIP() []byte {
	file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_rawDescOnce.Do(func() {
		file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_rawDescData = protoimpl.X.CompressGZIP(file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_rawDescData)
	})
	return file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_rawDescData
}

var file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_enumTypes = make([]protoimpl.EnumInfo, 2)
var file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_msgTypes = make([]protoimpl.MessageInfo, 5)
var file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_goTypes = []interface{}{
	(TPUEmbeddingConfiguration_Mode)(0),                 // 0: tensorflow.tpu.TPUEmbeddingConfiguration.Mode
	(TPUEmbeddingConfiguration_ShardingStrategy)(0),     // 1: tensorflow.tpu.TPUEmbeddingConfiguration.ShardingStrategy
	(*TPUEmbeddingConfiguration)(nil),                   // 2: tensorflow.tpu.TPUEmbeddingConfiguration
	(*TPUEmbeddingError)(nil),                           // 3: tensorflow.tpu.TPUEmbeddingError
	(*TPUEmbeddingConfiguration_TableDescriptor)(nil),   // 4: tensorflow.tpu.TPUEmbeddingConfiguration.TableDescriptor
	(*TPUEmbeddingConfiguration_FeatureDescriptor)(nil), // 5: tensorflow.tpu.TPUEmbeddingConfiguration.FeatureDescriptor
	(*TPUEmbeddingConfiguration_SpmdSharding)(nil),      // 6: tensorflow.tpu.TPUEmbeddingConfiguration.SpmdSharding
	(*OptimizationParameters)(nil),                      // 7: tensorflow.tpu.OptimizationParameters
}
var file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_depIdxs = []int32{
	4, // 0: tensorflow.tpu.TPUEmbeddingConfiguration.table_descriptor:type_name -> tensorflow.tpu.TPUEmbeddingConfiguration.TableDescriptor
	0, // 1: tensorflow.tpu.TPUEmbeddingConfiguration.mode:type_name -> tensorflow.tpu.TPUEmbeddingConfiguration.Mode
	1, // 2: tensorflow.tpu.TPUEmbeddingConfiguration.sharding_strategy:type_name -> tensorflow.tpu.TPUEmbeddingConfiguration.ShardingStrategy
	5, // 3: tensorflow.tpu.TPUEmbeddingConfiguration.feature_descriptor:type_name -> tensorflow.tpu.TPUEmbeddingConfiguration.FeatureDescriptor
	6, // 4: tensorflow.tpu.TPUEmbeddingConfiguration.spmd_sharding:type_name -> tensorflow.tpu.TPUEmbeddingConfiguration.SpmdSharding
	7, // 5: tensorflow.tpu.TPUEmbeddingConfiguration.TableDescriptor.optimization_parameters:type_name -> tensorflow.tpu.OptimizationParameters
	6, // [6:6] is the sub-list for method output_type
	6, // [6:6] is the sub-list for method input_type
	6, // [6:6] is the sub-list for extension type_name
	6, // [6:6] is the sub-list for extension extendee
	0, // [0:6] is the sub-list for field type_name
}

func init() { file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_init() }
func file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_init() {
	if File_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto != nil {
		return
	}
	file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_init()
	if !protoimpl.UnsafeEnabled {
		file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_msgTypes[0].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*TPUEmbeddingConfiguration); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_msgTypes[1].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*TPUEmbeddingError); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_msgTypes[2].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*TPUEmbeddingConfiguration_TableDescriptor); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_msgTypes[3].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*TPUEmbeddingConfiguration_FeatureDescriptor); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_msgTypes[4].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*TPUEmbeddingConfiguration_SpmdSharding); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_rawDesc,
			NumEnums:      2,
			NumMessages:   5,
			NumExtensions: 0,
			NumServices:   0,
		},
		GoTypes:           file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_goTypes,
		DependencyIndexes: file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_depIdxs,
		EnumInfos:         file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_enumTypes,
		MessageInfos:      file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_msgTypes,
	}.Build()
	File_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto = out.File
	file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_rawDesc = nil
	file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_goTypes = nil
	file_tensorflow_core_protobuf_tpu_tpu_embedding_configuration_proto_depIdxs = nil
}
