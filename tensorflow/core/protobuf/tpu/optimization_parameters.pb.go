// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.28.1
// 	protoc        (unknown)
// source: tensorflow/core/protobuf/tpu/optimization_parameters.proto

package tpu

import (
	service "gitee.com/qciip-icp/tf-serving/tensorflow/compiler/xla/service"
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	wrapperspb "google.golang.org/protobuf/types/known/wrapperspb"
	reflect "reflect"
	sync "sync"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// if UNSPECIFIED (default), gradient accumulation is ENABLED.
type GradientAccumulationStatus_Status int32

const (
	GradientAccumulationStatus_UNSPECIFIED GradientAccumulationStatus_Status = 0
	GradientAccumulationStatus_ENABLED     GradientAccumulationStatus_Status = 1
	GradientAccumulationStatus_DISABLED    GradientAccumulationStatus_Status = 2
)

// Enum value maps for GradientAccumulationStatus_Status.
var (
	GradientAccumulationStatus_Status_name = map[int32]string{
		0: "UNSPECIFIED",
		1: "ENABLED",
		2: "DISABLED",
	}
	GradientAccumulationStatus_Status_value = map[string]int32{
		"UNSPECIFIED": 0,
		"ENABLED":     1,
		"DISABLED":    2,
	}
)

func (x GradientAccumulationStatus_Status) Enum() *GradientAccumulationStatus_Status {
	p := new(GradientAccumulationStatus_Status)
	*p = x
	return p
}

func (x GradientAccumulationStatus_Status) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (GradientAccumulationStatus_Status) Descriptor() protoreflect.EnumDescriptor {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_enumTypes[0].Descriptor()
}

func (GradientAccumulationStatus_Status) Type() protoreflect.EnumType {
	return &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_enumTypes[0]
}

func (x GradientAccumulationStatus_Status) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use GradientAccumulationStatus_Status.Descriptor instead.
func (GradientAccumulationStatus_Status) EnumDescriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{21, 0}
}

// if UNSPECIFIED (default), the low dimension packing status is DISABLED.
// This can change in future.
//
// if ENABLED, the low dimension packing is enabled only if the following
// three additional conditions are true:
//   - The optimizer treats the zero gradient as a NoOp.
//   - The embedding dimension is 1, 2, or 4.
//   - The vocabulary size is large enough to avoid performance issues.
//
// if DISABLED, the low dimension packing is always disabled.
type LowDimensionalPackingStatus_Status int32

const (
	LowDimensionalPackingStatus_UNSPECIFIED LowDimensionalPackingStatus_Status = 0
	LowDimensionalPackingStatus_ENABLED     LowDimensionalPackingStatus_Status = 1
	LowDimensionalPackingStatus_DISABLED    LowDimensionalPackingStatus_Status = 2
)

// Enum value maps for LowDimensionalPackingStatus_Status.
var (
	LowDimensionalPackingStatus_Status_name = map[int32]string{
		0: "UNSPECIFIED",
		1: "ENABLED",
		2: "DISABLED",
	}
	LowDimensionalPackingStatus_Status_value = map[string]int32{
		"UNSPECIFIED": 0,
		"ENABLED":     1,
		"DISABLED":    2,
	}
)

func (x LowDimensionalPackingStatus_Status) Enum() *LowDimensionalPackingStatus_Status {
	p := new(LowDimensionalPackingStatus_Status)
	*p = x
	return p
}

func (x LowDimensionalPackingStatus_Status) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (LowDimensionalPackingStatus_Status) Descriptor() protoreflect.EnumDescriptor {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_enumTypes[1].Descriptor()
}

func (LowDimensionalPackingStatus_Status) Type() protoreflect.EnumType {
	return &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_enumTypes[1]
}

func (x LowDimensionalPackingStatus_Status) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use LowDimensionalPackingStatus_Status.Descriptor instead.
func (LowDimensionalPackingStatus_Status) EnumDescriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{22, 0}
}

// Whether to enable or disable hot ID optimization.
// If UNSPECIFIED (default), hot ID optimization is DISABLED.
type HotIdReplicationConfiguration_Status int32

const (
	HotIdReplicationConfiguration_UNSPECIFIED HotIdReplicationConfiguration_Status = 0
	HotIdReplicationConfiguration_ENABLED     HotIdReplicationConfiguration_Status = 1
	HotIdReplicationConfiguration_DISABLED    HotIdReplicationConfiguration_Status = 2
)

// Enum value maps for HotIdReplicationConfiguration_Status.
var (
	HotIdReplicationConfiguration_Status_name = map[int32]string{
		0: "UNSPECIFIED",
		1: "ENABLED",
		2: "DISABLED",
	}
	HotIdReplicationConfiguration_Status_value = map[string]int32{
		"UNSPECIFIED": 0,
		"ENABLED":     1,
		"DISABLED":    2,
	}
)

func (x HotIdReplicationConfiguration_Status) Enum() *HotIdReplicationConfiguration_Status {
	p := new(HotIdReplicationConfiguration_Status)
	*p = x
	return p
}

func (x HotIdReplicationConfiguration_Status) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (HotIdReplicationConfiguration_Status) Descriptor() protoreflect.EnumDescriptor {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_enumTypes[2].Descriptor()
}

func (HotIdReplicationConfiguration_Status) Type() protoreflect.EnumType {
	return &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_enumTypes[2]
}

func (x HotIdReplicationConfiguration_Status) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use HotIdReplicationConfiguration_Status.Descriptor instead.
func (HotIdReplicationConfiguration_Status) EnumDescriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{23, 0}
}

type ClippingLimits struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	Lower *wrapperspb.FloatValue `protobuf:"bytes,1,opt,name=lower,proto3" json:"lower,omitempty"` // -inf if not set
	Upper *wrapperspb.FloatValue `protobuf:"bytes,2,opt,name=upper,proto3" json:"upper,omitempty"` // +inf if not set
}

func (x *ClippingLimits) Reset() {
	*x = ClippingLimits{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[0]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *ClippingLimits) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ClippingLimits) ProtoMessage() {}

func (x *ClippingLimits) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[0]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ClippingLimits.ProtoReflect.Descriptor instead.
func (*ClippingLimits) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{0}
}

func (x *ClippingLimits) GetLower() *wrapperspb.FloatValue {
	if x != nil {
		return x.Lower
	}
	return nil
}

func (x *ClippingLimits) GetUpper() *wrapperspb.FloatValue {
	if x != nil {
		return x.Upper
	}
	return nil
}

// Configuration for simulated quantization; simulated quantization is used to
// reduce training/serving skew when the serving variables are quantized. The
// same quantization operations are executed during training to minimize
// differences with serving.
//
// Simulated quantization inserts the following operations on the forward pass
// after gathering the embedding vector from HBM. The backward pass operations
// are unchanged.
//
// clipped_val = clip(input, clipping_limits)
// quantum = clipping_limits.range() / (num_buckets - 1)
// quantized_val = floor((clipped_val - clipping_limits.lower()) / quantum + .5)
// return quantized_val * quantum + clipping_limits.lower().
type SimulatedQuantization struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// Whether simulated quantization is enabled.
	Enabled bool `protobuf:"varint,1,opt,name=enabled,proto3" json:"enabled,omitempty"`
	// Minimum and maximum values of the range used for quantization.
	ClippingLimits *ClippingLimits `protobuf:"bytes,2,opt,name=clipping_limits,json=clippingLimits,proto3" json:"clipping_limits,omitempty"`
	// Number of possible quantized values.
	NumBuckets int32 `protobuf:"varint,3,opt,name=num_buckets,json=numBuckets,proto3" json:"num_buckets,omitempty"`
}

func (x *SimulatedQuantization) Reset() {
	*x = SimulatedQuantization{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[1]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *SimulatedQuantization) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SimulatedQuantization) ProtoMessage() {}

func (x *SimulatedQuantization) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[1]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SimulatedQuantization.ProtoReflect.Descriptor instead.
func (*SimulatedQuantization) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{1}
}

func (x *SimulatedQuantization) GetEnabled() bool {
	if x != nil {
		return x.Enabled
	}
	return false
}

func (x *SimulatedQuantization) GetClippingLimits() *ClippingLimits {
	if x != nil {
		return x.ClippingLimits
	}
	return nil
}

func (x *SimulatedQuantization) GetNumBuckets() int32 {
	if x != nil {
		return x.NumBuckets
	}
	return 0
}

// Dynamic learning rate specification in the TPUEmbeddingConfiguration. The
// actual learning rates are provided as a scalar input list to the
// SendTPUEmbeddingGradients Op indexed by their tag specified through the
// following proto.
type DynamicLearningRate struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// For tables where learning rates are dynamically computed and communicated
	// to the TPU embedding program, a tag must be specified for the learning
	// rate.
	//
	// The tag must be a non-negative  integer. The total number of unique tags
	// must be less than or equal to the number of tables in the TPU embedding
	// configuration (a table does not specify any tag if it uses a constant
	// learning rate, and specifies exactly one tag if it uses dynamic learning
	// rates).
	//
	// All tags in the range [0, number_of_unique_tags) must be present in the TPU
	// embedding configuration, i.e. a tag cannot be skipped if a different tag
	// numerically greater than it is used in the configuration.
	//
	// If multiple tables specify the same tag, they *MUST* have
	// the same dynamic learning rate, for example, their dynamic learning rate
	// could be computed by the same TensorFlow sub-graph. The partitioning of the
	// embedding layer would be more optimal if the number_of_unique_tags is as
	// *LOW* as possible, i.e., if many tables share the same tag.
	//
	// The learning_rate input of the SendTPUEmbeddingGradients op is used to
	// communicate dynamic learning rates to the TPU embedding program.
	// The learning_rate input is a list of scalars where the size of the list is
	// equal to the number of unique tags. The learning rate associated with a
	// particular tag is specified by populating its corresponding index in the
	// list of learning_rate scalars.
	Tag int32 `protobuf:"varint,1,opt,name=tag,proto3" json:"tag,omitempty"`
}

func (x *DynamicLearningRate) Reset() {
	*x = DynamicLearningRate{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[2]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *DynamicLearningRate) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DynamicLearningRate) ProtoMessage() {}

func (x *DynamicLearningRate) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[2]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DynamicLearningRate.ProtoReflect.Descriptor instead.
func (*DynamicLearningRate) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{2}
}

func (x *DynamicLearningRate) GetTag() int32 {
	if x != nil {
		return x.Tag
	}
	return 0
}

// Source of learning rate to use.
type LearningRate struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// Types that are assignable to LearningRate:
	//
	//	*LearningRate_Constant
	//	*LearningRate_Dynamic
	LearningRate isLearningRate_LearningRate `protobuf_oneof:"learning_rate"`
}

func (x *LearningRate) Reset() {
	*x = LearningRate{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[3]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *LearningRate) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LearningRate) ProtoMessage() {}

func (x *LearningRate) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[3]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LearningRate.ProtoReflect.Descriptor instead.
func (*LearningRate) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{3}
}

func (m *LearningRate) GetLearningRate() isLearningRate_LearningRate {
	if m != nil {
		return m.LearningRate
	}
	return nil
}

func (x *LearningRate) GetConstant() float32 {
	if x, ok := x.GetLearningRate().(*LearningRate_Constant); ok {
		return x.Constant
	}
	return 0
}

func (x *LearningRate) GetDynamic() *DynamicLearningRate {
	if x, ok := x.GetLearningRate().(*LearningRate_Dynamic); ok {
		return x.Dynamic
	}
	return nil
}

type isLearningRate_LearningRate interface {
	isLearningRate_LearningRate()
}

type LearningRate_Constant struct {
	Constant float32 `protobuf:"fixed32,1,opt,name=constant,proto3,oneof"`
}

type LearningRate_Dynamic struct {
	Dynamic *DynamicLearningRate `protobuf:"bytes,2,opt,name=dynamic,proto3,oneof"`
}

func (*LearningRate_Constant) isLearningRate_LearningRate() {}

func (*LearningRate_Dynamic) isLearningRate_LearningRate() {}

// https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adagrad
// https://github.com/tensorflow/tensorflow/blob/6b6471f3ffb7f1fefe42d814aa5fb9ab7a535b58/tensorflow/core/kernels/training_ops.cc#L1634
type AdagradParameters struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields
}

func (x *AdagradParameters) Reset() {
	*x = AdagradParameters{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[4]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *AdagradParameters) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AdagradParameters) ProtoMessage() {}

func (x *AdagradParameters) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[4]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AdagradParameters.ProtoReflect.Descriptor instead.
func (*AdagradParameters) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{4}
}

// This optimizer combines the Adagrad and Momentum update rules.
// accum(new) = beta2 == 1.0 ?
//
//	accum(old) + grad^2 :
//	beta2 * accum(old) + (1 - beta2) * grad^2
//
// accum_with_exponent = (accum(new) + epsilon)^(-1.0 / exponent)
// mom_accum(new) = momentum * mom_accum(old) + accum_with_exponent
// update = use_nesterov ?
//
//	momentum * mom_accum(new) + accum_with_exponent :
//	mom_accum(new)
//
// var(new) = var(old) - lr * grad * update
// Algorithm described in https://arxiv.org/abs/2002.11803.
type AdagradMomentumParameters struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// Moving average parameter for the momentum accumulator.
	Momentum float32 `protobuf:"fixed32,1,opt,name=momentum,proto3" json:"momentum,omitempty"`
	// Whether to use the Nesterov variant of momentum.
	UseNesterov bool `protobuf:"varint,2,opt,name=use_nesterov,json=useNesterov,proto3" json:"use_nesterov,omitempty"`
	// Exponent for the gradient^2 accumulator.
	Exponent float32 `protobuf:"fixed32,3,opt,name=exponent,proto3" json:"exponent,omitempty"`
	// Moving average parameter for the gradient^2 accumulator.
	Beta2 float32 `protobuf:"fixed32,4,opt,name=beta2,proto3" json:"beta2,omitempty"`
	// Offset added to the Adagrad accumulator.
	Epsilon float32 `protobuf:"fixed32,5,opt,name=epsilon,proto3" json:"epsilon,omitempty"`
}

func (x *AdagradMomentumParameters) Reset() {
	*x = AdagradMomentumParameters{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[5]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *AdagradMomentumParameters) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AdagradMomentumParameters) ProtoMessage() {}

func (x *AdagradMomentumParameters) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[5]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AdagradMomentumParameters.ProtoReflect.Descriptor instead.
func (*AdagradMomentumParameters) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{5}
}

func (x *AdagradMomentumParameters) GetMomentum() float32 {
	if x != nil {
		return x.Momentum
	}
	return 0
}

func (x *AdagradMomentumParameters) GetUseNesterov() bool {
	if x != nil {
		return x.UseNesterov
	}
	return false
}

func (x *AdagradMomentumParameters) GetExponent() float32 {
	if x != nil {
		return x.Exponent
	}
	return 0
}

func (x *AdagradMomentumParameters) GetBeta2() float32 {
	if x != nil {
		return x.Beta2
	}
	return 0
}

func (x *AdagradMomentumParameters) GetEpsilon() float32 {
	if x != nil {
		return x.Epsilon
	}
	return 0
}

// Algorithm in http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf.
type BoundedAdagradParameters struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// Whether to use the updated or the old value of the accumulator when
	// computing the effective learning rate. When update_accumulator_first is set
	// to True, the updated value of the accumulator is used.
	UpdateAccumulatorFirst bool `protobuf:"varint,1,opt,name=update_accumulator_first,json=updateAccumulatorFirst,proto3" json:"update_accumulator_first,omitempty"`
	// The max_var_update value to use. Set value to 0 (default) to disable using
	// max_var_update to clip the gradient.
	MaxVarUpdate float32 `protobuf:"fixed32,2,opt,name=max_var_update,json=maxVarUpdate,proto3" json:"max_var_update,omitempty"`
	// The maximum value of the accumulator. Set max_accumulator to 0 (default)
	// to disable using max_accumulator to clip the accumulator.
	MaxAccumulator float32 `protobuf:"fixed32,3,opt,name=max_accumulator,json=maxAccumulator,proto3" json:"max_accumulator,omitempty"`
}

func (x *BoundedAdagradParameters) Reset() {
	*x = BoundedAdagradParameters{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[6]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *BoundedAdagradParameters) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*BoundedAdagradParameters) ProtoMessage() {}

func (x *BoundedAdagradParameters) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[6]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use BoundedAdagradParameters.ProtoReflect.Descriptor instead.
func (*BoundedAdagradParameters) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{6}
}

func (x *BoundedAdagradParameters) GetUpdateAccumulatorFirst() bool {
	if x != nil {
		return x.UpdateAccumulatorFirst
	}
	return false
}

func (x *BoundedAdagradParameters) GetMaxVarUpdate() float32 {
	if x != nil {
		return x.MaxVarUpdate
	}
	return 0
}

func (x *BoundedAdagradParameters) GetMaxAccumulator() float32 {
	if x != nil {
		return x.MaxAccumulator
	}
	return 0
}

// https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD
// https://github.com/tensorflow/tensorflow/blob/6b6471f3ffb7f1fefe42d814aa5fb9ab7a535b58/tensorflow/core/kernels/training_ops.cc#L629
type StochasticGradientDescentParameters struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields
}

func (x *StochasticGradientDescentParameters) Reset() {
	*x = StochasticGradientDescentParameters{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[7]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *StochasticGradientDescentParameters) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StochasticGradientDescentParameters) ProtoMessage() {}

func (x *StochasticGradientDescentParameters) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[7]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StochasticGradientDescentParameters.ProtoReflect.Descriptor instead.
func (*StochasticGradientDescentParameters) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{7}
}

// https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Ftrl
// https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41159.pdf
// https://github.com/tensorflow/tensorflow/blob/6b6471f3ffb7f1fefe42d814aa5fb9ab7a535b58/tensorflow/core/kernels/training_ops.cc#L2646
//
// The hyperparameters for FTRL are the same as for the Keras implementation,
// with some additions. The "beta" parameter matches the behavior described in
// the second link above; "beta" / (2 * learning rate) should be added to "l2"
// to get equivalent behavior in the other TensorFlow implementations of this
// optimizer. When the multiply_linear_by_lr field is set to true, a modified
// formula is used for FTRL that treats the "linear" accumulator as being
// pre-multiplied by the learning rate (i.e., the accumulator named "linear"
// actually stores "linear * learning_rate"). Other than checkpoint
// compatibility, this is mathematically equivalent for a static learning rate;
// for a dynamic learning rate, it is nearly the same as long as the learning
// rate does not change quickly. The benefit of setting multiply_linear_by_lr to
// true is that the modified formula handles zero and near-zero learning rates
// without producing NaNs, improving flexibility for learning rate ramp-up.
type FtrlParameters struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	L1                 float32 `protobuf:"fixed32,1,opt,name=l1,proto3" json:"l1,omitempty"`
	L2                 float32 `protobuf:"fixed32,2,opt,name=l2,proto3" json:"l2,omitempty"`
	LrPower            float32 `protobuf:"fixed32,3,opt,name=lr_power,json=lrPower,proto3" json:"lr_power,omitempty"`
	Beta               float32 `protobuf:"fixed32,7,opt,name=beta,proto3" json:"beta,omitempty"`
	MultiplyLinearByLr bool    `protobuf:"varint,6,opt,name=multiply_linear_by_lr,json=multiplyLinearByLr,proto3" json:"multiply_linear_by_lr,omitempty"`
	// Previously, allow_zero_accumulator parameter changed some internal formulas
	// to allow zero and near-zero accumulator values at the cost of some
	// performance. The current implementation ignores this parameter; zero or
	// near-zero accumulator values are now always supported.
	//
	// Deprecated: Do not use.
	AllowZeroAccumulator bool `protobuf:"varint,8,opt,name=allow_zero_accumulator,json=allowZeroAccumulator,proto3" json:"allow_zero_accumulator,omitempty"`
}

func (x *FtrlParameters) Reset() {
	*x = FtrlParameters{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[8]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *FtrlParameters) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*FtrlParameters) ProtoMessage() {}

func (x *FtrlParameters) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[8]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use FtrlParameters.ProtoReflect.Descriptor instead.
func (*FtrlParameters) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{8}
}

func (x *FtrlParameters) GetL1() float32 {
	if x != nil {
		return x.L1
	}
	return 0
}

func (x *FtrlParameters) GetL2() float32 {
	if x != nil {
		return x.L2
	}
	return 0
}

func (x *FtrlParameters) GetLrPower() float32 {
	if x != nil {
		return x.LrPower
	}
	return 0
}

func (x *FtrlParameters) GetBeta() float32 {
	if x != nil {
		return x.Beta
	}
	return 0
}

func (x *FtrlParameters) GetMultiplyLinearByLr() bool {
	if x != nil {
		return x.MultiplyLinearByLr
	}
	return false
}

// Deprecated: Do not use.
func (x *FtrlParameters) GetAllowZeroAccumulator() bool {
	if x != nil {
		return x.AllowZeroAccumulator
	}
	return false
}

// The Adam optimizer does not implement hyper-parameter update due to hardware
// limitations; use the dynamic learning rate feature instead, setting the
// learning rate to: user learning_rate * sqrt(1 - beta2^t) / (1 - beta1^t)
// Here, t is the current timestep.
//
// https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam
// https://github.com/tensorflow/tensorflow/blob/ab51450c817674c8ff08a7ae4f8ac50cdc4bed8b/tensorflow/python/training/adam.py#L32
//
// Note that the code by default implements the lazy version of Adam
// (https://www.tensorflow.org/api_docs/python/tf/contrib/opt/LazyAdamOptimizer)
// unless the use_non_lazy_adam parameter is set, in which case it implements
// the normal version of Adam that updates all parameters in the embedding
// table, even for entries that are not used in the current minibatch
// (https://www.tensorflow.org/api_docs/python/tf/contrib/opt/AdamOptimizer). If
// use_non_lazy_adam is enabled, gradient accumulation is also required to be
// enabled in order to get correct results; a warning will be printed otherwise
// (which may change to an error in the future). If use_sum_inside_sqrt is set,
// the Adam variable update formula will be changed from m / (sqrt(v) + epsilon)
// to m / sqrt(v + epsilon**2); this option improves the performance of TPU
// training and is not expected to harm model quality.
type AdamParameters struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	Beta1            float32 `protobuf:"fixed32,3,opt,name=beta1,proto3" json:"beta1,omitempty"`
	Beta2            float32 `protobuf:"fixed32,4,opt,name=beta2,proto3" json:"beta2,omitempty"`
	Epsilon          float32 `protobuf:"fixed32,5,opt,name=epsilon,proto3" json:"epsilon,omitempty"`
	UseNonLazyAdam   bool    `protobuf:"varint,8,opt,name=use_non_lazy_adam,json=useNonLazyAdam,proto3" json:"use_non_lazy_adam,omitempty"`
	UseSumInsideSqrt bool    `protobuf:"varint,10,opt,name=use_sum_inside_sqrt,json=useSumInsideSqrt,proto3" json:"use_sum_inside_sqrt,omitempty"`
}

func (x *AdamParameters) Reset() {
	*x = AdamParameters{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[9]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *AdamParameters) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AdamParameters) ProtoMessage() {}

func (x *AdamParameters) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[9]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AdamParameters.ProtoReflect.Descriptor instead.
func (*AdamParameters) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{9}
}

func (x *AdamParameters) GetBeta1() float32 {
	if x != nil {
		return x.Beta1
	}
	return 0
}

func (x *AdamParameters) GetBeta2() float32 {
	if x != nil {
		return x.Beta2
	}
	return 0
}

func (x *AdamParameters) GetEpsilon() float32 {
	if x != nil {
		return x.Epsilon
	}
	return 0
}

func (x *AdamParameters) GetUseNonLazyAdam() bool {
	if x != nil {
		return x.UseNonLazyAdam
	}
	return false
}

func (x *AdamParameters) GetUseSumInsideSqrt() bool {
	if x != nil {
		return x.UseSumInsideSqrt
	}
	return false
}

// https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD
// https://github.com/tensorflow/tensorflow/blob/6b6471f3ffb7f1fefe42d814aa5fb9ab7a535b58/tensorflow/core/kernels/training_ops.cc#L3068
type MomentumParameters struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	Momentum    float32 `protobuf:"fixed32,1,opt,name=momentum,proto3" json:"momentum,omitempty"`
	UseNesterov bool    `protobuf:"varint,2,opt,name=use_nesterov,json=useNesterov,proto3" json:"use_nesterov,omitempty"`
}

func (x *MomentumParameters) Reset() {
	*x = MomentumParameters{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[10]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *MomentumParameters) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*MomentumParameters) ProtoMessage() {}

func (x *MomentumParameters) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[10]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use MomentumParameters.ProtoReflect.Descriptor instead.
func (*MomentumParameters) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{10}
}

func (x *MomentumParameters) GetMomentum() float32 {
	if x != nil {
		return x.Momentum
	}
	return 0
}

func (x *MomentumParameters) GetUseNesterov() bool {
	if x != nil {
		return x.UseNesterov
	}
	return false
}

// https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/RMSprop
// https://github.com/tensorflow/tensorflow/blob/6b6471f3ffb7f1fefe42d814aa5fb9ab7a535b58/tensorflow/core/kernels/training_ops.cc#L4229
type RmsPropParameters struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	Rho      float32 `protobuf:"fixed32,1,opt,name=rho,proto3" json:"rho,omitempty"`
	Momentum float32 `protobuf:"fixed32,2,opt,name=momentum,proto3" json:"momentum,omitempty"`
	Epsilon  float32 `protobuf:"fixed32,3,opt,name=epsilon,proto3" json:"epsilon,omitempty"`
}

func (x *RmsPropParameters) Reset() {
	*x = RmsPropParameters{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[11]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *RmsPropParameters) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RmsPropParameters) ProtoMessage() {}

func (x *RmsPropParameters) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[11]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RmsPropParameters.ProtoReflect.Descriptor instead.
func (*RmsPropParameters) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{11}
}

func (x *RmsPropParameters) GetRho() float32 {
	if x != nil {
		return x.Rho
	}
	return 0
}

func (x *RmsPropParameters) GetMomentum() float32 {
	if x != nil {
		return x.Momentum
	}
	return 0
}

func (x *RmsPropParameters) GetEpsilon() float32 {
	if x != nil {
		return x.Epsilon
	}
	return 0
}

// https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/RMSprop
// https://github.com/tensorflow/tensorflow/blob/6b6471f3ffb7f1fefe42d814aa5fb9ab7a535b58/tensorflow/core/kernels/training_ops.cc#L4358
type CenteredRmsPropParameters struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	Rho      float32 `protobuf:"fixed32,1,opt,name=rho,proto3" json:"rho,omitempty"`
	Momentum float32 `protobuf:"fixed32,2,opt,name=momentum,proto3" json:"momentum,omitempty"`
	Epsilon  float32 `protobuf:"fixed32,3,opt,name=epsilon,proto3" json:"epsilon,omitempty"`
}

func (x *CenteredRmsPropParameters) Reset() {
	*x = CenteredRmsPropParameters{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[12]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *CenteredRmsPropParameters) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CenteredRmsPropParameters) ProtoMessage() {}

func (x *CenteredRmsPropParameters) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[12]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CenteredRmsPropParameters.ProtoReflect.Descriptor instead.
func (*CenteredRmsPropParameters) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{12}
}

func (x *CenteredRmsPropParameters) GetRho() float32 {
	if x != nil {
		return x.Rho
	}
	return 0
}

func (x *CenteredRmsPropParameters) GetMomentum() float32 {
	if x != nil {
		return x.Momentum
	}
	return 0
}

func (x *CenteredRmsPropParameters) GetEpsilon() float32 {
	if x != nil {
		return x.Epsilon
	}
	return 0
}

// Variant of algorithm in http://proceedings.mlr.press/v44/shamir15.pdf
type MdlAdagradLightParameters struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	L2                    float32 `protobuf:"fixed32,1,opt,name=l2,proto3" json:"l2,omitempty"`
	LrPower               float32 `protobuf:"fixed32,2,opt,name=lr_power,json=lrPower,proto3" json:"lr_power,omitempty"`
	MinServableMdlBenefit float32 `protobuf:"fixed32,3,opt,name=min_servable_mdl_benefit,json=minServableMdlBenefit,proto3" json:"min_servable_mdl_benefit,omitempty"`
	MdlMixInMargin        float32 `protobuf:"fixed32,4,opt,name=mdl_mix_in_margin,json=mdlMixInMargin,proto3" json:"mdl_mix_in_margin,omitempty"`
	MdlBenefitRampupCoeff float32 `protobuf:"fixed32,5,opt,name=mdl_benefit_rampup_coeff,json=mdlBenefitRampupCoeff,proto3" json:"mdl_benefit_rampup_coeff,omitempty"`
	MdlMinWeight          float32 `protobuf:"fixed32,6,opt,name=mdl_min_weight,json=mdlMinWeight,proto3" json:"mdl_min_weight,omitempty"`
	BenefitRevisitScale   float32 `protobuf:"fixed32,7,opt,name=benefit_revisit_scale,json=benefitRevisitScale,proto3" json:"benefit_revisit_scale,omitempty"`
	MaxEventBenefit       float32 `protobuf:"fixed32,8,opt,name=max_event_benefit,json=maxEventBenefit,proto3" json:"max_event_benefit,omitempty"`
	MaxTotalBenefit       float32 `protobuf:"fixed32,9,opt,name=max_total_benefit,json=maxTotalBenefit,proto3" json:"max_total_benefit,omitempty"`
	MdlHardLimit          float32 `protobuf:"fixed32,10,opt,name=mdl_hard_limit,json=mdlHardLimit,proto3" json:"mdl_hard_limit,omitempty"`
	HardLimitMinBenefit   bool    `protobuf:"varint,11,opt,name=hard_limit_min_benefit,json=hardLimitMinBenefit,proto3" json:"hard_limit_min_benefit,omitempty"`
	MdlRegularize         bool    `protobuf:"varint,12,opt,name=mdl_regularize,json=mdlRegularize,proto3" json:"mdl_regularize,omitempty"`
}

func (x *MdlAdagradLightParameters) Reset() {
	*x = MdlAdagradLightParameters{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[13]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *MdlAdagradLightParameters) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*MdlAdagradLightParameters) ProtoMessage() {}

func (x *MdlAdagradLightParameters) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[13]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use MdlAdagradLightParameters.ProtoReflect.Descriptor instead.
func (*MdlAdagradLightParameters) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{13}
}

func (x *MdlAdagradLightParameters) GetL2() float32 {
	if x != nil {
		return x.L2
	}
	return 0
}

func (x *MdlAdagradLightParameters) GetLrPower() float32 {
	if x != nil {
		return x.LrPower
	}
	return 0
}

func (x *MdlAdagradLightParameters) GetMinServableMdlBenefit() float32 {
	if x != nil {
		return x.MinServableMdlBenefit
	}
	return 0
}

func (x *MdlAdagradLightParameters) GetMdlMixInMargin() float32 {
	if x != nil {
		return x.MdlMixInMargin
	}
	return 0
}

func (x *MdlAdagradLightParameters) GetMdlBenefitRampupCoeff() float32 {
	if x != nil {
		return x.MdlBenefitRampupCoeff
	}
	return 0
}

func (x *MdlAdagradLightParameters) GetMdlMinWeight() float32 {
	if x != nil {
		return x.MdlMinWeight
	}
	return 0
}

func (x *MdlAdagradLightParameters) GetBenefitRevisitScale() float32 {
	if x != nil {
		return x.BenefitRevisitScale
	}
	return 0
}

func (x *MdlAdagradLightParameters) GetMaxEventBenefit() float32 {
	if x != nil {
		return x.MaxEventBenefit
	}
	return 0
}

func (x *MdlAdagradLightParameters) GetMaxTotalBenefit() float32 {
	if x != nil {
		return x.MaxTotalBenefit
	}
	return 0
}

func (x *MdlAdagradLightParameters) GetMdlHardLimit() float32 {
	if x != nil {
		return x.MdlHardLimit
	}
	return 0
}

func (x *MdlAdagradLightParameters) GetHardLimitMinBenefit() bool {
	if x != nil {
		return x.HardLimitMinBenefit
	}
	return false
}

func (x *MdlAdagradLightParameters) GetMdlRegularize() bool {
	if x != nil {
		return x.MdlRegularize
	}
	return false
}

// https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adadelta
// https://github.com/tensorflow/tensorflow/blob/6b6471f3ffb7f1fefe42d814aa5fb9ab7a535b58/tensorflow/core/kernels/training_ops.cc#L933
type AdadeltaParameters struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	Rho     float32 `protobuf:"fixed32,1,opt,name=rho,proto3" json:"rho,omitempty"`
	Epsilon float32 `protobuf:"fixed32,2,opt,name=epsilon,proto3" json:"epsilon,omitempty"`
}

func (x *AdadeltaParameters) Reset() {
	*x = AdadeltaParameters{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[14]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *AdadeltaParameters) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AdadeltaParameters) ProtoMessage() {}

func (x *AdadeltaParameters) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[14]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AdadeltaParameters.ProtoReflect.Descriptor instead.
func (*AdadeltaParameters) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{14}
}

func (x *AdadeltaParameters) GetRho() float32 {
	if x != nil {
		return x.Rho
	}
	return 0
}

func (x *AdadeltaParameters) GetEpsilon() float32 {
	if x != nil {
		return x.Epsilon
	}
	return 0
}

// https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/ProximalAdagradOptimizer
// https://github.com/tensorflow/tensorflow/blob/6b6471f3ffb7f1fefe42d814aa5fb9ab7a535b58/tensorflow/core/kernels/training_ops.cc#L1961
type ProximalAdagradParameters struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	L1 float32 `protobuf:"fixed32,1,opt,name=l1,proto3" json:"l1,omitempty"`
	L2 float32 `protobuf:"fixed32,2,opt,name=l2,proto3" json:"l2,omitempty"`
}

func (x *ProximalAdagradParameters) Reset() {
	*x = ProximalAdagradParameters{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[15]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *ProximalAdagradParameters) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ProximalAdagradParameters) ProtoMessage() {}

func (x *ProximalAdagradParameters) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[15]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ProximalAdagradParameters.ProtoReflect.Descriptor instead.
func (*ProximalAdagradParameters) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{15}
}

func (x *ProximalAdagradParameters) GetL1() float32 {
	if x != nil {
		return x.L1
	}
	return 0
}

func (x *ProximalAdagradParameters) GetL2() float32 {
	if x != nil {
		return x.L2
	}
	return 0
}

// The online Yogi optimizer does not implement hyper-parameter update; use the
// dynamic learning rate feature instead, setting the learning rate to:
// user learning_rate * sqrt(1 - beta2^t) / (1 - beta1^t)
// Here, t is the current timestep.
//
// https://papers.nips.cc/paper/8186-adaptive-methods-for-nonconvex-optimization.pdf
// plus some extensions based on FTRL.
//
// Note that the code by default implements the lazy version of online Yogi.
type OnlineYogiParameters struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// The L1 regularization parameter (used analogously to the one in FTRL).
	L1 float32 `protobuf:"fixed32,1,opt,name=l1,proto3" json:"l1,omitempty"`
	// The L2 regularization parameter (used analogously to the one in FTRL).
	L2 float32 `protobuf:"fixed32,2,opt,name=l2,proto3" json:"l2,omitempty"`
	// \beta_2 from Algorithm 2 in the paper.
	Beta2 float32 `protobuf:"fixed32,3,opt,name=beta2,proto3" json:"beta2,omitempty"`
}

func (x *OnlineYogiParameters) Reset() {
	*x = OnlineYogiParameters{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[16]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *OnlineYogiParameters) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*OnlineYogiParameters) ProtoMessage() {}

func (x *OnlineYogiParameters) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[16]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use OnlineYogiParameters.ProtoReflect.Descriptor instead.
func (*OnlineYogiParameters) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{16}
}

func (x *OnlineYogiParameters) GetL1() float32 {
	if x != nil {
		return x.L1
	}
	return 0
}

func (x *OnlineYogiParameters) GetL2() float32 {
	if x != nil {
		return x.L2
	}
	return 0
}

func (x *OnlineYogiParameters) GetBeta2() float32 {
	if x != nil {
		return x.Beta2
	}
	return 0
}

// The online Yogi optimizer does not implement hyper-parameter update; use the
// dynamic learning rate feature instead, setting the learning rate to:
// user learning_rate * sqrt(1 - beta2^t) / (1 - beta1^t)
// Here, t is the current timestep.
//
// https://papers.nips.cc/paper/8186-adaptive-methods-for-nonconvex-optimization.pdf
// plus some extensions based on FTRL.
//
// Note that the code by default implements the lazy version of proximal Yogi.
type ProximalYogiParameters struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// The L1 regularization parameter.
	L1 float32 `protobuf:"fixed32,1,opt,name=l1,proto3" json:"l1,omitempty"`
	// The L2 regularization parameter.
	L2 float32 `protobuf:"fixed32,2,opt,name=l2,proto3" json:"l2,omitempty"`
	// The exponential decay rate for the 1st moment estimates.
	Beta1 float32 `protobuf:"fixed32,3,opt,name=beta1,proto3" json:"beta1,omitempty"`
	// The exponential decay rate for the 2nd moment estimates.
	Beta2 float32 `protobuf:"fixed32,4,opt,name=beta2,proto3" json:"beta2,omitempty"`
	// A constant trading off adaptivity and noise.
	Epsilon float32 `protobuf:"fixed32,5,opt,name=epsilon,proto3" json:"epsilon,omitempty"`
}

func (x *ProximalYogiParameters) Reset() {
	*x = ProximalYogiParameters{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[17]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *ProximalYogiParameters) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ProximalYogiParameters) ProtoMessage() {}

func (x *ProximalYogiParameters) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[17]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ProximalYogiParameters.ProtoReflect.Descriptor instead.
func (*ProximalYogiParameters) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{17}
}

func (x *ProximalYogiParameters) GetL1() float32 {
	if x != nil {
		return x.L1
	}
	return 0
}

func (x *ProximalYogiParameters) GetL2() float32 {
	if x != nil {
		return x.L2
	}
	return 0
}

func (x *ProximalYogiParameters) GetBeta1() float32 {
	if x != nil {
		return x.Beta1
	}
	return 0
}

func (x *ProximalYogiParameters) GetBeta2() float32 {
	if x != nil {
		return x.Beta2
	}
	return 0
}

func (x *ProximalYogiParameters) GetEpsilon() float32 {
	if x != nil {
		return x.Epsilon
	}
	return 0
}

// Estimator for the frequency of updates to a lookup table. It maintains an
// array (tf.Variable) D, where each element records the average number of
// global steps between two consecutive batches that hit the corresponding
// bucket. Once an item with bucket id i is sampled, D[i] is updated by:
//
//	D[i] <- D[i] * (1 - tau) + delta[i] * tau,
//
// where tau is a learning rate between 0 and 1 (exclusive), and
//
//	delta[i] = current global step - last step i is sampled.
//
// The estimated frequency (sampling rate in a batch) is thus 1 / D[i].
//
// Elements in D are initialized with a large value max_delta. delta[i] will
// also be capped by this value.
//
// The exact sequence of operations used in the optimizer is shown below.
// last_hit_step[i] is a tf.Variable that holds the last global step at which i
// was sampled.
//
//	delta = global_step - last_hit_step[i]
//	clipped_delta = min(delta, params.max_delta)
//	is_outlier = (delta >= params.outlier_threshold * D[i])
//	D[i] <- is_outlier ? clipped_delta
//	                   : D[i] * (1 - params.tau) + clipped_delta * params.tau
//	last_hit_step[i] <- global_step
type FrequencyEstimatorParameters struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// Learning rate between (0, 1) that is used to update the array D.
	Tau float32 `protobuf:"fixed32,1,opt,name=tau,proto3" json:"tau,omitempty"`
	// Maximum value of delta: difference between the current global step and the
	// last global step at which the row was sampled.
	MaxDelta float32 `protobuf:"fixed32,2,opt,name=max_delta,json=maxDelta,proto3" json:"max_delta,omitempty"`
	// Threshold used to determine whether the current update is an outlier.
	OutlierThreshold float32 `protobuf:"fixed32,3,opt,name=outlier_threshold,json=outlierThreshold,proto3" json:"outlier_threshold,omitempty"`
	// The weight exponent used to transform the estimated delta into weights.
	// The transformation function is: (delta / max_delta) ^ (weight_exponent)
	WeightExponent float32 `protobuf:"fixed32,4,opt,name=weight_exponent,json=weightExponent,proto3" json:"weight_exponent,omitempty"`
}

func (x *FrequencyEstimatorParameters) Reset() {
	*x = FrequencyEstimatorParameters{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[18]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *FrequencyEstimatorParameters) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*FrequencyEstimatorParameters) ProtoMessage() {}

func (x *FrequencyEstimatorParameters) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[18]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use FrequencyEstimatorParameters.ProtoReflect.Descriptor instead.
func (*FrequencyEstimatorParameters) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{18}
}

func (x *FrequencyEstimatorParameters) GetTau() float32 {
	if x != nil {
		return x.Tau
	}
	return 0
}

func (x *FrequencyEstimatorParameters) GetMaxDelta() float32 {
	if x != nil {
		return x.MaxDelta
	}
	return 0
}

func (x *FrequencyEstimatorParameters) GetOutlierThreshold() float32 {
	if x != nil {
		return x.OutlierThreshold
	}
	return 0
}

func (x *FrequencyEstimatorParameters) GetWeightExponent() float32 {
	if x != nil {
		return x.WeightExponent
	}
	return 0
}

// A user-defined optimizer.
// The contained HLO program must take the following arguments in the following
// order:
//  1. gradients
//  2. table weights
//  3. slot variables
//  4. an optional scalar input that is passed in via the dynamic learning
//     rate mechanism.
//
// It must return/end in a tuple op that contains the following values in the
// following order:
// 1.  new table values
// 2.  new slot variable value
//
// The program must have shape (1,1) with dtype float32 throughout and only use
// HLO that operate elementwise (e.g., no reduce, no variables, no control flow
// and no broadcasting outside of the single scalar input).
// The HLO program should be written as if it were a dense update. It will be
// called on each row that needs an update and will applied elementwise.
type UserDefinedProgramParameters struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	Program *service.HloModuleProto `protobuf:"bytes,1,opt,name=program,proto3" json:"program,omitempty"`
}

func (x *UserDefinedProgramParameters) Reset() {
	*x = UserDefinedProgramParameters{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[19]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *UserDefinedProgramParameters) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UserDefinedProgramParameters) ProtoMessage() {}

func (x *UserDefinedProgramParameters) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[19]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UserDefinedProgramParameters.ProtoReflect.Descriptor instead.
func (*UserDefinedProgramParameters) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{19}
}

func (x *UserDefinedProgramParameters) GetProgram() *service.HloModuleProto {
	if x != nil {
		return x.Program
	}
	return nil
}

// Optimizer that just sets the variable to the value of the gradient. To be
// correct, this requires either gradient accumulation (to sum the values of a
// computed expression across the samples) or to deduplicate IDs within a single
// host (to assign the value from an arbitrary sample).
type AssignParameters struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields
}

func (x *AssignParameters) Reset() {
	*x = AssignParameters{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[20]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *AssignParameters) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AssignParameters) ProtoMessage() {}

func (x *AssignParameters) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[20]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AssignParameters.ProtoReflect.Descriptor instead.
func (*AssignParameters) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{20}
}

// Status of using gradient accumulation (doing two passes over the input
// gradients: one to accumulate them into a temporary array and another to apply
// them using the actual optimization algorithm). The extra message is to wrap
// the enum for scoping.
type GradientAccumulationStatus struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields
}

func (x *GradientAccumulationStatus) Reset() {
	*x = GradientAccumulationStatus{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[21]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *GradientAccumulationStatus) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GradientAccumulationStatus) ProtoMessage() {}

func (x *GradientAccumulationStatus) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[21]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GradientAccumulationStatus.ProtoReflect.Descriptor instead.
func (*GradientAccumulationStatus) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{21}
}

// There is one important limitation for this HBM packing though. When only a
// subset of rows in an 8-float chunk are accessed on a particular step, the
// adjoining rows in the same chunk are updated with zero gradients on the
// backward pass even if they are not touched. This is an artifact of the
// packing implementation. This operation is NOT functionally correct for
// optimizers where zero gradients change the embeddings/slot-variable values,
// e.g., momentum-based optimizers. Hence, this HBM packing cannot be enabled
// for embedding tables with such optimizers. The TPU software automatically
// recognizes that a zero gradient can modify state and turns off the low
// dimensional embedding packing in that scenario.
//
// However, for optimizers where a zero gradient is a NoOp, such as SGD,
// Adagrad, and FTRL, this packing optimization can be used. However, there are
// some important considerations:
//   - Clipping limits: The initial values for such embeddings should fall within
//     the clipping limits specified in the optimization parameters. Otherwise, a
//     zero gradient will cause the embeddings to be clipped. This changes state
//     and hence, is not a NoOp.
//   - FTRL: The embedding vector is computed directly from the values of the
//     accumulator and linear slot variables. Hence, the initial embedding values
//     should match that computed from the initial values of the accumulator and
//     linear slot variables. Note that in nearly all cases, the linear value is
//     initialized to zero; this corresponds to an embedding value of zero.
//
// Performance: The TPU has to perform additional work when low dimensional
// packing is enabled. In certain situations when the vocabulary size is small,
// it may not make sense to turn on this packing since the total memory usage
// due to padding is extremely low. Hence, the TPU software automatically turns
// off the packing optimization in such scenarios.
type LowDimensionalPackingStatus struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields
}

func (x *LowDimensionalPackingStatus) Reset() {
	*x = LowDimensionalPackingStatus{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[22]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *LowDimensionalPackingStatus) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LowDimensionalPackingStatus) ProtoMessage() {}

func (x *LowDimensionalPackingStatus) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[22]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LowDimensionalPackingStatus.ProtoReflect.Descriptor instead.
func (*LowDimensionalPackingStatus) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{22}
}

// Configuration proto for hot ID optimization. This is an experimental feature
// that is currently disabled (by default).
type HotIdReplicationConfiguration struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	Status HotIdReplicationConfiguration_Status `protobuf:"varint,1,opt,name=status,proto3,enum=tensorflow.tpu.HotIdReplicationConfiguration_Status" json:"status,omitempty"`
}

func (x *HotIdReplicationConfiguration) Reset() {
	*x = HotIdReplicationConfiguration{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[23]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *HotIdReplicationConfiguration) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*HotIdReplicationConfiguration) ProtoMessage() {}

func (x *HotIdReplicationConfiguration) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[23]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use HotIdReplicationConfiguration.ProtoReflect.Descriptor instead.
func (*HotIdReplicationConfiguration) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{23}
}

func (x *HotIdReplicationConfiguration) GetStatus() HotIdReplicationConfiguration_Status {
	if x != nil {
		return x.Status
	}
	return HotIdReplicationConfiguration_UNSPECIFIED
}

type OptimizationParameters struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// Learning rate used for updating the embedding layer parameters.
	LearningRate *LearningRate `protobuf:"bytes,13,opt,name=learning_rate,json=learningRate,proto3" json:"learning_rate,omitempty"`
	// Limits to which to clip the weight values after the backward pass; not
	// present means no limits are applied.
	ClippingLimits *ClippingLimits `protobuf:"bytes,2,opt,name=clipping_limits,json=clippingLimits,proto3" json:"clipping_limits,omitempty"`
	// Limits to which to clip the backward pass gradient before using it for
	// updates; not present means no limits are applied.
	GradientClippingLimits *ClippingLimits `protobuf:"bytes,7,opt,name=gradient_clipping_limits,json=gradientClippingLimits,proto3" json:"gradient_clipping_limits,omitempty"`
	// Amount of weight decay to apply; see weight_decay_optimizers.py for
	// details. All optimizers except MDL Adagrad Light are supported with this
	// option. Although there is no check, users who want weight decay will also
	// want to ensure that gradient accumulation is enabled so that the decay will
	// happen once per global batch.
	WeightDecayFactor float32 `protobuf:"fixed32,16,opt,name=weight_decay_factor,json=weightDecayFactor,proto3" json:"weight_decay_factor,omitempty"`
	// If true, the weight decay factor is multiplied by the current learning rate
	// before use; this is to match the note in DecoupledWeightDecayExtension in
	// weight_decay_optimizers.py.
	MultiplyWeightDecayFactorByLearningRate bool `protobuf:"varint,22,opt,name=multiply_weight_decay_factor_by_learning_rate,json=multiplyWeightDecayFactorByLearningRate,proto3" json:"multiply_weight_decay_factor_by_learning_rate,omitempty"`
	// Configuration for simulated quantization which is used to reduce
	// training/serving skew when the serving variables are quantized. The same
	// quantization operations are executed during training to minimize
	// differences with serving.
	SimulatedQuantization *SimulatedQuantization `protobuf:"bytes,27,opt,name=simulated_quantization,json=simulatedQuantization,proto3" json:"simulated_quantization,omitempty"`
	// Status of using gradient accumulation (doing two passes over the input
	// gradients: one to accumulate them into a temporary array and another to
	// apply them using the actual optimization algorithm).
	GradientAccumulationStatus GradientAccumulationStatus_Status `protobuf:"varint,17,opt,name=gradient_accumulation_status,json=gradientAccumulationStatus,proto3,enum=tensorflow.tpu.GradientAccumulationStatus_Status" json:"gradient_accumulation_status,omitempty"`
	// Status of the low-dimensional embedding packing optimization. This controls
	// whether to optimize the packing of 1-dimensional, 2-dimensional, and
	// 4-dimensional embedding tables in memory.
	LowDimensionalPackingStatus LowDimensionalPackingStatus_Status `protobuf:"varint,28,opt,name=low_dimensional_packing_status,json=lowDimensionalPackingStatus,proto3,enum=tensorflow.tpu.LowDimensionalPackingStatus_Status" json:"low_dimensional_packing_status,omitempty"`
	// Configuration proto for hot ID replication. This is an experimental
	// feature that is currently disabled (by default).
	HotIdReplicationConfiguration *HotIdReplicationConfiguration `protobuf:"bytes,18,opt,name=hot_id_replication_configuration,json=hotIdReplicationConfiguration,proto3" json:"hot_id_replication_configuration,omitempty"`
	// Optimization algorithm parameters; which field is selected determines which
	// algorithm to use.
	//
	// Types that are assignable to Parameters:
	//
	//	*OptimizationParameters_Adagrad
	//	*OptimizationParameters_AdagradMomentum
	//	*OptimizationParameters_BoundedAdagrad
	//	*OptimizationParameters_StochasticGradientDescent
	//	*OptimizationParameters_Ftrl
	//	*OptimizationParameters_Adam
	//	*OptimizationParameters_Momentum
	//	*OptimizationParameters_RmsProp
	//	*OptimizationParameters_CenteredRmsProp
	//	*OptimizationParameters_MdlAdagradLight
	//	*OptimizationParameters_Adadelta
	//	*OptimizationParameters_ProximalAdagrad
	//	*OptimizationParameters_OnlineYogi
	//	*OptimizationParameters_ProximalYogi
	//	*OptimizationParameters_FrequencyEstimator
	//	*OptimizationParameters_UserDefinedProgram
	//	*OptimizationParameters_Assign
	Parameters isOptimizationParameters_Parameters `protobuf_oneof:"parameters"`
}

func (x *OptimizationParameters) Reset() {
	*x = OptimizationParameters{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[24]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *OptimizationParameters) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*OptimizationParameters) ProtoMessage() {}

func (x *OptimizationParameters) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[24]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use OptimizationParameters.ProtoReflect.Descriptor instead.
func (*OptimizationParameters) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{24}
}

func (x *OptimizationParameters) GetLearningRate() *LearningRate {
	if x != nil {
		return x.LearningRate
	}
	return nil
}

func (x *OptimizationParameters) GetClippingLimits() *ClippingLimits {
	if x != nil {
		return x.ClippingLimits
	}
	return nil
}

func (x *OptimizationParameters) GetGradientClippingLimits() *ClippingLimits {
	if x != nil {
		return x.GradientClippingLimits
	}
	return nil
}

func (x *OptimizationParameters) GetWeightDecayFactor() float32 {
	if x != nil {
		return x.WeightDecayFactor
	}
	return 0
}

func (x *OptimizationParameters) GetMultiplyWeightDecayFactorByLearningRate() bool {
	if x != nil {
		return x.MultiplyWeightDecayFactorByLearningRate
	}
	return false
}

func (x *OptimizationParameters) GetSimulatedQuantization() *SimulatedQuantization {
	if x != nil {
		return x.SimulatedQuantization
	}
	return nil
}

func (x *OptimizationParameters) GetGradientAccumulationStatus() GradientAccumulationStatus_Status {
	if x != nil {
		return x.GradientAccumulationStatus
	}
	return GradientAccumulationStatus_UNSPECIFIED
}

func (x *OptimizationParameters) GetLowDimensionalPackingStatus() LowDimensionalPackingStatus_Status {
	if x != nil {
		return x.LowDimensionalPackingStatus
	}
	return LowDimensionalPackingStatus_UNSPECIFIED
}

func (x *OptimizationParameters) GetHotIdReplicationConfiguration() *HotIdReplicationConfiguration {
	if x != nil {
		return x.HotIdReplicationConfiguration
	}
	return nil
}

func (m *OptimizationParameters) GetParameters() isOptimizationParameters_Parameters {
	if m != nil {
		return m.Parameters
	}
	return nil
}

func (x *OptimizationParameters) GetAdagrad() *AdagradParameters {
	if x, ok := x.GetParameters().(*OptimizationParameters_Adagrad); ok {
		return x.Adagrad
	}
	return nil
}

func (x *OptimizationParameters) GetAdagradMomentum() *AdagradMomentumParameters {
	if x, ok := x.GetParameters().(*OptimizationParameters_AdagradMomentum); ok {
		return x.AdagradMomentum
	}
	return nil
}

func (x *OptimizationParameters) GetBoundedAdagrad() *BoundedAdagradParameters {
	if x, ok := x.GetParameters().(*OptimizationParameters_BoundedAdagrad); ok {
		return x.BoundedAdagrad
	}
	return nil
}

func (x *OptimizationParameters) GetStochasticGradientDescent() *StochasticGradientDescentParameters {
	if x, ok := x.GetParameters().(*OptimizationParameters_StochasticGradientDescent); ok {
		return x.StochasticGradientDescent
	}
	return nil
}

func (x *OptimizationParameters) GetFtrl() *FtrlParameters {
	if x, ok := x.GetParameters().(*OptimizationParameters_Ftrl); ok {
		return x.Ftrl
	}
	return nil
}

func (x *OptimizationParameters) GetAdam() *AdamParameters {
	if x, ok := x.GetParameters().(*OptimizationParameters_Adam); ok {
		return x.Adam
	}
	return nil
}

func (x *OptimizationParameters) GetMomentum() *MomentumParameters {
	if x, ok := x.GetParameters().(*OptimizationParameters_Momentum); ok {
		return x.Momentum
	}
	return nil
}

func (x *OptimizationParameters) GetRmsProp() *RmsPropParameters {
	if x, ok := x.GetParameters().(*OptimizationParameters_RmsProp); ok {
		return x.RmsProp
	}
	return nil
}

func (x *OptimizationParameters) GetCenteredRmsProp() *CenteredRmsPropParameters {
	if x, ok := x.GetParameters().(*OptimizationParameters_CenteredRmsProp); ok {
		return x.CenteredRmsProp
	}
	return nil
}

func (x *OptimizationParameters) GetMdlAdagradLight() *MdlAdagradLightParameters {
	if x, ok := x.GetParameters().(*OptimizationParameters_MdlAdagradLight); ok {
		return x.MdlAdagradLight
	}
	return nil
}

func (x *OptimizationParameters) GetAdadelta() *AdadeltaParameters {
	if x, ok := x.GetParameters().(*OptimizationParameters_Adadelta); ok {
		return x.Adadelta
	}
	return nil
}

func (x *OptimizationParameters) GetProximalAdagrad() *ProximalAdagradParameters {
	if x, ok := x.GetParameters().(*OptimizationParameters_ProximalAdagrad); ok {
		return x.ProximalAdagrad
	}
	return nil
}

func (x *OptimizationParameters) GetOnlineYogi() *OnlineYogiParameters {
	if x, ok := x.GetParameters().(*OptimizationParameters_OnlineYogi); ok {
		return x.OnlineYogi
	}
	return nil
}

func (x *OptimizationParameters) GetProximalYogi() *ProximalYogiParameters {
	if x, ok := x.GetParameters().(*OptimizationParameters_ProximalYogi); ok {
		return x.ProximalYogi
	}
	return nil
}

func (x *OptimizationParameters) GetFrequencyEstimator() *FrequencyEstimatorParameters {
	if x, ok := x.GetParameters().(*OptimizationParameters_FrequencyEstimator); ok {
		return x.FrequencyEstimator
	}
	return nil
}

func (x *OptimizationParameters) GetUserDefinedProgram() *UserDefinedProgramParameters {
	if x, ok := x.GetParameters().(*OptimizationParameters_UserDefinedProgram); ok {
		return x.UserDefinedProgram
	}
	return nil
}

func (x *OptimizationParameters) GetAssign() *AssignParameters {
	if x, ok := x.GetParameters().(*OptimizationParameters_Assign); ok {
		return x.Assign
	}
	return nil
}

type isOptimizationParameters_Parameters interface {
	isOptimizationParameters_Parameters()
}

type OptimizationParameters_Adagrad struct {
	Adagrad *AdagradParameters `protobuf:"bytes,3,opt,name=adagrad,proto3,oneof"`
}

type OptimizationParameters_AdagradMomentum struct {
	AdagradMomentum *AdagradMomentumParameters `protobuf:"bytes,26,opt,name=adagrad_momentum,json=adagradMomentum,proto3,oneof"`
}

type OptimizationParameters_BoundedAdagrad struct {
	BoundedAdagrad *BoundedAdagradParameters `protobuf:"bytes,19,opt,name=bounded_adagrad,json=boundedAdagrad,proto3,oneof"`
}

type OptimizationParameters_StochasticGradientDescent struct {
	StochasticGradientDescent *StochasticGradientDescentParameters `protobuf:"bytes,4,opt,name=stochastic_gradient_descent,json=stochasticGradientDescent,proto3,oneof"`
}

type OptimizationParameters_Ftrl struct {
	Ftrl *FtrlParameters `protobuf:"bytes,5,opt,name=ftrl,proto3,oneof"`
}

type OptimizationParameters_Adam struct {
	Adam *AdamParameters `protobuf:"bytes,6,opt,name=adam,proto3,oneof"`
}

type OptimizationParameters_Momentum struct {
	Momentum *MomentumParameters `protobuf:"bytes,8,opt,name=momentum,proto3,oneof"`
}

type OptimizationParameters_RmsProp struct {
	RmsProp *RmsPropParameters `protobuf:"bytes,9,opt,name=rms_prop,json=rmsProp,proto3,oneof"`
}

type OptimizationParameters_CenteredRmsProp struct {
	CenteredRmsProp *CenteredRmsPropParameters `protobuf:"bytes,10,opt,name=centered_rms_prop,json=centeredRmsProp,proto3,oneof"`
}

type OptimizationParameters_MdlAdagradLight struct {
	MdlAdagradLight *MdlAdagradLightParameters `protobuf:"bytes,11,opt,name=mdl_adagrad_light,json=mdlAdagradLight,proto3,oneof"`
}

type OptimizationParameters_Adadelta struct {
	Adadelta *AdadeltaParameters `protobuf:"bytes,12,opt,name=adadelta,proto3,oneof"`
}

type OptimizationParameters_ProximalAdagrad struct {
	ProximalAdagrad *ProximalAdagradParameters `protobuf:"bytes,14,opt,name=proximal_adagrad,json=proximalAdagrad,proto3,oneof"`
}

type OptimizationParameters_OnlineYogi struct {
	OnlineYogi *OnlineYogiParameters `protobuf:"bytes,20,opt,name=online_yogi,json=onlineYogi,proto3,oneof"`
}

type OptimizationParameters_ProximalYogi struct {
	ProximalYogi *ProximalYogiParameters `protobuf:"bytes,21,opt,name=proximal_yogi,json=proximalYogi,proto3,oneof"`
}

type OptimizationParameters_FrequencyEstimator struct {
	FrequencyEstimator *FrequencyEstimatorParameters `protobuf:"bytes,23,opt,name=frequency_estimator,json=frequencyEstimator,proto3,oneof"`
}

type OptimizationParameters_UserDefinedProgram struct {
	UserDefinedProgram *UserDefinedProgramParameters `protobuf:"bytes,24,opt,name=user_defined_program,json=userDefinedProgram,proto3,oneof"`
}

type OptimizationParameters_Assign struct {
	Assign *AssignParameters `protobuf:"bytes,25,opt,name=assign,proto3,oneof"`
}

func (*OptimizationParameters_Adagrad) isOptimizationParameters_Parameters() {}

func (*OptimizationParameters_AdagradMomentum) isOptimizationParameters_Parameters() {}

func (*OptimizationParameters_BoundedAdagrad) isOptimizationParameters_Parameters() {}

func (*OptimizationParameters_StochasticGradientDescent) isOptimizationParameters_Parameters() {}

func (*OptimizationParameters_Ftrl) isOptimizationParameters_Parameters() {}

func (*OptimizationParameters_Adam) isOptimizationParameters_Parameters() {}

func (*OptimizationParameters_Momentum) isOptimizationParameters_Parameters() {}

func (*OptimizationParameters_RmsProp) isOptimizationParameters_Parameters() {}

func (*OptimizationParameters_CenteredRmsProp) isOptimizationParameters_Parameters() {}

func (*OptimizationParameters_MdlAdagradLight) isOptimizationParameters_Parameters() {}

func (*OptimizationParameters_Adadelta) isOptimizationParameters_Parameters() {}

func (*OptimizationParameters_ProximalAdagrad) isOptimizationParameters_Parameters() {}

func (*OptimizationParameters_OnlineYogi) isOptimizationParameters_Parameters() {}

func (*OptimizationParameters_ProximalYogi) isOptimizationParameters_Parameters() {}

func (*OptimizationParameters_FrequencyEstimator) isOptimizationParameters_Parameters() {}

func (*OptimizationParameters_UserDefinedProgram) isOptimizationParameters_Parameters() {}

func (*OptimizationParameters_Assign) isOptimizationParameters_Parameters() {}

// Specification of an optimization algorithm's state variables (both the main
// value vector and any extra accumulators, etc.). This proto is only used
// internally by the TPU software and is not exposed directly to the TF model.
type StateVariableSpecification struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// Parameter name for the state variable.
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// Usage type of this state variable.
	//
	// Types that are assignable to Usage:
	//
	//	*StateVariableSpecification_UserDefined_
	//	*StateVariableSpecification_FillWithConstant_
	Usage isStateVariableSpecification_Usage `protobuf_oneof:"usage"`
}

func (x *StateVariableSpecification) Reset() {
	*x = StateVariableSpecification{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[25]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *StateVariableSpecification) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StateVariableSpecification) ProtoMessage() {}

func (x *StateVariableSpecification) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[25]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StateVariableSpecification.ProtoReflect.Descriptor instead.
func (*StateVariableSpecification) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{25}
}

func (x *StateVariableSpecification) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (m *StateVariableSpecification) GetUsage() isStateVariableSpecification_Usage {
	if m != nil {
		return m.Usage
	}
	return nil
}

func (x *StateVariableSpecification) GetUserDefined() *StateVariableSpecification_UserDefined {
	if x, ok := x.GetUsage().(*StateVariableSpecification_UserDefined_); ok {
		return x.UserDefined
	}
	return nil
}

func (x *StateVariableSpecification) GetFillWithConstant() *StateVariableSpecification_FillWithConstant {
	if x, ok := x.GetUsage().(*StateVariableSpecification_FillWithConstant_); ok {
		return x.FillWithConstant
	}
	return nil
}

type isStateVariableSpecification_Usage interface {
	isStateVariableSpecification_Usage()
}

type StateVariableSpecification_UserDefined_ struct {
	UserDefined *StateVariableSpecification_UserDefined `protobuf:"bytes,2,opt,name=user_defined,json=userDefined,proto3,oneof"`
}

type StateVariableSpecification_FillWithConstant_ struct {
	FillWithConstant *StateVariableSpecification_FillWithConstant `protobuf:"bytes,3,opt,name=fill_with_constant,json=fillWithConstant,proto3,oneof"`
}

func (*StateVariableSpecification_UserDefined_) isStateVariableSpecification_Usage() {}

func (*StateVariableSpecification_FillWithConstant_) isStateVariableSpecification_Usage() {}

// A normal state variable that should be saved and restored in checkpoints
// and used as an input or output to non-debug TensorFlow ops.
type StateVariableSpecification_UserDefined struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields
}

func (x *StateVariableSpecification_UserDefined) Reset() {
	*x = StateVariableSpecification_UserDefined{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[26]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *StateVariableSpecification_UserDefined) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StateVariableSpecification_UserDefined) ProtoMessage() {}

func (x *StateVariableSpecification_UserDefined) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[26]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StateVariableSpecification_UserDefined.ProtoReflect.Descriptor instead.
func (*StateVariableSpecification_UserDefined) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{25, 0}
}

// A state variable that should be filled with a constant and normally hidden
// from users (used for intermediate gradients being accumulated, for
// example).
type StateVariableSpecification_FillWithConstant struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	InitialValue float64 `protobuf:"fixed64,1,opt,name=initial_value,json=initialValue,proto3" json:"initial_value,omitempty"`
}

func (x *StateVariableSpecification_FillWithConstant) Reset() {
	*x = StateVariableSpecification_FillWithConstant{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[27]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *StateVariableSpecification_FillWithConstant) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StateVariableSpecification_FillWithConstant) ProtoMessage() {}

func (x *StateVariableSpecification_FillWithConstant) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[27]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StateVariableSpecification_FillWithConstant.ProtoReflect.Descriptor instead.
func (*StateVariableSpecification_FillWithConstant) Descriptor() ([]byte, []int) {
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP(), []int{25, 1}
}

func (x *StateVariableSpecification_FillWithConstant) GetInitialValue() float64 {
	if x != nil {
		return x.InitialValue
	}
	return 0
}

var File_tensorflow_core_protobuf_tpu_optimization_parameters_proto protoreflect.FileDescriptor

var file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDesc = []byte{
	0x0a, 0x3a, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2f, 0x63, 0x6f, 0x72,
	0x65, 0x2f, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x62, 0x75, 0x66, 0x2f, 0x74, 0x70, 0x75, 0x2f, 0x6f,
	0x70, 0x74, 0x69, 0x6d, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x5f, 0x70, 0x61, 0x72, 0x61,
	0x6d, 0x65, 0x74, 0x65, 0x72, 0x73, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x12, 0x0e, 0x74, 0x65,
	0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x74, 0x70, 0x75, 0x1a, 0x1e, 0x67, 0x6f,
	0x6f, 0x67, 0x6c, 0x65, 0x2f, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x62, 0x75, 0x66, 0x2f, 0x77, 0x72,
	0x61, 0x70, 0x70, 0x65, 0x72, 0x73, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x1a, 0x29, 0x74, 0x65,
	0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2f, 0x63, 0x6f, 0x6d, 0x70, 0x69, 0x6c, 0x65,
	0x72, 0x2f, 0x78, 0x6c, 0x61, 0x2f, 0x73, 0x65, 0x72, 0x76, 0x69, 0x63, 0x65, 0x2f, 0x68, 0x6c,
	0x6f, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x22, 0x76, 0x0a, 0x0e, 0x43, 0x6c, 0x69, 0x70, 0x70,
	0x69, 0x6e, 0x67, 0x4c, 0x69, 0x6d, 0x69, 0x74, 0x73, 0x12, 0x31, 0x0a, 0x05, 0x6c, 0x6f, 0x77,
	0x65, 0x72, 0x18, 0x01, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x1b, 0x2e, 0x67, 0x6f, 0x6f, 0x67, 0x6c,
	0x65, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x62, 0x75, 0x66, 0x2e, 0x46, 0x6c, 0x6f, 0x61, 0x74,
	0x56, 0x61, 0x6c, 0x75, 0x65, 0x52, 0x05, 0x6c, 0x6f, 0x77, 0x65, 0x72, 0x12, 0x31, 0x0a, 0x05,
	0x75, 0x70, 0x70, 0x65, 0x72, 0x18, 0x02, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x1b, 0x2e, 0x67, 0x6f,
	0x6f, 0x67, 0x6c, 0x65, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x62, 0x75, 0x66, 0x2e, 0x46, 0x6c,
	0x6f, 0x61, 0x74, 0x56, 0x61, 0x6c, 0x75, 0x65, 0x52, 0x05, 0x75, 0x70, 0x70, 0x65, 0x72, 0x22,
	0x9b, 0x01, 0x0a, 0x15, 0x53, 0x69, 0x6d, 0x75, 0x6c, 0x61, 0x74, 0x65, 0x64, 0x51, 0x75, 0x61,
	0x6e, 0x74, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x12, 0x18, 0x0a, 0x07, 0x65, 0x6e, 0x61,
	0x62, 0x6c, 0x65, 0x64, 0x18, 0x01, 0x20, 0x01, 0x28, 0x08, 0x52, 0x07, 0x65, 0x6e, 0x61, 0x62,
	0x6c, 0x65, 0x64, 0x12, 0x47, 0x0a, 0x0f, 0x63, 0x6c, 0x69, 0x70, 0x70, 0x69, 0x6e, 0x67, 0x5f,
	0x6c, 0x69, 0x6d, 0x69, 0x74, 0x73, 0x18, 0x02, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x1e, 0x2e, 0x74,
	0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x74, 0x70, 0x75, 0x2e, 0x43, 0x6c,
	0x69, 0x70, 0x70, 0x69, 0x6e, 0x67, 0x4c, 0x69, 0x6d, 0x69, 0x74, 0x73, 0x52, 0x0e, 0x63, 0x6c,
	0x69, 0x70, 0x70, 0x69, 0x6e, 0x67, 0x4c, 0x69, 0x6d, 0x69, 0x74, 0x73, 0x12, 0x1f, 0x0a, 0x0b,
	0x6e, 0x75, 0x6d, 0x5f, 0x62, 0x75, 0x63, 0x6b, 0x65, 0x74, 0x73, 0x18, 0x03, 0x20, 0x01, 0x28,
	0x05, 0x52, 0x0a, 0x6e, 0x75, 0x6d, 0x42, 0x75, 0x63, 0x6b, 0x65, 0x74, 0x73, 0x22, 0x27, 0x0a,
	0x13, 0x44, 0x79, 0x6e, 0x61, 0x6d, 0x69, 0x63, 0x4c, 0x65, 0x61, 0x72, 0x6e, 0x69, 0x6e, 0x67,
	0x52, 0x61, 0x74, 0x65, 0x12, 0x10, 0x0a, 0x03, 0x74, 0x61, 0x67, 0x18, 0x01, 0x20, 0x01, 0x28,
	0x05, 0x52, 0x03, 0x74, 0x61, 0x67, 0x22, 0x7e, 0x0a, 0x0c, 0x4c, 0x65, 0x61, 0x72, 0x6e, 0x69,
	0x6e, 0x67, 0x52, 0x61, 0x74, 0x65, 0x12, 0x1c, 0x0a, 0x08, 0x63, 0x6f, 0x6e, 0x73, 0x74, 0x61,
	0x6e, 0x74, 0x18, 0x01, 0x20, 0x01, 0x28, 0x02, 0x48, 0x00, 0x52, 0x08, 0x63, 0x6f, 0x6e, 0x73,
	0x74, 0x61, 0x6e, 0x74, 0x12, 0x3f, 0x0a, 0x07, 0x64, 0x79, 0x6e, 0x61, 0x6d, 0x69, 0x63, 0x18,
	0x02, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x23, 0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c,
	0x6f, 0x77, 0x2e, 0x74, 0x70, 0x75, 0x2e, 0x44, 0x79, 0x6e, 0x61, 0x6d, 0x69, 0x63, 0x4c, 0x65,
	0x61, 0x72, 0x6e, 0x69, 0x6e, 0x67, 0x52, 0x61, 0x74, 0x65, 0x48, 0x00, 0x52, 0x07, 0x64, 0x79,
	0x6e, 0x61, 0x6d, 0x69, 0x63, 0x42, 0x0f, 0x0a, 0x0d, 0x6c, 0x65, 0x61, 0x72, 0x6e, 0x69, 0x6e,
	0x67, 0x5f, 0x72, 0x61, 0x74, 0x65, 0x22, 0x2e, 0x0a, 0x11, 0x41, 0x64, 0x61, 0x67, 0x72, 0x61,
	0x64, 0x50, 0x61, 0x72, 0x61, 0x6d, 0x65, 0x74, 0x65, 0x72, 0x73, 0x4a, 0x04, 0x08, 0x01, 0x10,
	0x02, 0x52, 0x13, 0x69, 0x6e, 0x69, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x61, 0x63, 0x63, 0x75, 0x6d,
	0x75, 0x6c, 0x61, 0x74, 0x6f, 0x72, 0x22, 0xa6, 0x01, 0x0a, 0x19, 0x41, 0x64, 0x61, 0x67, 0x72,
	0x61, 0x64, 0x4d, 0x6f, 0x6d, 0x65, 0x6e, 0x74, 0x75, 0x6d, 0x50, 0x61, 0x72, 0x61, 0x6d, 0x65,
	0x74, 0x65, 0x72, 0x73, 0x12, 0x1a, 0x0a, 0x08, 0x6d, 0x6f, 0x6d, 0x65, 0x6e, 0x74, 0x75, 0x6d,
	0x18, 0x01, 0x20, 0x01, 0x28, 0x02, 0x52, 0x08, 0x6d, 0x6f, 0x6d, 0x65, 0x6e, 0x74, 0x75, 0x6d,
	0x12, 0x21, 0x0a, 0x0c, 0x75, 0x73, 0x65, 0x5f, 0x6e, 0x65, 0x73, 0x74, 0x65, 0x72, 0x6f, 0x76,
	0x18, 0x02, 0x20, 0x01, 0x28, 0x08, 0x52, 0x0b, 0x75, 0x73, 0x65, 0x4e, 0x65, 0x73, 0x74, 0x65,
	0x72, 0x6f, 0x76, 0x12, 0x1a, 0x0a, 0x08, 0x65, 0x78, 0x70, 0x6f, 0x6e, 0x65, 0x6e, 0x74, 0x18,
	0x03, 0x20, 0x01, 0x28, 0x02, 0x52, 0x08, 0x65, 0x78, 0x70, 0x6f, 0x6e, 0x65, 0x6e, 0x74, 0x12,
	0x14, 0x0a, 0x05, 0x62, 0x65, 0x74, 0x61, 0x32, 0x18, 0x04, 0x20, 0x01, 0x28, 0x02, 0x52, 0x05,
	0x62, 0x65, 0x74, 0x61, 0x32, 0x12, 0x18, 0x0a, 0x07, 0x65, 0x70, 0x73, 0x69, 0x6c, 0x6f, 0x6e,
	0x18, 0x05, 0x20, 0x01, 0x28, 0x02, 0x52, 0x07, 0x65, 0x70, 0x73, 0x69, 0x6c, 0x6f, 0x6e, 0x22,
	0xa3, 0x01, 0x0a, 0x18, 0x42, 0x6f, 0x75, 0x6e, 0x64, 0x65, 0x64, 0x41, 0x64, 0x61, 0x67, 0x72,
	0x61, 0x64, 0x50, 0x61, 0x72, 0x61, 0x6d, 0x65, 0x74, 0x65, 0x72, 0x73, 0x12, 0x38, 0x0a, 0x18,
	0x75, 0x70, 0x64, 0x61, 0x74, 0x65, 0x5f, 0x61, 0x63, 0x63, 0x75, 0x6d, 0x75, 0x6c, 0x61, 0x74,
	0x6f, 0x72, 0x5f, 0x66, 0x69, 0x72, 0x73, 0x74, 0x18, 0x01, 0x20, 0x01, 0x28, 0x08, 0x52, 0x16,
	0x75, 0x70, 0x64, 0x61, 0x74, 0x65, 0x41, 0x63, 0x63, 0x75, 0x6d, 0x75, 0x6c, 0x61, 0x74, 0x6f,
	0x72, 0x46, 0x69, 0x72, 0x73, 0x74, 0x12, 0x24, 0x0a, 0x0e, 0x6d, 0x61, 0x78, 0x5f, 0x76, 0x61,
	0x72, 0x5f, 0x75, 0x70, 0x64, 0x61, 0x74, 0x65, 0x18, 0x02, 0x20, 0x01, 0x28, 0x02, 0x52, 0x0c,
	0x6d, 0x61, 0x78, 0x56, 0x61, 0x72, 0x55, 0x70, 0x64, 0x61, 0x74, 0x65, 0x12, 0x27, 0x0a, 0x0f,
	0x6d, 0x61, 0x78, 0x5f, 0x61, 0x63, 0x63, 0x75, 0x6d, 0x75, 0x6c, 0x61, 0x74, 0x6f, 0x72, 0x18,
	0x03, 0x20, 0x01, 0x28, 0x02, 0x52, 0x0e, 0x6d, 0x61, 0x78, 0x41, 0x63, 0x63, 0x75, 0x6d, 0x75,
	0x6c, 0x61, 0x74, 0x6f, 0x72, 0x22, 0x25, 0x0a, 0x23, 0x53, 0x74, 0x6f, 0x63, 0x68, 0x61, 0x73,
	0x74, 0x69, 0x63, 0x47, 0x72, 0x61, 0x64, 0x69, 0x65, 0x6e, 0x74, 0x44, 0x65, 0x73, 0x63, 0x65,
	0x6e, 0x74, 0x50, 0x61, 0x72, 0x61, 0x6d, 0x65, 0x74, 0x65, 0x72, 0x73, 0x22, 0xf7, 0x01, 0x0a,
	0x0e, 0x46, 0x74, 0x72, 0x6c, 0x50, 0x61, 0x72, 0x61, 0x6d, 0x65, 0x74, 0x65, 0x72, 0x73, 0x12,
	0x0e, 0x0a, 0x02, 0x6c, 0x31, 0x18, 0x01, 0x20, 0x01, 0x28, 0x02, 0x52, 0x02, 0x6c, 0x31, 0x12,
	0x0e, 0x0a, 0x02, 0x6c, 0x32, 0x18, 0x02, 0x20, 0x01, 0x28, 0x02, 0x52, 0x02, 0x6c, 0x32, 0x12,
	0x19, 0x0a, 0x08, 0x6c, 0x72, 0x5f, 0x70, 0x6f, 0x77, 0x65, 0x72, 0x18, 0x03, 0x20, 0x01, 0x28,
	0x02, 0x52, 0x07, 0x6c, 0x72, 0x50, 0x6f, 0x77, 0x65, 0x72, 0x12, 0x12, 0x0a, 0x04, 0x62, 0x65,
	0x74, 0x61, 0x18, 0x07, 0x20, 0x01, 0x28, 0x02, 0x52, 0x04, 0x62, 0x65, 0x74, 0x61, 0x12, 0x31,
	0x0a, 0x15, 0x6d, 0x75, 0x6c, 0x74, 0x69, 0x70, 0x6c, 0x79, 0x5f, 0x6c, 0x69, 0x6e, 0x65, 0x61,
	0x72, 0x5f, 0x62, 0x79, 0x5f, 0x6c, 0x72, 0x18, 0x06, 0x20, 0x01, 0x28, 0x08, 0x52, 0x12, 0x6d,
	0x75, 0x6c, 0x74, 0x69, 0x70, 0x6c, 0x79, 0x4c, 0x69, 0x6e, 0x65, 0x61, 0x72, 0x42, 0x79, 0x4c,
	0x72, 0x12, 0x38, 0x0a, 0x16, 0x61, 0x6c, 0x6c, 0x6f, 0x77, 0x5f, 0x7a, 0x65, 0x72, 0x6f, 0x5f,
	0x61, 0x63, 0x63, 0x75, 0x6d, 0x75, 0x6c, 0x61, 0x74, 0x6f, 0x72, 0x18, 0x08, 0x20, 0x01, 0x28,
	0x08, 0x42, 0x02, 0x18, 0x01, 0x52, 0x14, 0x61, 0x6c, 0x6c, 0x6f, 0x77, 0x5a, 0x65, 0x72, 0x6f,
	0x41, 0x63, 0x63, 0x75, 0x6d, 0x75, 0x6c, 0x61, 0x74, 0x6f, 0x72, 0x4a, 0x04, 0x08, 0x04, 0x10,
	0x05, 0x4a, 0x04, 0x08, 0x05, 0x10, 0x06, 0x52, 0x0d, 0x69, 0x6e, 0x69, 0x74, 0x69, 0x61, 0x6c,
	0x5f, 0x61, 0x63, 0x63, 0x75, 0x6d, 0x52, 0x0e, 0x69, 0x6e, 0x69, 0x74, 0x69, 0x61, 0x6c, 0x5f,
	0x6c, 0x69, 0x6e, 0x65, 0x61, 0x72, 0x22, 0xd2, 0x01, 0x0a, 0x0e, 0x41, 0x64, 0x61, 0x6d, 0x50,
	0x61, 0x72, 0x61, 0x6d, 0x65, 0x74, 0x65, 0x72, 0x73, 0x12, 0x14, 0x0a, 0x05, 0x62, 0x65, 0x74,
	0x61, 0x31, 0x18, 0x03, 0x20, 0x01, 0x28, 0x02, 0x52, 0x05, 0x62, 0x65, 0x74, 0x61, 0x31, 0x12,
	0x14, 0x0a, 0x05, 0x62, 0x65, 0x74, 0x61, 0x32, 0x18, 0x04, 0x20, 0x01, 0x28, 0x02, 0x52, 0x05,
	0x62, 0x65, 0x74, 0x61, 0x32, 0x12, 0x18, 0x0a, 0x07, 0x65, 0x70, 0x73, 0x69, 0x6c, 0x6f, 0x6e,
	0x18, 0x05, 0x20, 0x01, 0x28, 0x02, 0x52, 0x07, 0x65, 0x70, 0x73, 0x69, 0x6c, 0x6f, 0x6e, 0x12,
	0x29, 0x0a, 0x11, 0x75, 0x73, 0x65, 0x5f, 0x6e, 0x6f, 0x6e, 0x5f, 0x6c, 0x61, 0x7a, 0x79, 0x5f,
	0x61, 0x64, 0x61, 0x6d, 0x18, 0x08, 0x20, 0x01, 0x28, 0x08, 0x52, 0x0e, 0x75, 0x73, 0x65, 0x4e,
	0x6f, 0x6e, 0x4c, 0x61, 0x7a, 0x79, 0x41, 0x64, 0x61, 0x6d, 0x12, 0x2d, 0x0a, 0x13, 0x75, 0x73,
	0x65, 0x5f, 0x73, 0x75, 0x6d, 0x5f, 0x69, 0x6e, 0x73, 0x69, 0x64, 0x65, 0x5f, 0x73, 0x71, 0x72,
	0x74, 0x18, 0x0a, 0x20, 0x01, 0x28, 0x08, 0x52, 0x10, 0x75, 0x73, 0x65, 0x53, 0x75, 0x6d, 0x49,
	0x6e, 0x73, 0x69, 0x64, 0x65, 0x53, 0x71, 0x72, 0x74, 0x4a, 0x04, 0x08, 0x06, 0x10, 0x07, 0x4a,
	0x04, 0x08, 0x07, 0x10, 0x08, 0x52, 0x09, 0x69, 0x6e, 0x69, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x6d,
	0x52, 0x09, 0x69, 0x6e, 0x69, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x76, 0x22, 0x68, 0x0a, 0x12, 0x4d,
	0x6f, 0x6d, 0x65, 0x6e, 0x74, 0x75, 0x6d, 0x50, 0x61, 0x72, 0x61, 0x6d, 0x65, 0x74, 0x65, 0x72,
	0x73, 0x12, 0x1a, 0x0a, 0x08, 0x6d, 0x6f, 0x6d, 0x65, 0x6e, 0x74, 0x75, 0x6d, 0x18, 0x01, 0x20,
	0x01, 0x28, 0x02, 0x52, 0x08, 0x6d, 0x6f, 0x6d, 0x65, 0x6e, 0x74, 0x75, 0x6d, 0x12, 0x21, 0x0a,
	0x0c, 0x75, 0x73, 0x65, 0x5f, 0x6e, 0x65, 0x73, 0x74, 0x65, 0x72, 0x6f, 0x76, 0x18, 0x02, 0x20,
	0x01, 0x28, 0x08, 0x52, 0x0b, 0x75, 0x73, 0x65, 0x4e, 0x65, 0x73, 0x74, 0x65, 0x72, 0x6f, 0x76,
	0x4a, 0x04, 0x08, 0x03, 0x10, 0x04, 0x52, 0x0d, 0x69, 0x6e, 0x69, 0x74, 0x69, 0x61, 0x6c, 0x5f,
	0x61, 0x63, 0x63, 0x75, 0x6d, 0x22, 0x80, 0x01, 0x0a, 0x11, 0x52, 0x6d, 0x73, 0x50, 0x72, 0x6f,
	0x70, 0x50, 0x61, 0x72, 0x61, 0x6d, 0x65, 0x74, 0x65, 0x72, 0x73, 0x12, 0x10, 0x0a, 0x03, 0x72,
	0x68, 0x6f, 0x18, 0x01, 0x20, 0x01, 0x28, 0x02, 0x52, 0x03, 0x72, 0x68, 0x6f, 0x12, 0x1a, 0x0a,
	0x08, 0x6d, 0x6f, 0x6d, 0x65, 0x6e, 0x74, 0x75, 0x6d, 0x18, 0x02, 0x20, 0x01, 0x28, 0x02, 0x52,
	0x08, 0x6d, 0x6f, 0x6d, 0x65, 0x6e, 0x74, 0x75, 0x6d, 0x12, 0x18, 0x0a, 0x07, 0x65, 0x70, 0x73,
	0x69, 0x6c, 0x6f, 0x6e, 0x18, 0x03, 0x20, 0x01, 0x28, 0x02, 0x52, 0x07, 0x65, 0x70, 0x73, 0x69,
	0x6c, 0x6f, 0x6e, 0x4a, 0x04, 0x08, 0x04, 0x10, 0x05, 0x4a, 0x04, 0x08, 0x05, 0x10, 0x06, 0x52,
	0x0a, 0x69, 0x6e, 0x69, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x6d, 0x73, 0x52, 0x0b, 0x69, 0x6e, 0x69,
	0x74, 0x69, 0x61, 0x6c, 0x5f, 0x6d, 0x6f, 0x6d, 0x22, 0x9a, 0x01, 0x0a, 0x19, 0x43, 0x65, 0x6e,
	0x74, 0x65, 0x72, 0x65, 0x64, 0x52, 0x6d, 0x73, 0x50, 0x72, 0x6f, 0x70, 0x50, 0x61, 0x72, 0x61,
	0x6d, 0x65, 0x74, 0x65, 0x72, 0x73, 0x12, 0x10, 0x0a, 0x03, 0x72, 0x68, 0x6f, 0x18, 0x01, 0x20,
	0x01, 0x28, 0x02, 0x52, 0x03, 0x72, 0x68, 0x6f, 0x12, 0x1a, 0x0a, 0x08, 0x6d, 0x6f, 0x6d, 0x65,
	0x6e, 0x74, 0x75, 0x6d, 0x18, 0x02, 0x20, 0x01, 0x28, 0x02, 0x52, 0x08, 0x6d, 0x6f, 0x6d, 0x65,
	0x6e, 0x74, 0x75, 0x6d, 0x12, 0x18, 0x0a, 0x07, 0x65, 0x70, 0x73, 0x69, 0x6c, 0x6f, 0x6e, 0x18,
	0x03, 0x20, 0x01, 0x28, 0x02, 0x52, 0x07, 0x65, 0x70, 0x73, 0x69, 0x6c, 0x6f, 0x6e, 0x4a, 0x04,
	0x08, 0x04, 0x10, 0x05, 0x4a, 0x04, 0x08, 0x05, 0x10, 0x06, 0x4a, 0x04, 0x08, 0x06, 0x10, 0x07,
	0x52, 0x0a, 0x69, 0x6e, 0x69, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x6d, 0x73, 0x52, 0x0b, 0x69, 0x6e,
	0x69, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x6d, 0x6f, 0x6d, 0x52, 0x0a, 0x69, 0x6e, 0x69, 0x74, 0x69,
	0x61, 0x6c, 0x5f, 0x6d, 0x67, 0x22, 0xdf, 0x04, 0x0a, 0x19, 0x4d, 0x64, 0x6c, 0x41, 0x64, 0x61,
	0x67, 0x72, 0x61, 0x64, 0x4c, 0x69, 0x67, 0x68, 0x74, 0x50, 0x61, 0x72, 0x61, 0x6d, 0x65, 0x74,
	0x65, 0x72, 0x73, 0x12, 0x0e, 0x0a, 0x02, 0x6c, 0x32, 0x18, 0x01, 0x20, 0x01, 0x28, 0x02, 0x52,
	0x02, 0x6c, 0x32, 0x12, 0x19, 0x0a, 0x08, 0x6c, 0x72, 0x5f, 0x70, 0x6f, 0x77, 0x65, 0x72, 0x18,
	0x02, 0x20, 0x01, 0x28, 0x02, 0x52, 0x07, 0x6c, 0x72, 0x50, 0x6f, 0x77, 0x65, 0x72, 0x12, 0x37,
	0x0a, 0x18, 0x6d, 0x69, 0x6e, 0x5f, 0x73, 0x65, 0x72, 0x76, 0x61, 0x62, 0x6c, 0x65, 0x5f, 0x6d,
	0x64, 0x6c, 0x5f, 0x62, 0x65, 0x6e, 0x65, 0x66, 0x69, 0x74, 0x18, 0x03, 0x20, 0x01, 0x28, 0x02,
	0x52, 0x15, 0x6d, 0x69, 0x6e, 0x53, 0x65, 0x72, 0x76, 0x61, 0x62, 0x6c, 0x65, 0x4d, 0x64, 0x6c,
	0x42, 0x65, 0x6e, 0x65, 0x66, 0x69, 0x74, 0x12, 0x29, 0x0a, 0x11, 0x6d, 0x64, 0x6c, 0x5f, 0x6d,
	0x69, 0x78, 0x5f, 0x69, 0x6e, 0x5f, 0x6d, 0x61, 0x72, 0x67, 0x69, 0x6e, 0x18, 0x04, 0x20, 0x01,
	0x28, 0x02, 0x52, 0x0e, 0x6d, 0x64, 0x6c, 0x4d, 0x69, 0x78, 0x49, 0x6e, 0x4d, 0x61, 0x72, 0x67,
	0x69, 0x6e, 0x12, 0x37, 0x0a, 0x18, 0x6d, 0x64, 0x6c, 0x5f, 0x62, 0x65, 0x6e, 0x65, 0x66, 0x69,
	0x74, 0x5f, 0x72, 0x61, 0x6d, 0x70, 0x75, 0x70, 0x5f, 0x63, 0x6f, 0x65, 0x66, 0x66, 0x18, 0x05,
	0x20, 0x01, 0x28, 0x02, 0x52, 0x15, 0x6d, 0x64, 0x6c, 0x42, 0x65, 0x6e, 0x65, 0x66, 0x69, 0x74,
	0x52, 0x61, 0x6d, 0x70, 0x75, 0x70, 0x43, 0x6f, 0x65, 0x66, 0x66, 0x12, 0x24, 0x0a, 0x0e, 0x6d,
	0x64, 0x6c, 0x5f, 0x6d, 0x69, 0x6e, 0x5f, 0x77, 0x65, 0x69, 0x67, 0x68, 0x74, 0x18, 0x06, 0x20,
	0x01, 0x28, 0x02, 0x52, 0x0c, 0x6d, 0x64, 0x6c, 0x4d, 0x69, 0x6e, 0x57, 0x65, 0x69, 0x67, 0x68,
	0x74, 0x12, 0x32, 0x0a, 0x15, 0x62, 0x65, 0x6e, 0x65, 0x66, 0x69, 0x74, 0x5f, 0x72, 0x65, 0x76,
	0x69, 0x73, 0x69, 0x74, 0x5f, 0x73, 0x63, 0x61, 0x6c, 0x65, 0x18, 0x07, 0x20, 0x01, 0x28, 0x02,
	0x52, 0x13, 0x62, 0x65, 0x6e, 0x65, 0x66, 0x69, 0x74, 0x52, 0x65, 0x76, 0x69, 0x73, 0x69, 0x74,
	0x53, 0x63, 0x61, 0x6c, 0x65, 0x12, 0x2a, 0x0a, 0x11, 0x6d, 0x61, 0x78, 0x5f, 0x65, 0x76, 0x65,
	0x6e, 0x74, 0x5f, 0x62, 0x65, 0x6e, 0x65, 0x66, 0x69, 0x74, 0x18, 0x08, 0x20, 0x01, 0x28, 0x02,
	0x52, 0x0f, 0x6d, 0x61, 0x78, 0x45, 0x76, 0x65, 0x6e, 0x74, 0x42, 0x65, 0x6e, 0x65, 0x66, 0x69,
	0x74, 0x12, 0x2a, 0x0a, 0x11, 0x6d, 0x61, 0x78, 0x5f, 0x74, 0x6f, 0x74, 0x61, 0x6c, 0x5f, 0x62,
	0x65, 0x6e, 0x65, 0x66, 0x69, 0x74, 0x18, 0x09, 0x20, 0x01, 0x28, 0x02, 0x52, 0x0f, 0x6d, 0x61,
	0x78, 0x54, 0x6f, 0x74, 0x61, 0x6c, 0x42, 0x65, 0x6e, 0x65, 0x66, 0x69, 0x74, 0x12, 0x24, 0x0a,
	0x0e, 0x6d, 0x64, 0x6c, 0x5f, 0x68, 0x61, 0x72, 0x64, 0x5f, 0x6c, 0x69, 0x6d, 0x69, 0x74, 0x18,
	0x0a, 0x20, 0x01, 0x28, 0x02, 0x52, 0x0c, 0x6d, 0x64, 0x6c, 0x48, 0x61, 0x72, 0x64, 0x4c, 0x69,
	0x6d, 0x69, 0x74, 0x12, 0x33, 0x0a, 0x16, 0x68, 0x61, 0x72, 0x64, 0x5f, 0x6c, 0x69, 0x6d, 0x69,
	0x74, 0x5f, 0x6d, 0x69, 0x6e, 0x5f, 0x62, 0x65, 0x6e, 0x65, 0x66, 0x69, 0x74, 0x18, 0x0b, 0x20,
	0x01, 0x28, 0x08, 0x52, 0x13, 0x68, 0x61, 0x72, 0x64, 0x4c, 0x69, 0x6d, 0x69, 0x74, 0x4d, 0x69,
	0x6e, 0x42, 0x65, 0x6e, 0x65, 0x66, 0x69, 0x74, 0x12, 0x25, 0x0a, 0x0e, 0x6d, 0x64, 0x6c, 0x5f,
	0x72, 0x65, 0x67, 0x75, 0x6c, 0x61, 0x72, 0x69, 0x7a, 0x65, 0x18, 0x0c, 0x20, 0x01, 0x28, 0x08,
	0x52, 0x0d, 0x6d, 0x64, 0x6c, 0x52, 0x65, 0x67, 0x75, 0x6c, 0x61, 0x72, 0x69, 0x7a, 0x65, 0x4a,
	0x04, 0x08, 0x0d, 0x10, 0x0e, 0x4a, 0x04, 0x08, 0x0e, 0x10, 0x0f, 0x4a, 0x04, 0x08, 0x0f, 0x10,
	0x10, 0x52, 0x13, 0x69, 0x6e, 0x69, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x61, 0x63, 0x63, 0x75, 0x6d,
	0x75, 0x6c, 0x61, 0x74, 0x6f, 0x72, 0x52, 0x0e, 0x69, 0x6e, 0x69, 0x74, 0x69, 0x61, 0x6c, 0x5f,
	0x77, 0x65, 0x69, 0x67, 0x68, 0x74, 0x52, 0x0f, 0x69, 0x6e, 0x69, 0x74, 0x69, 0x61, 0x6c, 0x5f,
	0x62, 0x65, 0x6e, 0x65, 0x66, 0x69, 0x74, 0x22, 0x71, 0x0a, 0x12, 0x41, 0x64, 0x61, 0x64, 0x65,
	0x6c, 0x74, 0x61, 0x50, 0x61, 0x72, 0x61, 0x6d, 0x65, 0x74, 0x65, 0x72, 0x73, 0x12, 0x10, 0x0a,
	0x03, 0x72, 0x68, 0x6f, 0x18, 0x01, 0x20, 0x01, 0x28, 0x02, 0x52, 0x03, 0x72, 0x68, 0x6f, 0x12,
	0x18, 0x0a, 0x07, 0x65, 0x70, 0x73, 0x69, 0x6c, 0x6f, 0x6e, 0x18, 0x02, 0x20, 0x01, 0x28, 0x02,
	0x52, 0x07, 0x65, 0x70, 0x73, 0x69, 0x6c, 0x6f, 0x6e, 0x4a, 0x04, 0x08, 0x03, 0x10, 0x04, 0x4a,
	0x04, 0x08, 0x04, 0x10, 0x05, 0x52, 0x13, 0x69, 0x6e, 0x69, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x61,
	0x63, 0x63, 0x75, 0x6d, 0x75, 0x6c, 0x61, 0x74, 0x6f, 0x72, 0x52, 0x0e, 0x69, 0x6e, 0x69, 0x74,
	0x69, 0x61, 0x6c, 0x5f, 0x75, 0x70, 0x64, 0x61, 0x74, 0x65, 0x22, 0x56, 0x0a, 0x19, 0x50, 0x72,
	0x6f, 0x78, 0x69, 0x6d, 0x61, 0x6c, 0x41, 0x64, 0x61, 0x67, 0x72, 0x61, 0x64, 0x50, 0x61, 0x72,
	0x61, 0x6d, 0x65, 0x74, 0x65, 0x72, 0x73, 0x12, 0x0e, 0x0a, 0x02, 0x6c, 0x31, 0x18, 0x01, 0x20,
	0x01, 0x28, 0x02, 0x52, 0x02, 0x6c, 0x31, 0x12, 0x0e, 0x0a, 0x02, 0x6c, 0x32, 0x18, 0x02, 0x20,
	0x01, 0x28, 0x02, 0x52, 0x02, 0x6c, 0x32, 0x4a, 0x04, 0x08, 0x03, 0x10, 0x04, 0x52, 0x13, 0x69,
	0x6e, 0x69, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x61, 0x63, 0x63, 0x75, 0x6d, 0x75, 0x6c, 0x61, 0x74,
	0x6f, 0x72, 0x22, 0x58, 0x0a, 0x14, 0x4f, 0x6e, 0x6c, 0x69, 0x6e, 0x65, 0x59, 0x6f, 0x67, 0x69,
	0x50, 0x61, 0x72, 0x61, 0x6d, 0x65, 0x74, 0x65, 0x72, 0x73, 0x12, 0x0e, 0x0a, 0x02, 0x6c, 0x31,
	0x18, 0x01, 0x20, 0x01, 0x28, 0x02, 0x52, 0x02, 0x6c, 0x31, 0x12, 0x0e, 0x0a, 0x02, 0x6c, 0x32,
	0x18, 0x02, 0x20, 0x01, 0x28, 0x02, 0x52, 0x02, 0x6c, 0x32, 0x12, 0x14, 0x0a, 0x05, 0x62, 0x65,
	0x74, 0x61, 0x32, 0x18, 0x03, 0x20, 0x01, 0x28, 0x02, 0x52, 0x05, 0x62, 0x65, 0x74, 0x61, 0x32,
	0x4a, 0x04, 0x08, 0x06, 0x10, 0x07, 0x4a, 0x04, 0x08, 0x07, 0x10, 0x08, 0x22, 0x8a, 0x01, 0x0a,
	0x16, 0x50, 0x72, 0x6f, 0x78, 0x69, 0x6d, 0x61, 0x6c, 0x59, 0x6f, 0x67, 0x69, 0x50, 0x61, 0x72,
	0x61, 0x6d, 0x65, 0x74, 0x65, 0x72, 0x73, 0x12, 0x0e, 0x0a, 0x02, 0x6c, 0x31, 0x18, 0x01, 0x20,
	0x01, 0x28, 0x02, 0x52, 0x02, 0x6c, 0x31, 0x12, 0x0e, 0x0a, 0x02, 0x6c, 0x32, 0x18, 0x02, 0x20,
	0x01, 0x28, 0x02, 0x52, 0x02, 0x6c, 0x32, 0x12, 0x14, 0x0a, 0x05, 0x62, 0x65, 0x74, 0x61, 0x31,
	0x18, 0x03, 0x20, 0x01, 0x28, 0x02, 0x52, 0x05, 0x62, 0x65, 0x74, 0x61, 0x31, 0x12, 0x14, 0x0a,
	0x05, 0x62, 0x65, 0x74, 0x61, 0x32, 0x18, 0x04, 0x20, 0x01, 0x28, 0x02, 0x52, 0x05, 0x62, 0x65,
	0x74, 0x61, 0x32, 0x12, 0x18, 0x0a, 0x07, 0x65, 0x70, 0x73, 0x69, 0x6c, 0x6f, 0x6e, 0x18, 0x05,
	0x20, 0x01, 0x28, 0x02, 0x52, 0x07, 0x65, 0x70, 0x73, 0x69, 0x6c, 0x6f, 0x6e, 0x4a, 0x04, 0x08,
	0x08, 0x10, 0x09, 0x4a, 0x04, 0x08, 0x09, 0x10, 0x0a, 0x22, 0xa3, 0x01, 0x0a, 0x1c, 0x46, 0x72,
	0x65, 0x71, 0x75, 0x65, 0x6e, 0x63, 0x79, 0x45, 0x73, 0x74, 0x69, 0x6d, 0x61, 0x74, 0x6f, 0x72,
	0x50, 0x61, 0x72, 0x61, 0x6d, 0x65, 0x74, 0x65, 0x72, 0x73, 0x12, 0x10, 0x0a, 0x03, 0x74, 0x61,
	0x75, 0x18, 0x01, 0x20, 0x01, 0x28, 0x02, 0x52, 0x03, 0x74, 0x61, 0x75, 0x12, 0x1b, 0x0a, 0x09,
	0x6d, 0x61, 0x78, 0x5f, 0x64, 0x65, 0x6c, 0x74, 0x61, 0x18, 0x02, 0x20, 0x01, 0x28, 0x02, 0x52,
	0x08, 0x6d, 0x61, 0x78, 0x44, 0x65, 0x6c, 0x74, 0x61, 0x12, 0x2b, 0x0a, 0x11, 0x6f, 0x75, 0x74,
	0x6c, 0x69, 0x65, 0x72, 0x5f, 0x74, 0x68, 0x72, 0x65, 0x73, 0x68, 0x6f, 0x6c, 0x64, 0x18, 0x03,
	0x20, 0x01, 0x28, 0x02, 0x52, 0x10, 0x6f, 0x75, 0x74, 0x6c, 0x69, 0x65, 0x72, 0x54, 0x68, 0x72,
	0x65, 0x73, 0x68, 0x6f, 0x6c, 0x64, 0x12, 0x27, 0x0a, 0x0f, 0x77, 0x65, 0x69, 0x67, 0x68, 0x74,
	0x5f, 0x65, 0x78, 0x70, 0x6f, 0x6e, 0x65, 0x6e, 0x74, 0x18, 0x04, 0x20, 0x01, 0x28, 0x02, 0x52,
	0x0e, 0x77, 0x65, 0x69, 0x67, 0x68, 0x74, 0x45, 0x78, 0x70, 0x6f, 0x6e, 0x65, 0x6e, 0x74, 0x22,
	0x53, 0x0a, 0x1c, 0x55, 0x73, 0x65, 0x72, 0x44, 0x65, 0x66, 0x69, 0x6e, 0x65, 0x64, 0x50, 0x72,
	0x6f, 0x67, 0x72, 0x61, 0x6d, 0x50, 0x61, 0x72, 0x61, 0x6d, 0x65, 0x74, 0x65, 0x72, 0x73, 0x12,
	0x2d, 0x0a, 0x07, 0x70, 0x72, 0x6f, 0x67, 0x72, 0x61, 0x6d, 0x18, 0x01, 0x20, 0x01, 0x28, 0x0b,
	0x32, 0x13, 0x2e, 0x78, 0x6c, 0x61, 0x2e, 0x48, 0x6c, 0x6f, 0x4d, 0x6f, 0x64, 0x75, 0x6c, 0x65,
	0x50, 0x72, 0x6f, 0x74, 0x6f, 0x52, 0x07, 0x70, 0x72, 0x6f, 0x67, 0x72, 0x61, 0x6d, 0x4a, 0x04,
	0x08, 0x02, 0x10, 0x03, 0x22, 0x12, 0x0a, 0x10, 0x41, 0x73, 0x73, 0x69, 0x67, 0x6e, 0x50, 0x61,
	0x72, 0x61, 0x6d, 0x65, 0x74, 0x65, 0x72, 0x73, 0x22, 0x52, 0x0a, 0x1a, 0x47, 0x72, 0x61, 0x64,
	0x69, 0x65, 0x6e, 0x74, 0x41, 0x63, 0x63, 0x75, 0x6d, 0x75, 0x6c, 0x61, 0x74, 0x69, 0x6f, 0x6e,
	0x53, 0x74, 0x61, 0x74, 0x75, 0x73, 0x22, 0x34, 0x0a, 0x06, 0x53, 0x74, 0x61, 0x74, 0x75, 0x73,
	0x12, 0x0f, 0x0a, 0x0b, 0x55, 0x4e, 0x53, 0x50, 0x45, 0x43, 0x49, 0x46, 0x49, 0x45, 0x44, 0x10,
	0x00, 0x12, 0x0b, 0x0a, 0x07, 0x45, 0x4e, 0x41, 0x42, 0x4c, 0x45, 0x44, 0x10, 0x01, 0x12, 0x0c,
	0x0a, 0x08, 0x44, 0x49, 0x53, 0x41, 0x42, 0x4c, 0x45, 0x44, 0x10, 0x02, 0x22, 0x53, 0x0a, 0x1b,
	0x4c, 0x6f, 0x77, 0x44, 0x69, 0x6d, 0x65, 0x6e, 0x73, 0x69, 0x6f, 0x6e, 0x61, 0x6c, 0x50, 0x61,
	0x63, 0x6b, 0x69, 0x6e, 0x67, 0x53, 0x74, 0x61, 0x74, 0x75, 0x73, 0x22, 0x34, 0x0a, 0x06, 0x53,
	0x74, 0x61, 0x74, 0x75, 0x73, 0x12, 0x0f, 0x0a, 0x0b, 0x55, 0x4e, 0x53, 0x50, 0x45, 0x43, 0x49,
	0x46, 0x49, 0x45, 0x44, 0x10, 0x00, 0x12, 0x0b, 0x0a, 0x07, 0x45, 0x4e, 0x41, 0x42, 0x4c, 0x45,
	0x44, 0x10, 0x01, 0x12, 0x0c, 0x0a, 0x08, 0x44, 0x49, 0x53, 0x41, 0x42, 0x4c, 0x45, 0x44, 0x10,
	0x02, 0x22, 0xa3, 0x01, 0x0a, 0x1d, 0x48, 0x6f, 0x74, 0x49, 0x64, 0x52, 0x65, 0x70, 0x6c, 0x69,
	0x63, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x43, 0x6f, 0x6e, 0x66, 0x69, 0x67, 0x75, 0x72, 0x61, 0x74,
	0x69, 0x6f, 0x6e, 0x12, 0x4c, 0x0a, 0x06, 0x73, 0x74, 0x61, 0x74, 0x75, 0x73, 0x18, 0x01, 0x20,
	0x01, 0x28, 0x0e, 0x32, 0x34, 0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77,
	0x2e, 0x74, 0x70, 0x75, 0x2e, 0x48, 0x6f, 0x74, 0x49, 0x64, 0x52, 0x65, 0x70, 0x6c, 0x69, 0x63,
	0x61, 0x74, 0x69, 0x6f, 0x6e, 0x43, 0x6f, 0x6e, 0x66, 0x69, 0x67, 0x75, 0x72, 0x61, 0x74, 0x69,
	0x6f, 0x6e, 0x2e, 0x53, 0x74, 0x61, 0x74, 0x75, 0x73, 0x52, 0x06, 0x73, 0x74, 0x61, 0x74, 0x75,
	0x73, 0x22, 0x34, 0x0a, 0x06, 0x53, 0x74, 0x61, 0x74, 0x75, 0x73, 0x12, 0x0f, 0x0a, 0x0b, 0x55,
	0x4e, 0x53, 0x50, 0x45, 0x43, 0x49, 0x46, 0x49, 0x45, 0x44, 0x10, 0x00, 0x12, 0x0b, 0x0a, 0x07,
	0x45, 0x4e, 0x41, 0x42, 0x4c, 0x45, 0x44, 0x10, 0x01, 0x12, 0x0c, 0x0a, 0x08, 0x44, 0x49, 0x53,
	0x41, 0x42, 0x4c, 0x45, 0x44, 0x10, 0x02, 0x22, 0xa0, 0x11, 0x0a, 0x16, 0x4f, 0x70, 0x74, 0x69,
	0x6d, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x50, 0x61, 0x72, 0x61, 0x6d, 0x65, 0x74, 0x65,
	0x72, 0x73, 0x12, 0x41, 0x0a, 0x0d, 0x6c, 0x65, 0x61, 0x72, 0x6e, 0x69, 0x6e, 0x67, 0x5f, 0x72,
	0x61, 0x74, 0x65, 0x18, 0x0d, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x1c, 0x2e, 0x74, 0x65, 0x6e, 0x73,
	0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x74, 0x70, 0x75, 0x2e, 0x4c, 0x65, 0x61, 0x72, 0x6e,
	0x69, 0x6e, 0x67, 0x52, 0x61, 0x74, 0x65, 0x52, 0x0c, 0x6c, 0x65, 0x61, 0x72, 0x6e, 0x69, 0x6e,
	0x67, 0x52, 0x61, 0x74, 0x65, 0x12, 0x47, 0x0a, 0x0f, 0x63, 0x6c, 0x69, 0x70, 0x70, 0x69, 0x6e,
	0x67, 0x5f, 0x6c, 0x69, 0x6d, 0x69, 0x74, 0x73, 0x18, 0x02, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x1e,
	0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x74, 0x70, 0x75, 0x2e,
	0x43, 0x6c, 0x69, 0x70, 0x70, 0x69, 0x6e, 0x67, 0x4c, 0x69, 0x6d, 0x69, 0x74, 0x73, 0x52, 0x0e,
	0x63, 0x6c, 0x69, 0x70, 0x70, 0x69, 0x6e, 0x67, 0x4c, 0x69, 0x6d, 0x69, 0x74, 0x73, 0x12, 0x58,
	0x0a, 0x18, 0x67, 0x72, 0x61, 0x64, 0x69, 0x65, 0x6e, 0x74, 0x5f, 0x63, 0x6c, 0x69, 0x70, 0x70,
	0x69, 0x6e, 0x67, 0x5f, 0x6c, 0x69, 0x6d, 0x69, 0x74, 0x73, 0x18, 0x07, 0x20, 0x01, 0x28, 0x0b,
	0x32, 0x1e, 0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x74, 0x70,
	0x75, 0x2e, 0x43, 0x6c, 0x69, 0x70, 0x70, 0x69, 0x6e, 0x67, 0x4c, 0x69, 0x6d, 0x69, 0x74, 0x73,
	0x52, 0x16, 0x67, 0x72, 0x61, 0x64, 0x69, 0x65, 0x6e, 0x74, 0x43, 0x6c, 0x69, 0x70, 0x70, 0x69,
	0x6e, 0x67, 0x4c, 0x69, 0x6d, 0x69, 0x74, 0x73, 0x12, 0x2e, 0x0a, 0x13, 0x77, 0x65, 0x69, 0x67,
	0x68, 0x74, 0x5f, 0x64, 0x65, 0x63, 0x61, 0x79, 0x5f, 0x66, 0x61, 0x63, 0x74, 0x6f, 0x72, 0x18,
	0x10, 0x20, 0x01, 0x28, 0x02, 0x52, 0x11, 0x77, 0x65, 0x69, 0x67, 0x68, 0x74, 0x44, 0x65, 0x63,
	0x61, 0x79, 0x46, 0x61, 0x63, 0x74, 0x6f, 0x72, 0x12, 0x5e, 0x0a, 0x2d, 0x6d, 0x75, 0x6c, 0x74,
	0x69, 0x70, 0x6c, 0x79, 0x5f, 0x77, 0x65, 0x69, 0x67, 0x68, 0x74, 0x5f, 0x64, 0x65, 0x63, 0x61,
	0x79, 0x5f, 0x66, 0x61, 0x63, 0x74, 0x6f, 0x72, 0x5f, 0x62, 0x79, 0x5f, 0x6c, 0x65, 0x61, 0x72,
	0x6e, 0x69, 0x6e, 0x67, 0x5f, 0x72, 0x61, 0x74, 0x65, 0x18, 0x16, 0x20, 0x01, 0x28, 0x08, 0x52,
	0x27, 0x6d, 0x75, 0x6c, 0x74, 0x69, 0x70, 0x6c, 0x79, 0x57, 0x65, 0x69, 0x67, 0x68, 0x74, 0x44,
	0x65, 0x63, 0x61, 0x79, 0x46, 0x61, 0x63, 0x74, 0x6f, 0x72, 0x42, 0x79, 0x4c, 0x65, 0x61, 0x72,
	0x6e, 0x69, 0x6e, 0x67, 0x52, 0x61, 0x74, 0x65, 0x12, 0x5c, 0x0a, 0x16, 0x73, 0x69, 0x6d, 0x75,
	0x6c, 0x61, 0x74, 0x65, 0x64, 0x5f, 0x71, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x61, 0x74, 0x69,
	0x6f, 0x6e, 0x18, 0x1b, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x25, 0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f,
	0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x74, 0x70, 0x75, 0x2e, 0x53, 0x69, 0x6d, 0x75, 0x6c, 0x61,
	0x74, 0x65, 0x64, 0x51, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x52,
	0x15, 0x73, 0x69, 0x6d, 0x75, 0x6c, 0x61, 0x74, 0x65, 0x64, 0x51, 0x75, 0x61, 0x6e, 0x74, 0x69,
	0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x12, 0x73, 0x0a, 0x1c, 0x67, 0x72, 0x61, 0x64, 0x69, 0x65,
	0x6e, 0x74, 0x5f, 0x61, 0x63, 0x63, 0x75, 0x6d, 0x75, 0x6c, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x5f,
	0x73, 0x74, 0x61, 0x74, 0x75, 0x73, 0x18, 0x11, 0x20, 0x01, 0x28, 0x0e, 0x32, 0x31, 0x2e, 0x74,
	0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x74, 0x70, 0x75, 0x2e, 0x47, 0x72,
	0x61, 0x64, 0x69, 0x65, 0x6e, 0x74, 0x41, 0x63, 0x63, 0x75, 0x6d, 0x75, 0x6c, 0x61, 0x74, 0x69,
	0x6f, 0x6e, 0x53, 0x74, 0x61, 0x74, 0x75, 0x73, 0x2e, 0x53, 0x74, 0x61, 0x74, 0x75, 0x73, 0x52,
	0x1a, 0x67, 0x72, 0x61, 0x64, 0x69, 0x65, 0x6e, 0x74, 0x41, 0x63, 0x63, 0x75, 0x6d, 0x75, 0x6c,
	0x61, 0x74, 0x69, 0x6f, 0x6e, 0x53, 0x74, 0x61, 0x74, 0x75, 0x73, 0x12, 0x77, 0x0a, 0x1e, 0x6c,
	0x6f, 0x77, 0x5f, 0x64, 0x69, 0x6d, 0x65, 0x6e, 0x73, 0x69, 0x6f, 0x6e, 0x61, 0x6c, 0x5f, 0x70,
	0x61, 0x63, 0x6b, 0x69, 0x6e, 0x67, 0x5f, 0x73, 0x74, 0x61, 0x74, 0x75, 0x73, 0x18, 0x1c, 0x20,
	0x01, 0x28, 0x0e, 0x32, 0x32, 0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77,
	0x2e, 0x74, 0x70, 0x75, 0x2e, 0x4c, 0x6f, 0x77, 0x44, 0x69, 0x6d, 0x65, 0x6e, 0x73, 0x69, 0x6f,
	0x6e, 0x61, 0x6c, 0x50, 0x61, 0x63, 0x6b, 0x69, 0x6e, 0x67, 0x53, 0x74, 0x61, 0x74, 0x75, 0x73,
	0x2e, 0x53, 0x74, 0x61, 0x74, 0x75, 0x73, 0x52, 0x1b, 0x6c, 0x6f, 0x77, 0x44, 0x69, 0x6d, 0x65,
	0x6e, 0x73, 0x69, 0x6f, 0x6e, 0x61, 0x6c, 0x50, 0x61, 0x63, 0x6b, 0x69, 0x6e, 0x67, 0x53, 0x74,
	0x61, 0x74, 0x75, 0x73, 0x12, 0x76, 0x0a, 0x20, 0x68, 0x6f, 0x74, 0x5f, 0x69, 0x64, 0x5f, 0x72,
	0x65, 0x70, 0x6c, 0x69, 0x63, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x5f, 0x63, 0x6f, 0x6e, 0x66, 0x69,
	0x67, 0x75, 0x72, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x18, 0x12, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x2d,
	0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x74, 0x70, 0x75, 0x2e,
	0x48, 0x6f, 0x74, 0x49, 0x64, 0x52, 0x65, 0x70, 0x6c, 0x69, 0x63, 0x61, 0x74, 0x69, 0x6f, 0x6e,
	0x43, 0x6f, 0x6e, 0x66, 0x69, 0x67, 0x75, 0x72, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x52, 0x1d, 0x68,
	0x6f, 0x74, 0x49, 0x64, 0x52, 0x65, 0x70, 0x6c, 0x69, 0x63, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x43,
	0x6f, 0x6e, 0x66, 0x69, 0x67, 0x75, 0x72, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x12, 0x3d, 0x0a, 0x07,
	0x61, 0x64, 0x61, 0x67, 0x72, 0x61, 0x64, 0x18, 0x03, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x21, 0x2e,
	0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x74, 0x70, 0x75, 0x2e, 0x41,
	0x64, 0x61, 0x67, 0x72, 0x61, 0x64, 0x50, 0x61, 0x72, 0x61, 0x6d, 0x65, 0x74, 0x65, 0x72, 0x73,
	0x48, 0x00, 0x52, 0x07, 0x61, 0x64, 0x61, 0x67, 0x72, 0x61, 0x64, 0x12, 0x56, 0x0a, 0x10, 0x61,
	0x64, 0x61, 0x67, 0x72, 0x61, 0x64, 0x5f, 0x6d, 0x6f, 0x6d, 0x65, 0x6e, 0x74, 0x75, 0x6d, 0x18,
	0x1a, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x29, 0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c,
	0x6f, 0x77, 0x2e, 0x74, 0x70, 0x75, 0x2e, 0x41, 0x64, 0x61, 0x67, 0x72, 0x61, 0x64, 0x4d, 0x6f,
	0x6d, 0x65, 0x6e, 0x74, 0x75, 0x6d, 0x50, 0x61, 0x72, 0x61, 0x6d, 0x65, 0x74, 0x65, 0x72, 0x73,
	0x48, 0x00, 0x52, 0x0f, 0x61, 0x64, 0x61, 0x67, 0x72, 0x61, 0x64, 0x4d, 0x6f, 0x6d, 0x65, 0x6e,
	0x74, 0x75, 0x6d, 0x12, 0x53, 0x0a, 0x0f, 0x62, 0x6f, 0x75, 0x6e, 0x64, 0x65, 0x64, 0x5f, 0x61,
	0x64, 0x61, 0x67, 0x72, 0x61, 0x64, 0x18, 0x13, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x28, 0x2e, 0x74,
	0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x74, 0x70, 0x75, 0x2e, 0x42, 0x6f,
	0x75, 0x6e, 0x64, 0x65, 0x64, 0x41, 0x64, 0x61, 0x67, 0x72, 0x61, 0x64, 0x50, 0x61, 0x72, 0x61,
	0x6d, 0x65, 0x74, 0x65, 0x72, 0x73, 0x48, 0x00, 0x52, 0x0e, 0x62, 0x6f, 0x75, 0x6e, 0x64, 0x65,
	0x64, 0x41, 0x64, 0x61, 0x67, 0x72, 0x61, 0x64, 0x12, 0x75, 0x0a, 0x1b, 0x73, 0x74, 0x6f, 0x63,
	0x68, 0x61, 0x73, 0x74, 0x69, 0x63, 0x5f, 0x67, 0x72, 0x61, 0x64, 0x69, 0x65, 0x6e, 0x74, 0x5f,
	0x64, 0x65, 0x73, 0x63, 0x65, 0x6e, 0x74, 0x18, 0x04, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x33, 0x2e,
	0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x74, 0x70, 0x75, 0x2e, 0x53,
	0x74, 0x6f, 0x63, 0x68, 0x61, 0x73, 0x74, 0x69, 0x63, 0x47, 0x72, 0x61, 0x64, 0x69, 0x65, 0x6e,
	0x74, 0x44, 0x65, 0x73, 0x63, 0x65, 0x6e, 0x74, 0x50, 0x61, 0x72, 0x61, 0x6d, 0x65, 0x74, 0x65,
	0x72, 0x73, 0x48, 0x00, 0x52, 0x19, 0x73, 0x74, 0x6f, 0x63, 0x68, 0x61, 0x73, 0x74, 0x69, 0x63,
	0x47, 0x72, 0x61, 0x64, 0x69, 0x65, 0x6e, 0x74, 0x44, 0x65, 0x73, 0x63, 0x65, 0x6e, 0x74, 0x12,
	0x34, 0x0a, 0x04, 0x66, 0x74, 0x72, 0x6c, 0x18, 0x05, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x1e, 0x2e,
	0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x74, 0x70, 0x75, 0x2e, 0x46,
	0x74, 0x72, 0x6c, 0x50, 0x61, 0x72, 0x61, 0x6d, 0x65, 0x74, 0x65, 0x72, 0x73, 0x48, 0x00, 0x52,
	0x04, 0x66, 0x74, 0x72, 0x6c, 0x12, 0x34, 0x0a, 0x04, 0x61, 0x64, 0x61, 0x6d, 0x18, 0x06, 0x20,
	0x01, 0x28, 0x0b, 0x32, 0x1e, 0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77,
	0x2e, 0x74, 0x70, 0x75, 0x2e, 0x41, 0x64, 0x61, 0x6d, 0x50, 0x61, 0x72, 0x61, 0x6d, 0x65, 0x74,
	0x65, 0x72, 0x73, 0x48, 0x00, 0x52, 0x04, 0x61, 0x64, 0x61, 0x6d, 0x12, 0x40, 0x0a, 0x08, 0x6d,
	0x6f, 0x6d, 0x65, 0x6e, 0x74, 0x75, 0x6d, 0x18, 0x08, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x22, 0x2e,
	0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x74, 0x70, 0x75, 0x2e, 0x4d,
	0x6f, 0x6d, 0x65, 0x6e, 0x74, 0x75, 0x6d, 0x50, 0x61, 0x72, 0x61, 0x6d, 0x65, 0x74, 0x65, 0x72,
	0x73, 0x48, 0x00, 0x52, 0x08, 0x6d, 0x6f, 0x6d, 0x65, 0x6e, 0x74, 0x75, 0x6d, 0x12, 0x3e, 0x0a,
	0x08, 0x72, 0x6d, 0x73, 0x5f, 0x70, 0x72, 0x6f, 0x70, 0x18, 0x09, 0x20, 0x01, 0x28, 0x0b, 0x32,
	0x21, 0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x74, 0x70, 0x75,
	0x2e, 0x52, 0x6d, 0x73, 0x50, 0x72, 0x6f, 0x70, 0x50, 0x61, 0x72, 0x61, 0x6d, 0x65, 0x74, 0x65,
	0x72, 0x73, 0x48, 0x00, 0x52, 0x07, 0x72, 0x6d, 0x73, 0x50, 0x72, 0x6f, 0x70, 0x12, 0x57, 0x0a,
	0x11, 0x63, 0x65, 0x6e, 0x74, 0x65, 0x72, 0x65, 0x64, 0x5f, 0x72, 0x6d, 0x73, 0x5f, 0x70, 0x72,
	0x6f, 0x70, 0x18, 0x0a, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x29, 0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f,
	0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x74, 0x70, 0x75, 0x2e, 0x43, 0x65, 0x6e, 0x74, 0x65, 0x72,
	0x65, 0x64, 0x52, 0x6d, 0x73, 0x50, 0x72, 0x6f, 0x70, 0x50, 0x61, 0x72, 0x61, 0x6d, 0x65, 0x74,
	0x65, 0x72, 0x73, 0x48, 0x00, 0x52, 0x0f, 0x63, 0x65, 0x6e, 0x74, 0x65, 0x72, 0x65, 0x64, 0x52,
	0x6d, 0x73, 0x50, 0x72, 0x6f, 0x70, 0x12, 0x57, 0x0a, 0x11, 0x6d, 0x64, 0x6c, 0x5f, 0x61, 0x64,
	0x61, 0x67, 0x72, 0x61, 0x64, 0x5f, 0x6c, 0x69, 0x67, 0x68, 0x74, 0x18, 0x0b, 0x20, 0x01, 0x28,
	0x0b, 0x32, 0x29, 0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x74,
	0x70, 0x75, 0x2e, 0x4d, 0x64, 0x6c, 0x41, 0x64, 0x61, 0x67, 0x72, 0x61, 0x64, 0x4c, 0x69, 0x67,
	0x68, 0x74, 0x50, 0x61, 0x72, 0x61, 0x6d, 0x65, 0x74, 0x65, 0x72, 0x73, 0x48, 0x00, 0x52, 0x0f,
	0x6d, 0x64, 0x6c, 0x41, 0x64, 0x61, 0x67, 0x72, 0x61, 0x64, 0x4c, 0x69, 0x67, 0x68, 0x74, 0x12,
	0x40, 0x0a, 0x08, 0x61, 0x64, 0x61, 0x64, 0x65, 0x6c, 0x74, 0x61, 0x18, 0x0c, 0x20, 0x01, 0x28,
	0x0b, 0x32, 0x22, 0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x74,
	0x70, 0x75, 0x2e, 0x41, 0x64, 0x61, 0x64, 0x65, 0x6c, 0x74, 0x61, 0x50, 0x61, 0x72, 0x61, 0x6d,
	0x65, 0x74, 0x65, 0x72, 0x73, 0x48, 0x00, 0x52, 0x08, 0x61, 0x64, 0x61, 0x64, 0x65, 0x6c, 0x74,
	0x61, 0x12, 0x56, 0x0a, 0x10, 0x70, 0x72, 0x6f, 0x78, 0x69, 0x6d, 0x61, 0x6c, 0x5f, 0x61, 0x64,
	0x61, 0x67, 0x72, 0x61, 0x64, 0x18, 0x0e, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x29, 0x2e, 0x74, 0x65,
	0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x74, 0x70, 0x75, 0x2e, 0x50, 0x72, 0x6f,
	0x78, 0x69, 0x6d, 0x61, 0x6c, 0x41, 0x64, 0x61, 0x67, 0x72, 0x61, 0x64, 0x50, 0x61, 0x72, 0x61,
	0x6d, 0x65, 0x74, 0x65, 0x72, 0x73, 0x48, 0x00, 0x52, 0x0f, 0x70, 0x72, 0x6f, 0x78, 0x69, 0x6d,
	0x61, 0x6c, 0x41, 0x64, 0x61, 0x67, 0x72, 0x61, 0x64, 0x12, 0x47, 0x0a, 0x0b, 0x6f, 0x6e, 0x6c,
	0x69, 0x6e, 0x65, 0x5f, 0x79, 0x6f, 0x67, 0x69, 0x18, 0x14, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x24,
	0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x74, 0x70, 0x75, 0x2e,
	0x4f, 0x6e, 0x6c, 0x69, 0x6e, 0x65, 0x59, 0x6f, 0x67, 0x69, 0x50, 0x61, 0x72, 0x61, 0x6d, 0x65,
	0x74, 0x65, 0x72, 0x73, 0x48, 0x00, 0x52, 0x0a, 0x6f, 0x6e, 0x6c, 0x69, 0x6e, 0x65, 0x59, 0x6f,
	0x67, 0x69, 0x12, 0x4d, 0x0a, 0x0d, 0x70, 0x72, 0x6f, 0x78, 0x69, 0x6d, 0x61, 0x6c, 0x5f, 0x79,
	0x6f, 0x67, 0x69, 0x18, 0x15, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x26, 0x2e, 0x74, 0x65, 0x6e, 0x73,
	0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x74, 0x70, 0x75, 0x2e, 0x50, 0x72, 0x6f, 0x78, 0x69,
	0x6d, 0x61, 0x6c, 0x59, 0x6f, 0x67, 0x69, 0x50, 0x61, 0x72, 0x61, 0x6d, 0x65, 0x74, 0x65, 0x72,
	0x73, 0x48, 0x00, 0x52, 0x0c, 0x70, 0x72, 0x6f, 0x78, 0x69, 0x6d, 0x61, 0x6c, 0x59, 0x6f, 0x67,
	0x69, 0x12, 0x5f, 0x0a, 0x13, 0x66, 0x72, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x63, 0x79, 0x5f, 0x65,
	0x73, 0x74, 0x69, 0x6d, 0x61, 0x74, 0x6f, 0x72, 0x18, 0x17, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x2c,
	0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x74, 0x70, 0x75, 0x2e,
	0x46, 0x72, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x63, 0x79, 0x45, 0x73, 0x74, 0x69, 0x6d, 0x61, 0x74,
	0x6f, 0x72, 0x50, 0x61, 0x72, 0x61, 0x6d, 0x65, 0x74, 0x65, 0x72, 0x73, 0x48, 0x00, 0x52, 0x12,
	0x66, 0x72, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x63, 0x79, 0x45, 0x73, 0x74, 0x69, 0x6d, 0x61, 0x74,
	0x6f, 0x72, 0x12, 0x60, 0x0a, 0x14, 0x75, 0x73, 0x65, 0x72, 0x5f, 0x64, 0x65, 0x66, 0x69, 0x6e,
	0x65, 0x64, 0x5f, 0x70, 0x72, 0x6f, 0x67, 0x72, 0x61, 0x6d, 0x18, 0x18, 0x20, 0x01, 0x28, 0x0b,
	0x32, 0x2c, 0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x74, 0x70,
	0x75, 0x2e, 0x55, 0x73, 0x65, 0x72, 0x44, 0x65, 0x66, 0x69, 0x6e, 0x65, 0x64, 0x50, 0x72, 0x6f,
	0x67, 0x72, 0x61, 0x6d, 0x50, 0x61, 0x72, 0x61, 0x6d, 0x65, 0x74, 0x65, 0x72, 0x73, 0x48, 0x00,
	0x52, 0x12, 0x75, 0x73, 0x65, 0x72, 0x44, 0x65, 0x66, 0x69, 0x6e, 0x65, 0x64, 0x50, 0x72, 0x6f,
	0x67, 0x72, 0x61, 0x6d, 0x12, 0x3a, 0x0a, 0x06, 0x61, 0x73, 0x73, 0x69, 0x67, 0x6e, 0x18, 0x19,
	0x20, 0x01, 0x28, 0x0b, 0x32, 0x20, 0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f,
	0x77, 0x2e, 0x74, 0x70, 0x75, 0x2e, 0x41, 0x73, 0x73, 0x69, 0x67, 0x6e, 0x50, 0x61, 0x72, 0x61,
	0x6d, 0x65, 0x74, 0x65, 0x72, 0x73, 0x48, 0x00, 0x52, 0x06, 0x61, 0x73, 0x73, 0x69, 0x67, 0x6e,
	0x42, 0x0c, 0x0a, 0x0a, 0x70, 0x61, 0x72, 0x61, 0x6d, 0x65, 0x74, 0x65, 0x72, 0x73, 0x4a, 0x04,
	0x08, 0x01, 0x10, 0x02, 0x4a, 0x04, 0x08, 0x0f, 0x10, 0x10, 0x22, 0xd1, 0x02, 0x0a, 0x1a, 0x53,
	0x74, 0x61, 0x74, 0x65, 0x56, 0x61, 0x72, 0x69, 0x61, 0x62, 0x6c, 0x65, 0x53, 0x70, 0x65, 0x63,
	0x69, 0x66, 0x69, 0x63, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x12, 0x12, 0x0a, 0x04, 0x6e, 0x61, 0x6d,
	0x65, 0x18, 0x01, 0x20, 0x01, 0x28, 0x09, 0x52, 0x04, 0x6e, 0x61, 0x6d, 0x65, 0x12, 0x5b, 0x0a,
	0x0c, 0x75, 0x73, 0x65, 0x72, 0x5f, 0x64, 0x65, 0x66, 0x69, 0x6e, 0x65, 0x64, 0x18, 0x02, 0x20,
	0x01, 0x28, 0x0b, 0x32, 0x36, 0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77,
	0x2e, 0x74, 0x70, 0x75, 0x2e, 0x53, 0x74, 0x61, 0x74, 0x65, 0x56, 0x61, 0x72, 0x69, 0x61, 0x62,
	0x6c, 0x65, 0x53, 0x70, 0x65, 0x63, 0x69, 0x66, 0x69, 0x63, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x2e,
	0x55, 0x73, 0x65, 0x72, 0x44, 0x65, 0x66, 0x69, 0x6e, 0x65, 0x64, 0x48, 0x00, 0x52, 0x0b, 0x75,
	0x73, 0x65, 0x72, 0x44, 0x65, 0x66, 0x69, 0x6e, 0x65, 0x64, 0x12, 0x6b, 0x0a, 0x12, 0x66, 0x69,
	0x6c, 0x6c, 0x5f, 0x77, 0x69, 0x74, 0x68, 0x5f, 0x63, 0x6f, 0x6e, 0x73, 0x74, 0x61, 0x6e, 0x74,
	0x18, 0x03, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x3b, 0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66,
	0x6c, 0x6f, 0x77, 0x2e, 0x74, 0x70, 0x75, 0x2e, 0x53, 0x74, 0x61, 0x74, 0x65, 0x56, 0x61, 0x72,
	0x69, 0x61, 0x62, 0x6c, 0x65, 0x53, 0x70, 0x65, 0x63, 0x69, 0x66, 0x69, 0x63, 0x61, 0x74, 0x69,
	0x6f, 0x6e, 0x2e, 0x46, 0x69, 0x6c, 0x6c, 0x57, 0x69, 0x74, 0x68, 0x43, 0x6f, 0x6e, 0x73, 0x74,
	0x61, 0x6e, 0x74, 0x48, 0x00, 0x52, 0x10, 0x66, 0x69, 0x6c, 0x6c, 0x57, 0x69, 0x74, 0x68, 0x43,
	0x6f, 0x6e, 0x73, 0x74, 0x61, 0x6e, 0x74, 0x1a, 0x13, 0x0a, 0x0b, 0x55, 0x73, 0x65, 0x72, 0x44,
	0x65, 0x66, 0x69, 0x6e, 0x65, 0x64, 0x4a, 0x04, 0x08, 0x01, 0x10, 0x02, 0x1a, 0x37, 0x0a, 0x10,
	0x46, 0x69, 0x6c, 0x6c, 0x57, 0x69, 0x74, 0x68, 0x43, 0x6f, 0x6e, 0x73, 0x74, 0x61, 0x6e, 0x74,
	0x12, 0x23, 0x0a, 0x0d, 0x69, 0x6e, 0x69, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x76, 0x61, 0x6c, 0x75,
	0x65, 0x18, 0x01, 0x20, 0x01, 0x28, 0x01, 0x52, 0x0c, 0x69, 0x6e, 0x69, 0x74, 0x69, 0x61, 0x6c,
	0x56, 0x61, 0x6c, 0x75, 0x65, 0x42, 0x07, 0x0a, 0x05, 0x75, 0x73, 0x61, 0x67, 0x65, 0x42, 0xc9,
	0x01, 0x0a, 0x12, 0x63, 0x6f, 0x6d, 0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f,
	0x77, 0x2e, 0x74, 0x70, 0x75, 0x42, 0x1b, 0x4f, 0x70, 0x74, 0x69, 0x6d, 0x69, 0x7a, 0x61, 0x74,
	0x69, 0x6f, 0x6e, 0x50, 0x61, 0x72, 0x61, 0x6d, 0x65, 0x74, 0x65, 0x72, 0x73, 0x50, 0x72, 0x6f,
	0x74, 0x6f, 0x48, 0x02, 0x50, 0x01, 0x5a, 0x3b, 0x67, 0x69, 0x74, 0x65, 0x65, 0x2e, 0x63, 0x6f,
	0x6d, 0x2f, 0x71, 0x63, 0x69, 0x69, 0x70, 0x2d, 0x69, 0x63, 0x70, 0x2f, 0x74, 0x66, 0x2d, 0x73,
	0x65, 0x72, 0x76, 0x69, 0x6e, 0x67, 0x2f, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f,
	0x77, 0x2f, 0x63, 0x6f, 0x72, 0x65, 0x2f, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x62, 0x75, 0x66, 0x2f,
	0x74, 0x70, 0x75, 0xa2, 0x02, 0x03, 0x54, 0x54, 0x58, 0xaa, 0x02, 0x0e, 0x54, 0x65, 0x6e, 0x73,
	0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x54, 0x70, 0x75, 0xca, 0x02, 0x0e, 0x54, 0x65, 0x6e,
	0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x5c, 0x54, 0x70, 0x75, 0xe2, 0x02, 0x1a, 0x54, 0x65,
	0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x5c, 0x54, 0x70, 0x75, 0x5c, 0x47, 0x50, 0x42,
	0x4d, 0x65, 0x74, 0x61, 0x64, 0x61, 0x74, 0x61, 0xea, 0x02, 0x0f, 0x54, 0x65, 0x6e, 0x73, 0x6f,
	0x72, 0x66, 0x6c, 0x6f, 0x77, 0x3a, 0x3a, 0x54, 0x70, 0x75, 0x62, 0x06, 0x70, 0x72, 0x6f, 0x74,
	0x6f, 0x33,
}

var (
	file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescOnce sync.Once
	file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescData = file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDesc
)

func file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescGZIP() []byte {
	file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescOnce.Do(func() {
		file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescData = protoimpl.X.CompressGZIP(file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescData)
	})
	return file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDescData
}

var file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_enumTypes = make([]protoimpl.EnumInfo, 3)
var file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes = make([]protoimpl.MessageInfo, 28)
var file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_goTypes = []interface{}{
	(GradientAccumulationStatus_Status)(0),              // 0: tensorflow.tpu.GradientAccumulationStatus.Status
	(LowDimensionalPackingStatus_Status)(0),             // 1: tensorflow.tpu.LowDimensionalPackingStatus.Status
	(HotIdReplicationConfiguration_Status)(0),           // 2: tensorflow.tpu.HotIdReplicationConfiguration.Status
	(*ClippingLimits)(nil),                              // 3: tensorflow.tpu.ClippingLimits
	(*SimulatedQuantization)(nil),                       // 4: tensorflow.tpu.SimulatedQuantization
	(*DynamicLearningRate)(nil),                         // 5: tensorflow.tpu.DynamicLearningRate
	(*LearningRate)(nil),                                // 6: tensorflow.tpu.LearningRate
	(*AdagradParameters)(nil),                           // 7: tensorflow.tpu.AdagradParameters
	(*AdagradMomentumParameters)(nil),                   // 8: tensorflow.tpu.AdagradMomentumParameters
	(*BoundedAdagradParameters)(nil),                    // 9: tensorflow.tpu.BoundedAdagradParameters
	(*StochasticGradientDescentParameters)(nil),         // 10: tensorflow.tpu.StochasticGradientDescentParameters
	(*FtrlParameters)(nil),                              // 11: tensorflow.tpu.FtrlParameters
	(*AdamParameters)(nil),                              // 12: tensorflow.tpu.AdamParameters
	(*MomentumParameters)(nil),                          // 13: tensorflow.tpu.MomentumParameters
	(*RmsPropParameters)(nil),                           // 14: tensorflow.tpu.RmsPropParameters
	(*CenteredRmsPropParameters)(nil),                   // 15: tensorflow.tpu.CenteredRmsPropParameters
	(*MdlAdagradLightParameters)(nil),                   // 16: tensorflow.tpu.MdlAdagradLightParameters
	(*AdadeltaParameters)(nil),                          // 17: tensorflow.tpu.AdadeltaParameters
	(*ProximalAdagradParameters)(nil),                   // 18: tensorflow.tpu.ProximalAdagradParameters
	(*OnlineYogiParameters)(nil),                        // 19: tensorflow.tpu.OnlineYogiParameters
	(*ProximalYogiParameters)(nil),                      // 20: tensorflow.tpu.ProximalYogiParameters
	(*FrequencyEstimatorParameters)(nil),                // 21: tensorflow.tpu.FrequencyEstimatorParameters
	(*UserDefinedProgramParameters)(nil),                // 22: tensorflow.tpu.UserDefinedProgramParameters
	(*AssignParameters)(nil),                            // 23: tensorflow.tpu.AssignParameters
	(*GradientAccumulationStatus)(nil),                  // 24: tensorflow.tpu.GradientAccumulationStatus
	(*LowDimensionalPackingStatus)(nil),                 // 25: tensorflow.tpu.LowDimensionalPackingStatus
	(*HotIdReplicationConfiguration)(nil),               // 26: tensorflow.tpu.HotIdReplicationConfiguration
	(*OptimizationParameters)(nil),                      // 27: tensorflow.tpu.OptimizationParameters
	(*StateVariableSpecification)(nil),                  // 28: tensorflow.tpu.StateVariableSpecification
	(*StateVariableSpecification_UserDefined)(nil),      // 29: tensorflow.tpu.StateVariableSpecification.UserDefined
	(*StateVariableSpecification_FillWithConstant)(nil), // 30: tensorflow.tpu.StateVariableSpecification.FillWithConstant
	(*wrapperspb.FloatValue)(nil),                       // 31: google.protobuf.FloatValue
	(*service.HloModuleProto)(nil),                      // 32: xla.HloModuleProto
}
var file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_depIdxs = []int32{
	31, // 0: tensorflow.tpu.ClippingLimits.lower:type_name -> google.protobuf.FloatValue
	31, // 1: tensorflow.tpu.ClippingLimits.upper:type_name -> google.protobuf.FloatValue
	3,  // 2: tensorflow.tpu.SimulatedQuantization.clipping_limits:type_name -> tensorflow.tpu.ClippingLimits
	5,  // 3: tensorflow.tpu.LearningRate.dynamic:type_name -> tensorflow.tpu.DynamicLearningRate
	32, // 4: tensorflow.tpu.UserDefinedProgramParameters.program:type_name -> xla.HloModuleProto
	2,  // 5: tensorflow.tpu.HotIdReplicationConfiguration.status:type_name -> tensorflow.tpu.HotIdReplicationConfiguration.Status
	6,  // 6: tensorflow.tpu.OptimizationParameters.learning_rate:type_name -> tensorflow.tpu.LearningRate
	3,  // 7: tensorflow.tpu.OptimizationParameters.clipping_limits:type_name -> tensorflow.tpu.ClippingLimits
	3,  // 8: tensorflow.tpu.OptimizationParameters.gradient_clipping_limits:type_name -> tensorflow.tpu.ClippingLimits
	4,  // 9: tensorflow.tpu.OptimizationParameters.simulated_quantization:type_name -> tensorflow.tpu.SimulatedQuantization
	0,  // 10: tensorflow.tpu.OptimizationParameters.gradient_accumulation_status:type_name -> tensorflow.tpu.GradientAccumulationStatus.Status
	1,  // 11: tensorflow.tpu.OptimizationParameters.low_dimensional_packing_status:type_name -> tensorflow.tpu.LowDimensionalPackingStatus.Status
	26, // 12: tensorflow.tpu.OptimizationParameters.hot_id_replication_configuration:type_name -> tensorflow.tpu.HotIdReplicationConfiguration
	7,  // 13: tensorflow.tpu.OptimizationParameters.adagrad:type_name -> tensorflow.tpu.AdagradParameters
	8,  // 14: tensorflow.tpu.OptimizationParameters.adagrad_momentum:type_name -> tensorflow.tpu.AdagradMomentumParameters
	9,  // 15: tensorflow.tpu.OptimizationParameters.bounded_adagrad:type_name -> tensorflow.tpu.BoundedAdagradParameters
	10, // 16: tensorflow.tpu.OptimizationParameters.stochastic_gradient_descent:type_name -> tensorflow.tpu.StochasticGradientDescentParameters
	11, // 17: tensorflow.tpu.OptimizationParameters.ftrl:type_name -> tensorflow.tpu.FtrlParameters
	12, // 18: tensorflow.tpu.OptimizationParameters.adam:type_name -> tensorflow.tpu.AdamParameters
	13, // 19: tensorflow.tpu.OptimizationParameters.momentum:type_name -> tensorflow.tpu.MomentumParameters
	14, // 20: tensorflow.tpu.OptimizationParameters.rms_prop:type_name -> tensorflow.tpu.RmsPropParameters
	15, // 21: tensorflow.tpu.OptimizationParameters.centered_rms_prop:type_name -> tensorflow.tpu.CenteredRmsPropParameters
	16, // 22: tensorflow.tpu.OptimizationParameters.mdl_adagrad_light:type_name -> tensorflow.tpu.MdlAdagradLightParameters
	17, // 23: tensorflow.tpu.OptimizationParameters.adadelta:type_name -> tensorflow.tpu.AdadeltaParameters
	18, // 24: tensorflow.tpu.OptimizationParameters.proximal_adagrad:type_name -> tensorflow.tpu.ProximalAdagradParameters
	19, // 25: tensorflow.tpu.OptimizationParameters.online_yogi:type_name -> tensorflow.tpu.OnlineYogiParameters
	20, // 26: tensorflow.tpu.OptimizationParameters.proximal_yogi:type_name -> tensorflow.tpu.ProximalYogiParameters
	21, // 27: tensorflow.tpu.OptimizationParameters.frequency_estimator:type_name -> tensorflow.tpu.FrequencyEstimatorParameters
	22, // 28: tensorflow.tpu.OptimizationParameters.user_defined_program:type_name -> tensorflow.tpu.UserDefinedProgramParameters
	23, // 29: tensorflow.tpu.OptimizationParameters.assign:type_name -> tensorflow.tpu.AssignParameters
	29, // 30: tensorflow.tpu.StateVariableSpecification.user_defined:type_name -> tensorflow.tpu.StateVariableSpecification.UserDefined
	30, // 31: tensorflow.tpu.StateVariableSpecification.fill_with_constant:type_name -> tensorflow.tpu.StateVariableSpecification.FillWithConstant
	32, // [32:32] is the sub-list for method output_type
	32, // [32:32] is the sub-list for method input_type
	32, // [32:32] is the sub-list for extension type_name
	32, // [32:32] is the sub-list for extension extendee
	0,  // [0:32] is the sub-list for field type_name
}

func init() { file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_init() }
func file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_init() {
	if File_tensorflow_core_protobuf_tpu_optimization_parameters_proto != nil {
		return
	}
	if !protoimpl.UnsafeEnabled {
		file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[0].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*ClippingLimits); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[1].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*SimulatedQuantization); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[2].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*DynamicLearningRate); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[3].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*LearningRate); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[4].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*AdagradParameters); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[5].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*AdagradMomentumParameters); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[6].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*BoundedAdagradParameters); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[7].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*StochasticGradientDescentParameters); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[8].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*FtrlParameters); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[9].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*AdamParameters); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[10].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*MomentumParameters); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[11].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*RmsPropParameters); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[12].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*CenteredRmsPropParameters); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[13].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*MdlAdagradLightParameters); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[14].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*AdadeltaParameters); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[15].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*ProximalAdagradParameters); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[16].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*OnlineYogiParameters); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[17].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*ProximalYogiParameters); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[18].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*FrequencyEstimatorParameters); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[19].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*UserDefinedProgramParameters); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[20].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*AssignParameters); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[21].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*GradientAccumulationStatus); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[22].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*LowDimensionalPackingStatus); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[23].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*HotIdReplicationConfiguration); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[24].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*OptimizationParameters); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[25].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*StateVariableSpecification); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[26].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*StateVariableSpecification_UserDefined); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[27].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*StateVariableSpecification_FillWithConstant); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
	}
	file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[3].OneofWrappers = []interface{}{
		(*LearningRate_Constant)(nil),
		(*LearningRate_Dynamic)(nil),
	}
	file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[24].OneofWrappers = []interface{}{
		(*OptimizationParameters_Adagrad)(nil),
		(*OptimizationParameters_AdagradMomentum)(nil),
		(*OptimizationParameters_BoundedAdagrad)(nil),
		(*OptimizationParameters_StochasticGradientDescent)(nil),
		(*OptimizationParameters_Ftrl)(nil),
		(*OptimizationParameters_Adam)(nil),
		(*OptimizationParameters_Momentum)(nil),
		(*OptimizationParameters_RmsProp)(nil),
		(*OptimizationParameters_CenteredRmsProp)(nil),
		(*OptimizationParameters_MdlAdagradLight)(nil),
		(*OptimizationParameters_Adadelta)(nil),
		(*OptimizationParameters_ProximalAdagrad)(nil),
		(*OptimizationParameters_OnlineYogi)(nil),
		(*OptimizationParameters_ProximalYogi)(nil),
		(*OptimizationParameters_FrequencyEstimator)(nil),
		(*OptimizationParameters_UserDefinedProgram)(nil),
		(*OptimizationParameters_Assign)(nil),
	}
	file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes[25].OneofWrappers = []interface{}{
		(*StateVariableSpecification_UserDefined_)(nil),
		(*StateVariableSpecification_FillWithConstant_)(nil),
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDesc,
			NumEnums:      3,
			NumMessages:   28,
			NumExtensions: 0,
			NumServices:   0,
		},
		GoTypes:           file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_goTypes,
		DependencyIndexes: file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_depIdxs,
		EnumInfos:         file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_enumTypes,
		MessageInfos:      file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_msgTypes,
	}.Build()
	File_tensorflow_core_protobuf_tpu_optimization_parameters_proto = out.File
	file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_rawDesc = nil
	file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_goTypes = nil
	file_tensorflow_core_protobuf_tpu_optimization_parameters_proto_depIdxs = nil
}
