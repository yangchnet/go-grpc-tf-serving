// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.28.1
// 	protoc        (unknown)
// source: tensorflow/compiler/mlir/quantization/tensorflow/quantization_options.proto

package tensorflow

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// Quantization precisions. If the specified quantization
// precision is not available, our quantizer needs to raise an error.
type QuantizationPrecision int32

const (
	QuantizationPrecision_PRECISION_UNSPECIFIED QuantizationPrecision = 0
	// Full Precision (Do not quantize)
	QuantizationPrecision_PRECISION_FULL QuantizationPrecision = 1
	// Weight 4 bit and activation 4 bit quantization
	QuantizationPrecision_PRECISION_W4A4 QuantizationPrecision = 2
	// Weight 4 bit and activation 8 bit quantization
	QuantizationPrecision_PRECISION_W4A8 QuantizationPrecision = 3
	// Weight 8 bit and activation 8 bit quantization
	QuantizationPrecision_PRECISION_W8A8 QuantizationPrecision = 4
)

// Enum value maps for QuantizationPrecision.
var (
	QuantizationPrecision_name = map[int32]string{
		0: "PRECISION_UNSPECIFIED",
		1: "PRECISION_FULL",
		2: "PRECISION_W4A4",
		3: "PRECISION_W4A8",
		4: "PRECISION_W8A8",
	}
	QuantizationPrecision_value = map[string]int32{
		"PRECISION_UNSPECIFIED": 0,
		"PRECISION_FULL":        1,
		"PRECISION_W4A4":        2,
		"PRECISION_W4A8":        3,
		"PRECISION_W8A8":        4,
	}
)

func (x QuantizationPrecision) Enum() *QuantizationPrecision {
	p := new(QuantizationPrecision)
	*p = x
	return p
}

func (x QuantizationPrecision) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (QuantizationPrecision) Descriptor() protoreflect.EnumDescriptor {
	return file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_enumTypes[0].Descriptor()
}

func (QuantizationPrecision) Type() protoreflect.EnumType {
	return &file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_enumTypes[0]
}

func (x QuantizationPrecision) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use QuantizationPrecision.Descriptor instead.
func (QuantizationPrecision) EnumDescriptor() ([]byte, []int) {
	return file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_rawDescGZIP(), []int{0}
}

// List of supported opsets to deploy the quantized model.
// The quantized model contains different set of ops depending on the opset.
type OpSet int32

const (
	OpSet_OP_SET_UNSPECIFIED OpSet = 0 // go/do-include-enum-unspecified
	// Uses TF ops that mimic quantization behavior. Used when the corresponding
	// integer op is not yet present.
	OpSet_TF OpSet = 1
	// Uses TF XLA ops
	OpSet_XLA OpSet = 2
	// Uses TF Uniform Quantized ops
	OpSet_UNIFORM_QUANTIZED OpSet = 3
)

// Enum value maps for OpSet.
var (
	OpSet_name = map[int32]string{
		0: "OP_SET_UNSPECIFIED",
		1: "TF",
		2: "XLA",
		3: "UNIFORM_QUANTIZED",
	}
	OpSet_value = map[string]int32{
		"OP_SET_UNSPECIFIED": 0,
		"TF":                 1,
		"XLA":                2,
		"UNIFORM_QUANTIZED":  3,
	}
)

func (x OpSet) Enum() *OpSet {
	p := new(OpSet)
	*p = x
	return p
}

func (x OpSet) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (OpSet) Descriptor() protoreflect.EnumDescriptor {
	return file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_enumTypes[1].Descriptor()
}

func (OpSet) Type() protoreflect.EnumType {
	return &file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_enumTypes[1]
}

func (x OpSet) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use OpSet.Descriptor instead.
func (OpSet) EnumDescriptor() ([]byte, []int) {
	return file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_rawDescGZIP(), []int{1}
}

// Quantization methods that are supported as a stable API.
type QuantizationMethod_Method int32

const (
	// This should never be used. Using this will generally result in an error.
	QuantizationMethod_METHOD_UNSPECIFIED QuantizationMethod_Method = 0 // go/do-include-enum-unspecified
)

// Enum value maps for QuantizationMethod_Method.
var (
	QuantizationMethod_Method_name = map[int32]string{
		0: "METHOD_UNSPECIFIED",
	}
	QuantizationMethod_Method_value = map[string]int32{
		"METHOD_UNSPECIFIED": 0,
	}
)

func (x QuantizationMethod_Method) Enum() *QuantizationMethod_Method {
	p := new(QuantizationMethod_Method)
	*p = x
	return p
}

func (x QuantizationMethod_Method) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (QuantizationMethod_Method) Descriptor() protoreflect.EnumDescriptor {
	return file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_enumTypes[2].Descriptor()
}

func (QuantizationMethod_Method) Type() protoreflect.EnumType {
	return &file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_enumTypes[2]
}

func (x QuantizationMethod_Method) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use QuantizationMethod_Method.Descriptor instead.
func (QuantizationMethod_Method) EnumDescriptor() ([]byte, []int) {
	return file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_rawDescGZIP(), []int{0, 0}
}

// Experimental quantization methods.
// These methods are either not implemented or provided with an unstable
// behavior.
type QuantizationMethod_ExperimentalMethod int32

const (
	// This should never be used. Using this will generally result in an error.
	QuantizationMethod_EXPERIMENTAL_METHOD_UNSPECIFIED QuantizationMethod_ExperimentalMethod = 0 // go/do-include-enum-unspecified
	// Static range quantization. Quantized tensor values' ranges are statically
	// determined.
	QuantizationMethod_STATIC_RANGE QuantizationMethod_ExperimentalMethod = 1
	// Dynamic range quantization. Quantized tensor values' ranges are
	// determined in the graph executions. The weights are quantized during
	// conversion.
	QuantizationMethod_DYNAMIC_RANGE QuantizationMethod_ExperimentalMethod = 2
	// Weight-only quantization. Only weights are quantized during conversion.
	QuantizationMethod_WEIGHT_ONLY QuantizationMethod_ExperimentalMethod = 3
)

// Enum value maps for QuantizationMethod_ExperimentalMethod.
var (
	QuantizationMethod_ExperimentalMethod_name = map[int32]string{
		0: "EXPERIMENTAL_METHOD_UNSPECIFIED",
		1: "STATIC_RANGE",
		2: "DYNAMIC_RANGE",
		3: "WEIGHT_ONLY",
	}
	QuantizationMethod_ExperimentalMethod_value = map[string]int32{
		"EXPERIMENTAL_METHOD_UNSPECIFIED": 0,
		"STATIC_RANGE":                    1,
		"DYNAMIC_RANGE":                   2,
		"WEIGHT_ONLY":                     3,
	}
)

func (x QuantizationMethod_ExperimentalMethod) Enum() *QuantizationMethod_ExperimentalMethod {
	p := new(QuantizationMethod_ExperimentalMethod)
	*p = x
	return p
}

func (x QuantizationMethod_ExperimentalMethod) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (QuantizationMethod_ExperimentalMethod) Descriptor() protoreflect.EnumDescriptor {
	return file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_enumTypes[3].Descriptor()
}

func (QuantizationMethod_ExperimentalMethod) Type() protoreflect.EnumType {
	return &file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_enumTypes[3]
}

func (x QuantizationMethod_ExperimentalMethod) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use QuantizationMethod_ExperimentalMethod.Descriptor instead.
func (QuantizationMethod_ExperimentalMethod) EnumDescriptor() ([]byte, []int) {
	return file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_rawDescGZIP(), []int{0, 1}
}

// Quantization unit granularity.
type UnitWiseQuantizationPrecision_UnitType int32

const (
	// This should never be used. Using this will generally result in an error.
	UnitWiseQuantizationPrecision_UNIT_UNSPECIFIED UnitWiseQuantizationPrecision_UnitType = 0
	UnitWiseQuantizationPrecision_UNIT_NODE        UnitWiseQuantizationPrecision_UnitType = 1
	UnitWiseQuantizationPrecision_UNIT_OP          UnitWiseQuantizationPrecision_UnitType = 2
)

// Enum value maps for UnitWiseQuantizationPrecision_UnitType.
var (
	UnitWiseQuantizationPrecision_UnitType_name = map[int32]string{
		0: "UNIT_UNSPECIFIED",
		1: "UNIT_NODE",
		2: "UNIT_OP",
	}
	UnitWiseQuantizationPrecision_UnitType_value = map[string]int32{
		"UNIT_UNSPECIFIED": 0,
		"UNIT_NODE":        1,
		"UNIT_OP":          2,
	}
)

func (x UnitWiseQuantizationPrecision_UnitType) Enum() *UnitWiseQuantizationPrecision_UnitType {
	p := new(UnitWiseQuantizationPrecision_UnitType)
	*p = x
	return p
}

func (x UnitWiseQuantizationPrecision_UnitType) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (UnitWiseQuantizationPrecision_UnitType) Descriptor() protoreflect.EnumDescriptor {
	return file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_enumTypes[4].Descriptor()
}

func (UnitWiseQuantizationPrecision_UnitType) Type() protoreflect.EnumType {
	return &file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_enumTypes[4]
}

func (x UnitWiseQuantizationPrecision_UnitType) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use UnitWiseQuantizationPrecision_UnitType.Descriptor instead.
func (UnitWiseQuantizationPrecision_UnitType) EnumDescriptor() ([]byte, []int) {
	return file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_rawDescGZIP(), []int{1, 0}
}

// Model quantization method for optimization.
//
// Various techniques for model quantization are defined within this message
// along with a field that specifies a method to be used for a particular
// quantization request.
type QuantizationMethod struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// Quantization method is either exprimental or non-experimental method.
	//
	// Types that are assignable to MethodOneof:
	//
	//	*QuantizationMethod_Method_
	//	*QuantizationMethod_ExperimentalMethod_
	MethodOneof isQuantizationMethod_MethodOneof `protobuf_oneof:"method_oneof"`
}

func (x *QuantizationMethod) Reset() {
	*x = QuantizationMethod{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_msgTypes[0]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *QuantizationMethod) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*QuantizationMethod) ProtoMessage() {}

func (x *QuantizationMethod) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_msgTypes[0]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use QuantizationMethod.ProtoReflect.Descriptor instead.
func (*QuantizationMethod) Descriptor() ([]byte, []int) {
	return file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_rawDescGZIP(), []int{0}
}

func (m *QuantizationMethod) GetMethodOneof() isQuantizationMethod_MethodOneof {
	if m != nil {
		return m.MethodOneof
	}
	return nil
}

func (x *QuantizationMethod) GetMethod() QuantizationMethod_Method {
	if x, ok := x.GetMethodOneof().(*QuantizationMethod_Method_); ok {
		return x.Method
	}
	return QuantizationMethod_METHOD_UNSPECIFIED
}

func (x *QuantizationMethod) GetExperimentalMethod() QuantizationMethod_ExperimentalMethod {
	if x, ok := x.GetMethodOneof().(*QuantizationMethod_ExperimentalMethod_); ok {
		return x.ExperimentalMethod
	}
	return QuantizationMethod_EXPERIMENTAL_METHOD_UNSPECIFIED
}

type isQuantizationMethod_MethodOneof interface {
	isQuantizationMethod_MethodOneof()
}

type QuantizationMethod_Method_ struct {
	Method QuantizationMethod_Method `protobuf:"varint,1,opt,name=method,proto3,enum=tensorflow.quantization.QuantizationMethod_Method,oneof"`
}

type QuantizationMethod_ExperimentalMethod_ struct {
	ExperimentalMethod QuantizationMethod_ExperimentalMethod `protobuf:"varint,2,opt,name=experimental_method,json=experimentalMethod,proto3,enum=tensorflow.quantization.QuantizationMethod_ExperimentalMethod,oneof"`
}

func (*QuantizationMethod_Method_) isQuantizationMethod_MethodOneof() {}

func (*QuantizationMethod_ExperimentalMethod_) isQuantizationMethod_MethodOneof() {}

// Unit (either nodes or ops at this moment) wise quantization method for
// mixed bit precision quantization. It contains the name of the unit,
// the granularity of the unit, and the quantization method for each unit.
type UnitWiseQuantizationPrecision struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// Available quantization unit. Currently node-wise and op-wise are
	// available quantization units.
	UnitType UnitWiseQuantizationPrecision_UnitType `protobuf:"varint,1,opt,name=unit_type,json=unitType,proto3,enum=tensorflow.quantization.UnitWiseQuantizationPrecision_UnitType" json:"unit_type,omitempty"`
	// Uniqueness isn't guaranteed across SavedModels but within each function
	// def's level, uniqueness is guaranteed. Updated
	// the configuration interfaces to reflect such circumstances.
	// If users do not need to guarantee uniqueness func_name can be omitted.
	FuncName string `protobuf:"bytes,2,opt,name=func_name,json=funcName,proto3" json:"func_name,omitempty"`
	UnitName string `protobuf:"bytes,3,opt,name=unit_name,json=unitName,proto3" json:"unit_name,omitempty"`
	// Quantization option information for the current unit.
	// TODO(b/241322587): Support specifying quantization method for each unit of
	// TF GraphDef.
	QuantizationPrecision QuantizationPrecision `protobuf:"varint,5,opt,name=quantization_precision,json=quantizationPrecision,proto3,enum=tensorflow.quantization.QuantizationPrecision" json:"quantization_precision,omitempty"`
}

func (x *UnitWiseQuantizationPrecision) Reset() {
	*x = UnitWiseQuantizationPrecision{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_msgTypes[1]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *UnitWiseQuantizationPrecision) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UnitWiseQuantizationPrecision) ProtoMessage() {}

func (x *UnitWiseQuantizationPrecision) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_msgTypes[1]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UnitWiseQuantizationPrecision.ProtoReflect.Descriptor instead.
func (*UnitWiseQuantizationPrecision) Descriptor() ([]byte, []int) {
	return file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_rawDescGZIP(), []int{1}
}

func (x *UnitWiseQuantizationPrecision) GetUnitType() UnitWiseQuantizationPrecision_UnitType {
	if x != nil {
		return x.UnitType
	}
	return UnitWiseQuantizationPrecision_UNIT_UNSPECIFIED
}

func (x *UnitWiseQuantizationPrecision) GetFuncName() string {
	if x != nil {
		return x.FuncName
	}
	return ""
}

func (x *UnitWiseQuantizationPrecision) GetUnitName() string {
	if x != nil {
		return x.UnitName
	}
	return ""
}

func (x *UnitWiseQuantizationPrecision) GetQuantizationPrecision() QuantizationPrecision {
	if x != nil {
		return x.QuantizationPrecision
	}
	return QuantizationPrecision_PRECISION_UNSPECIFIED
}

// Configurations for variable freezing during quantization passes.
type FreezeAllVariables struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// Setting this to true freezes all variables to constants during
	// quantization. Setting this to `false` is an experimental feature and does
	// not have stability guarantees.
	Enabled bool `protobuf:"varint,1,opt,name=enabled,proto3" json:"enabled,omitempty"`
}

func (x *FreezeAllVariables) Reset() {
	*x = FreezeAllVariables{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_msgTypes[2]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *FreezeAllVariables) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*FreezeAllVariables) ProtoMessage() {}

func (x *FreezeAllVariables) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_msgTypes[2]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use FreezeAllVariables.ProtoReflect.Descriptor instead.
func (*FreezeAllVariables) Descriptor() ([]byte, []int) {
	return file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_rawDescGZIP(), []int{2}
}

func (x *FreezeAllVariables) GetEnabled() bool {
	if x != nil {
		return x.Enabled
	}
	return false
}

// Defines various options to specify and control the behavior of the quantizer.
// It consists of
// 1) Model-wise quantization configuration as a default configuration. If it is
// None, the default configuration is "do not quantize the model".
// 2) A set of supported operations.
// 3) Unit wise quantization precision.
// 4) Target hardware name.
type QuantizationOptions struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// The default quantization configuration for the model. If the below
	// unit-wise configuration does not exist, we use this default quantization
	// configuration for the entire model. If the below unit-wise configuration
	// exists, this default one will become the quantization configuration for
	// units that are not specified in unit-wise configurations.
	QuantizationMethod    *QuantizationMethod   `protobuf:"bytes,1,opt,name=quantization_method,json=quantizationMethod,proto3" json:"quantization_method,omitempty"`
	OpSet                 OpSet                 `protobuf:"varint,2,opt,name=op_set,json=opSet,proto3,enum=tensorflow.quantization.OpSet" json:"op_set,omitempty"` // If not specified, it defaults to `TF`.
	QuantizationPrecision QuantizationPrecision `protobuf:"varint,3,opt,name=quantization_precision,json=quantizationPrecision,proto3,enum=tensorflow.quantization.QuantizationPrecision" json:"quantization_precision,omitempty"`
	// Quantization precision for each unit. Units can become either
	// nodes or ops, and the mixture of those different units are allowed.
	// If there are conflicts or ambiguity in this unit-wise precision, our
	// quantizer will raise an error.
	UnitWiseQuantizationPrecision []*UnitWiseQuantizationPrecision `protobuf:"bytes,4,rep,name=unit_wise_quantization_precision,json=unitWiseQuantizationPrecision,proto3" json:"unit_wise_quantization_precision,omitempty"`
	// Minimum number of weight elements to apply quantization. Currently only
	// supported for Post-training Dynamic Range Quantization. By default, it is
	// set to 1024. To disable this, set the value to -1 explicitly.
	MinNumElementsForWeights int64 `protobuf:"varint,5,opt,name=min_num_elements_for_weights,json=minNumElementsForWeights,proto3" json:"min_num_elements_for_weights,omitempty"`
	// When set to `true`, freezes all variables in the model into constants.
	// When set to `false` the model's large constants are converted to variables.
	// Setting this to `false` is an experimental feature and quantization may
	// fail. To quantize models larger than 2 GiB, this should be set to `false`.
	// If not set, it defaults to `true`.
	FreezeAllVariables *FreezeAllVariables `protobuf:"bytes,6,opt,name=freeze_all_variables,json=freezeAllVariables,proto3" json:"freeze_all_variables,omitempty"`
	// Enables chnanel-wise quantizaiton. By default, channel-wise quantization is
	// not applied regardless of the op support. Currently, it is supported for
	// Uniform Quantized opset only.
	EnablePerChannelQuantization bool `protobuf:"varint,7,opt,name=enable_per_channel_quantization,json=enablePerChannelQuantization,proto3" json:"enable_per_channel_quantization,omitempty"`
	// Enables two inputs of an operation to be both tensors.
	// Currently supports MatMul and BatchMatMul ops for XLA.
	// TODO(b/263528090): Check the condition when this feature is beneficial.
	EnableTwoInputTensors bool `protobuf:"varint,8,opt,name=enable_two_input_tensors,json=enableTwoInputTensors,proto3" json:"enable_two_input_tensors,omitempty"`
}

func (x *QuantizationOptions) Reset() {
	*x = QuantizationOptions{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_msgTypes[3]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *QuantizationOptions) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*QuantizationOptions) ProtoMessage() {}

func (x *QuantizationOptions) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_msgTypes[3]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use QuantizationOptions.ProtoReflect.Descriptor instead.
func (*QuantizationOptions) Descriptor() ([]byte, []int) {
	return file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_rawDescGZIP(), []int{3}
}

func (x *QuantizationOptions) GetQuantizationMethod() *QuantizationMethod {
	if x != nil {
		return x.QuantizationMethod
	}
	return nil
}

func (x *QuantizationOptions) GetOpSet() OpSet {
	if x != nil {
		return x.OpSet
	}
	return OpSet_OP_SET_UNSPECIFIED
}

func (x *QuantizationOptions) GetQuantizationPrecision() QuantizationPrecision {
	if x != nil {
		return x.QuantizationPrecision
	}
	return QuantizationPrecision_PRECISION_UNSPECIFIED
}

func (x *QuantizationOptions) GetUnitWiseQuantizationPrecision() []*UnitWiseQuantizationPrecision {
	if x != nil {
		return x.UnitWiseQuantizationPrecision
	}
	return nil
}

func (x *QuantizationOptions) GetMinNumElementsForWeights() int64 {
	if x != nil {
		return x.MinNumElementsForWeights
	}
	return 0
}

func (x *QuantizationOptions) GetFreezeAllVariables() *FreezeAllVariables {
	if x != nil {
		return x.FreezeAllVariables
	}
	return nil
}

func (x *QuantizationOptions) GetEnablePerChannelQuantization() bool {
	if x != nil {
		return x.EnablePerChannelQuantization
	}
	return false
}

func (x *QuantizationOptions) GetEnableTwoInputTensors() bool {
	if x != nil {
		return x.EnableTwoInputTensors
	}
	return false
}

var File_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto protoreflect.FileDescriptor

var file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_rawDesc = []byte{
	0x0a, 0x4b, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2f, 0x63, 0x6f, 0x6d,
	0x70, 0x69, 0x6c, 0x65, 0x72, 0x2f, 0x6d, 0x6c, 0x69, 0x72, 0x2f, 0x71, 0x75, 0x61, 0x6e, 0x74,
	0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x2f, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c,
	0x6f, 0x77, 0x2f, 0x71, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x5f,
	0x6f, 0x70, 0x74, 0x69, 0x6f, 0x6e, 0x73, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x12, 0x17, 0x74,
	0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x71, 0x75, 0x61, 0x6e, 0x74, 0x69,
	0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x22, 0xf8, 0x02, 0x0a, 0x12, 0x51, 0x75, 0x61, 0x6e, 0x74,
	0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x4d, 0x65, 0x74, 0x68, 0x6f, 0x64, 0x12, 0x4c, 0x0a,
	0x06, 0x6d, 0x65, 0x74, 0x68, 0x6f, 0x64, 0x18, 0x01, 0x20, 0x01, 0x28, 0x0e, 0x32, 0x32, 0x2e,
	0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x71, 0x75, 0x61, 0x6e, 0x74,
	0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x2e, 0x51, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x61,
	0x74, 0x69, 0x6f, 0x6e, 0x4d, 0x65, 0x74, 0x68, 0x6f, 0x64, 0x2e, 0x4d, 0x65, 0x74, 0x68, 0x6f,
	0x64, 0x48, 0x00, 0x52, 0x06, 0x6d, 0x65, 0x74, 0x68, 0x6f, 0x64, 0x12, 0x71, 0x0a, 0x13, 0x65,
	0x78, 0x70, 0x65, 0x72, 0x69, 0x6d, 0x65, 0x6e, 0x74, 0x61, 0x6c, 0x5f, 0x6d, 0x65, 0x74, 0x68,
	0x6f, 0x64, 0x18, 0x02, 0x20, 0x01, 0x28, 0x0e, 0x32, 0x3e, 0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f,
	0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x71, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x61, 0x74, 0x69,
	0x6f, 0x6e, 0x2e, 0x51, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x4d,
	0x65, 0x74, 0x68, 0x6f, 0x64, 0x2e, 0x45, 0x78, 0x70, 0x65, 0x72, 0x69, 0x6d, 0x65, 0x6e, 0x74,
	0x61, 0x6c, 0x4d, 0x65, 0x74, 0x68, 0x6f, 0x64, 0x48, 0x00, 0x52, 0x12, 0x65, 0x78, 0x70, 0x65,
	0x72, 0x69, 0x6d, 0x65, 0x6e, 0x74, 0x61, 0x6c, 0x4d, 0x65, 0x74, 0x68, 0x6f, 0x64, 0x22, 0x20,
	0x0a, 0x06, 0x4d, 0x65, 0x74, 0x68, 0x6f, 0x64, 0x12, 0x16, 0x0a, 0x12, 0x4d, 0x45, 0x54, 0x48,
	0x4f, 0x44, 0x5f, 0x55, 0x4e, 0x53, 0x50, 0x45, 0x43, 0x49, 0x46, 0x49, 0x45, 0x44, 0x10, 0x00,
	0x22, 0x6f, 0x0a, 0x12, 0x45, 0x78, 0x70, 0x65, 0x72, 0x69, 0x6d, 0x65, 0x6e, 0x74, 0x61, 0x6c,
	0x4d, 0x65, 0x74, 0x68, 0x6f, 0x64, 0x12, 0x23, 0x0a, 0x1f, 0x45, 0x58, 0x50, 0x45, 0x52, 0x49,
	0x4d, 0x45, 0x4e, 0x54, 0x41, 0x4c, 0x5f, 0x4d, 0x45, 0x54, 0x48, 0x4f, 0x44, 0x5f, 0x55, 0x4e,
	0x53, 0x50, 0x45, 0x43, 0x49, 0x46, 0x49, 0x45, 0x44, 0x10, 0x00, 0x12, 0x10, 0x0a, 0x0c, 0x53,
	0x54, 0x41, 0x54, 0x49, 0x43, 0x5f, 0x52, 0x41, 0x4e, 0x47, 0x45, 0x10, 0x01, 0x12, 0x11, 0x0a,
	0x0d, 0x44, 0x59, 0x4e, 0x41, 0x4d, 0x49, 0x43, 0x5f, 0x52, 0x41, 0x4e, 0x47, 0x45, 0x10, 0x02,
	0x12, 0x0f, 0x0a, 0x0b, 0x57, 0x45, 0x49, 0x47, 0x48, 0x54, 0x5f, 0x4f, 0x4e, 0x4c, 0x59, 0x10,
	0x03, 0x42, 0x0e, 0x0a, 0x0c, 0x6d, 0x65, 0x74, 0x68, 0x6f, 0x64, 0x5f, 0x6f, 0x6e, 0x65, 0x6f,
	0x66, 0x22, 0xdc, 0x02, 0x0a, 0x1d, 0x55, 0x6e, 0x69, 0x74, 0x57, 0x69, 0x73, 0x65, 0x51, 0x75,
	0x61, 0x6e, 0x74, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x50, 0x72, 0x65, 0x63, 0x69, 0x73,
	0x69, 0x6f, 0x6e, 0x12, 0x5c, 0x0a, 0x09, 0x75, 0x6e, 0x69, 0x74, 0x5f, 0x74, 0x79, 0x70, 0x65,
	0x18, 0x01, 0x20, 0x01, 0x28, 0x0e, 0x32, 0x3f, 0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66,
	0x6c, 0x6f, 0x77, 0x2e, 0x71, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e,
	0x2e, 0x55, 0x6e, 0x69, 0x74, 0x57, 0x69, 0x73, 0x65, 0x51, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a,
	0x61, 0x74, 0x69, 0x6f, 0x6e, 0x50, 0x72, 0x65, 0x63, 0x69, 0x73, 0x69, 0x6f, 0x6e, 0x2e, 0x55,
	0x6e, 0x69, 0x74, 0x54, 0x79, 0x70, 0x65, 0x52, 0x08, 0x75, 0x6e, 0x69, 0x74, 0x54, 0x79, 0x70,
	0x65, 0x12, 0x1b, 0x0a, 0x09, 0x66, 0x75, 0x6e, 0x63, 0x5f, 0x6e, 0x61, 0x6d, 0x65, 0x18, 0x02,
	0x20, 0x01, 0x28, 0x09, 0x52, 0x08, 0x66, 0x75, 0x6e, 0x63, 0x4e, 0x61, 0x6d, 0x65, 0x12, 0x1b,
	0x0a, 0x09, 0x75, 0x6e, 0x69, 0x74, 0x5f, 0x6e, 0x61, 0x6d, 0x65, 0x18, 0x03, 0x20, 0x01, 0x28,
	0x09, 0x52, 0x08, 0x75, 0x6e, 0x69, 0x74, 0x4e, 0x61, 0x6d, 0x65, 0x12, 0x65, 0x0a, 0x16, 0x71,
	0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x5f, 0x70, 0x72, 0x65, 0x63,
	0x69, 0x73, 0x69, 0x6f, 0x6e, 0x18, 0x05, 0x20, 0x01, 0x28, 0x0e, 0x32, 0x2e, 0x2e, 0x74, 0x65,
	0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x71, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a,
	0x61, 0x74, 0x69, 0x6f, 0x6e, 0x2e, 0x51, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x61, 0x74, 0x69,
	0x6f, 0x6e, 0x50, 0x72, 0x65, 0x63, 0x69, 0x73, 0x69, 0x6f, 0x6e, 0x52, 0x15, 0x71, 0x75, 0x61,
	0x6e, 0x74, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x50, 0x72, 0x65, 0x63, 0x69, 0x73, 0x69,
	0x6f, 0x6e, 0x22, 0x3c, 0x0a, 0x08, 0x55, 0x6e, 0x69, 0x74, 0x54, 0x79, 0x70, 0x65, 0x12, 0x14,
	0x0a, 0x10, 0x55, 0x4e, 0x49, 0x54, 0x5f, 0x55, 0x4e, 0x53, 0x50, 0x45, 0x43, 0x49, 0x46, 0x49,
	0x45, 0x44, 0x10, 0x00, 0x12, 0x0d, 0x0a, 0x09, 0x55, 0x4e, 0x49, 0x54, 0x5f, 0x4e, 0x4f, 0x44,
	0x45, 0x10, 0x01, 0x12, 0x0b, 0x0a, 0x07, 0x55, 0x4e, 0x49, 0x54, 0x5f, 0x4f, 0x50, 0x10, 0x02,
	0x22, 0x2e, 0x0a, 0x12, 0x46, 0x72, 0x65, 0x65, 0x7a, 0x65, 0x41, 0x6c, 0x6c, 0x56, 0x61, 0x72,
	0x69, 0x61, 0x62, 0x6c, 0x65, 0x73, 0x12, 0x18, 0x0a, 0x07, 0x65, 0x6e, 0x61, 0x62, 0x6c, 0x65,
	0x64, 0x18, 0x01, 0x20, 0x01, 0x28, 0x08, 0x52, 0x07, 0x65, 0x6e, 0x61, 0x62, 0x6c, 0x65, 0x64,
	0x22, 0xb1, 0x05, 0x0a, 0x13, 0x51, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f,
	0x6e, 0x4f, 0x70, 0x74, 0x69, 0x6f, 0x6e, 0x73, 0x12, 0x5c, 0x0a, 0x13, 0x71, 0x75, 0x61, 0x6e,
	0x74, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x5f, 0x6d, 0x65, 0x74, 0x68, 0x6f, 0x64, 0x18,
	0x01, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x2b, 0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c,
	0x6f, 0x77, 0x2e, 0x71, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x2e,
	0x51, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x4d, 0x65, 0x74, 0x68,
	0x6f, 0x64, 0x52, 0x12, 0x71, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e,
	0x4d, 0x65, 0x74, 0x68, 0x6f, 0x64, 0x12, 0x35, 0x0a, 0x06, 0x6f, 0x70, 0x5f, 0x73, 0x65, 0x74,
	0x18, 0x02, 0x20, 0x01, 0x28, 0x0e, 0x32, 0x1e, 0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66,
	0x6c, 0x6f, 0x77, 0x2e, 0x71, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e,
	0x2e, 0x4f, 0x70, 0x53, 0x65, 0x74, 0x52, 0x05, 0x6f, 0x70, 0x53, 0x65, 0x74, 0x12, 0x65, 0x0a,
	0x16, 0x71, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x5f, 0x70, 0x72,
	0x65, 0x63, 0x69, 0x73, 0x69, 0x6f, 0x6e, 0x18, 0x03, 0x20, 0x01, 0x28, 0x0e, 0x32, 0x2e, 0x2e,
	0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x71, 0x75, 0x61, 0x6e, 0x74,
	0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x2e, 0x51, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x61,
	0x74, 0x69, 0x6f, 0x6e, 0x50, 0x72, 0x65, 0x63, 0x69, 0x73, 0x69, 0x6f, 0x6e, 0x52, 0x15, 0x71,
	0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x50, 0x72, 0x65, 0x63, 0x69,
	0x73, 0x69, 0x6f, 0x6e, 0x12, 0x7f, 0x0a, 0x20, 0x75, 0x6e, 0x69, 0x74, 0x5f, 0x77, 0x69, 0x73,
	0x65, 0x5f, 0x71, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x5f, 0x70,
	0x72, 0x65, 0x63, 0x69, 0x73, 0x69, 0x6f, 0x6e, 0x18, 0x04, 0x20, 0x03, 0x28, 0x0b, 0x32, 0x36,
	0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x71, 0x75, 0x61, 0x6e,
	0x74, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x2e, 0x55, 0x6e, 0x69, 0x74, 0x57, 0x69, 0x73,
	0x65, 0x51, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x50, 0x72, 0x65,
	0x63, 0x69, 0x73, 0x69, 0x6f, 0x6e, 0x52, 0x1d, 0x75, 0x6e, 0x69, 0x74, 0x57, 0x69, 0x73, 0x65,
	0x51, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x50, 0x72, 0x65, 0x63,
	0x69, 0x73, 0x69, 0x6f, 0x6e, 0x12, 0x3e, 0x0a, 0x1c, 0x6d, 0x69, 0x6e, 0x5f, 0x6e, 0x75, 0x6d,
	0x5f, 0x65, 0x6c, 0x65, 0x6d, 0x65, 0x6e, 0x74, 0x73, 0x5f, 0x66, 0x6f, 0x72, 0x5f, 0x77, 0x65,
	0x69, 0x67, 0x68, 0x74, 0x73, 0x18, 0x05, 0x20, 0x01, 0x28, 0x03, 0x52, 0x18, 0x6d, 0x69, 0x6e,
	0x4e, 0x75, 0x6d, 0x45, 0x6c, 0x65, 0x6d, 0x65, 0x6e, 0x74, 0x73, 0x46, 0x6f, 0x72, 0x57, 0x65,
	0x69, 0x67, 0x68, 0x74, 0x73, 0x12, 0x5d, 0x0a, 0x14, 0x66, 0x72, 0x65, 0x65, 0x7a, 0x65, 0x5f,
	0x61, 0x6c, 0x6c, 0x5f, 0x76, 0x61, 0x72, 0x69, 0x61, 0x62, 0x6c, 0x65, 0x73, 0x18, 0x06, 0x20,
	0x01, 0x28, 0x0b, 0x32, 0x2b, 0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77,
	0x2e, 0x71, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x2e, 0x46, 0x72,
	0x65, 0x65, 0x7a, 0x65, 0x41, 0x6c, 0x6c, 0x56, 0x61, 0x72, 0x69, 0x61, 0x62, 0x6c, 0x65, 0x73,
	0x52, 0x12, 0x66, 0x72, 0x65, 0x65, 0x7a, 0x65, 0x41, 0x6c, 0x6c, 0x56, 0x61, 0x72, 0x69, 0x61,
	0x62, 0x6c, 0x65, 0x73, 0x12, 0x45, 0x0a, 0x1f, 0x65, 0x6e, 0x61, 0x62, 0x6c, 0x65, 0x5f, 0x70,
	0x65, 0x72, 0x5f, 0x63, 0x68, 0x61, 0x6e, 0x6e, 0x65, 0x6c, 0x5f, 0x71, 0x75, 0x61, 0x6e, 0x74,
	0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x18, 0x07, 0x20, 0x01, 0x28, 0x08, 0x52, 0x1c, 0x65,
	0x6e, 0x61, 0x62, 0x6c, 0x65, 0x50, 0x65, 0x72, 0x43, 0x68, 0x61, 0x6e, 0x6e, 0x65, 0x6c, 0x51,
	0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x12, 0x37, 0x0a, 0x18, 0x65,
	0x6e, 0x61, 0x62, 0x6c, 0x65, 0x5f, 0x74, 0x77, 0x6f, 0x5f, 0x69, 0x6e, 0x70, 0x75, 0x74, 0x5f,
	0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x73, 0x18, 0x08, 0x20, 0x01, 0x28, 0x08, 0x52, 0x15, 0x65,
	0x6e, 0x61, 0x62, 0x6c, 0x65, 0x54, 0x77, 0x6f, 0x49, 0x6e, 0x70, 0x75, 0x74, 0x54, 0x65, 0x6e,
	0x73, 0x6f, 0x72, 0x73, 0x2a, 0x82, 0x01, 0x0a, 0x15, 0x51, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a,
	0x61, 0x74, 0x69, 0x6f, 0x6e, 0x50, 0x72, 0x65, 0x63, 0x69, 0x73, 0x69, 0x6f, 0x6e, 0x12, 0x19,
	0x0a, 0x15, 0x50, 0x52, 0x45, 0x43, 0x49, 0x53, 0x49, 0x4f, 0x4e, 0x5f, 0x55, 0x4e, 0x53, 0x50,
	0x45, 0x43, 0x49, 0x46, 0x49, 0x45, 0x44, 0x10, 0x00, 0x12, 0x12, 0x0a, 0x0e, 0x50, 0x52, 0x45,
	0x43, 0x49, 0x53, 0x49, 0x4f, 0x4e, 0x5f, 0x46, 0x55, 0x4c, 0x4c, 0x10, 0x01, 0x12, 0x12, 0x0a,
	0x0e, 0x50, 0x52, 0x45, 0x43, 0x49, 0x53, 0x49, 0x4f, 0x4e, 0x5f, 0x57, 0x34, 0x41, 0x34, 0x10,
	0x02, 0x12, 0x12, 0x0a, 0x0e, 0x50, 0x52, 0x45, 0x43, 0x49, 0x53, 0x49, 0x4f, 0x4e, 0x5f, 0x57,
	0x34, 0x41, 0x38, 0x10, 0x03, 0x12, 0x12, 0x0a, 0x0e, 0x50, 0x52, 0x45, 0x43, 0x49, 0x53, 0x49,
	0x4f, 0x4e, 0x5f, 0x57, 0x38, 0x41, 0x38, 0x10, 0x04, 0x2a, 0x47, 0x0a, 0x05, 0x4f, 0x70, 0x53,
	0x65, 0x74, 0x12, 0x16, 0x0a, 0x12, 0x4f, 0x50, 0x5f, 0x53, 0x45, 0x54, 0x5f, 0x55, 0x4e, 0x53,
	0x50, 0x45, 0x43, 0x49, 0x46, 0x49, 0x45, 0x44, 0x10, 0x00, 0x12, 0x06, 0x0a, 0x02, 0x54, 0x46,
	0x10, 0x01, 0x12, 0x07, 0x0a, 0x03, 0x58, 0x4c, 0x41, 0x10, 0x02, 0x12, 0x15, 0x0a, 0x11, 0x55,
	0x4e, 0x49, 0x46, 0x4f, 0x52, 0x4d, 0x5f, 0x51, 0x55, 0x41, 0x4e, 0x54, 0x49, 0x5a, 0x45, 0x44,
	0x10, 0x03, 0x42, 0x8a, 0x02, 0x0a, 0x1b, 0x63, 0x6f, 0x6d, 0x2e, 0x74, 0x65, 0x6e, 0x73, 0x6f,
	0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x71, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x61, 0x74, 0x69,
	0x6f, 0x6e, 0x42, 0x18, 0x51, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e,
	0x4f, 0x70, 0x74, 0x69, 0x6f, 0x6e, 0x73, 0x50, 0x72, 0x6f, 0x74, 0x6f, 0x48, 0x02, 0x50, 0x01,
	0x5a, 0x4f, 0x67, 0x69, 0x74, 0x65, 0x65, 0x2e, 0x63, 0x6f, 0x6d, 0x2f, 0x71, 0x63, 0x69, 0x69,
	0x70, 0x2d, 0x69, 0x63, 0x70, 0x2f, 0x74, 0x66, 0x2d, 0x73, 0x65, 0x72, 0x76, 0x69, 0x6e, 0x67,
	0x2f, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2f, 0x63, 0x6f, 0x6d, 0x70,
	0x69, 0x6c, 0x65, 0x72, 0x2f, 0x6d, 0x6c, 0x69, 0x72, 0x2f, 0x71, 0x75, 0x61, 0x6e, 0x74, 0x69,
	0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x2f, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f,
	0x77, 0xf8, 0x01, 0x01, 0xa2, 0x02, 0x03, 0x54, 0x51, 0x58, 0xaa, 0x02, 0x17, 0x54, 0x65, 0x6e,
	0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2e, 0x51, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x61,
	0x74, 0x69, 0x6f, 0x6e, 0xca, 0x02, 0x17, 0x54, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f,
	0x77, 0x5c, 0x51, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0xe2, 0x02,
	0x23, 0x54, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x5c, 0x51, 0x75, 0x61, 0x6e,
	0x74, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x5c, 0x47, 0x50, 0x42, 0x4d, 0x65, 0x74, 0x61,
	0x64, 0x61, 0x74, 0x61, 0xea, 0x02, 0x18, 0x54, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f,
	0x77, 0x3a, 0x3a, 0x51, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x62,
	0x06, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x33,
}

var (
	file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_rawDescOnce sync.Once
	file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_rawDescData = file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_rawDesc
)

func file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_rawDescGZIP() []byte {
	file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_rawDescOnce.Do(func() {
		file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_rawDescData = protoimpl.X.CompressGZIP(file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_rawDescData)
	})
	return file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_rawDescData
}

var file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_enumTypes = make([]protoimpl.EnumInfo, 5)
var file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_msgTypes = make([]protoimpl.MessageInfo, 4)
var file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_goTypes = []interface{}{
	(QuantizationPrecision)(0),                  // 0: tensorflow.quantization.QuantizationPrecision
	(OpSet)(0),                                  // 1: tensorflow.quantization.OpSet
	(QuantizationMethod_Method)(0),              // 2: tensorflow.quantization.QuantizationMethod.Method
	(QuantizationMethod_ExperimentalMethod)(0),  // 3: tensorflow.quantization.QuantizationMethod.ExperimentalMethod
	(UnitWiseQuantizationPrecision_UnitType)(0), // 4: tensorflow.quantization.UnitWiseQuantizationPrecision.UnitType
	(*QuantizationMethod)(nil),                  // 5: tensorflow.quantization.QuantizationMethod
	(*UnitWiseQuantizationPrecision)(nil),       // 6: tensorflow.quantization.UnitWiseQuantizationPrecision
	(*FreezeAllVariables)(nil),                  // 7: tensorflow.quantization.FreezeAllVariables
	(*QuantizationOptions)(nil),                 // 8: tensorflow.quantization.QuantizationOptions
}
var file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_depIdxs = []int32{
	2, // 0: tensorflow.quantization.QuantizationMethod.method:type_name -> tensorflow.quantization.QuantizationMethod.Method
	3, // 1: tensorflow.quantization.QuantizationMethod.experimental_method:type_name -> tensorflow.quantization.QuantizationMethod.ExperimentalMethod
	4, // 2: tensorflow.quantization.UnitWiseQuantizationPrecision.unit_type:type_name -> tensorflow.quantization.UnitWiseQuantizationPrecision.UnitType
	0, // 3: tensorflow.quantization.UnitWiseQuantizationPrecision.quantization_precision:type_name -> tensorflow.quantization.QuantizationPrecision
	5, // 4: tensorflow.quantization.QuantizationOptions.quantization_method:type_name -> tensorflow.quantization.QuantizationMethod
	1, // 5: tensorflow.quantization.QuantizationOptions.op_set:type_name -> tensorflow.quantization.OpSet
	0, // 6: tensorflow.quantization.QuantizationOptions.quantization_precision:type_name -> tensorflow.quantization.QuantizationPrecision
	6, // 7: tensorflow.quantization.QuantizationOptions.unit_wise_quantization_precision:type_name -> tensorflow.quantization.UnitWiseQuantizationPrecision
	7, // 8: tensorflow.quantization.QuantizationOptions.freeze_all_variables:type_name -> tensorflow.quantization.FreezeAllVariables
	9, // [9:9] is the sub-list for method output_type
	9, // [9:9] is the sub-list for method input_type
	9, // [9:9] is the sub-list for extension type_name
	9, // [9:9] is the sub-list for extension extendee
	0, // [0:9] is the sub-list for field type_name
}

func init() { file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_init() }
func file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_init() {
	if File_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto != nil {
		return
	}
	if !protoimpl.UnsafeEnabled {
		file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_msgTypes[0].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*QuantizationMethod); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_msgTypes[1].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*UnitWiseQuantizationPrecision); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_msgTypes[2].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*FreezeAllVariables); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_msgTypes[3].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*QuantizationOptions); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
	}
	file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_msgTypes[0].OneofWrappers = []interface{}{
		(*QuantizationMethod_Method_)(nil),
		(*QuantizationMethod_ExperimentalMethod_)(nil),
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_rawDesc,
			NumEnums:      5,
			NumMessages:   4,
			NumExtensions: 0,
			NumServices:   0,
		},
		GoTypes:           file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_goTypes,
		DependencyIndexes: file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_depIdxs,
		EnumInfos:         file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_enumTypes,
		MessageInfos:      file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_msgTypes,
	}.Build()
	File_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto = out.File
	file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_rawDesc = nil
	file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_goTypes = nil
	file_tensorflow_compiler_mlir_quantization_tensorflow_quantization_options_proto_depIdxs = nil
}
