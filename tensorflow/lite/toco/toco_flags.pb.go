// Copyright 2022 The TensorFlow Authors. All Rights Reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.28.1
// 	protoc        (unknown)
// source: tensorflow/lite/toco/toco_flags.proto

package toco

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// Supported I/O file formats. Some formats may be input-only or output-only.
type FileFormat int32

const (
	FileFormat_FILE_FORMAT_UNKNOWN FileFormat = 0
	// GraphDef, third_party/tensorflow/core/framework/graph.proto
	FileFormat_TENSORFLOW_GRAPHDEF FileFormat = 1
	// Tensorflow's mobile inference model.
	// third_party/tensorflow/lite/schema/schema.fbs
	FileFormat_TFLITE FileFormat = 2
	// GraphViz
	// Export-only.
	FileFormat_GRAPHVIZ_DOT FileFormat = 3
)

// Enum value maps for FileFormat.
var (
	FileFormat_name = map[int32]string{
		0: "FILE_FORMAT_UNKNOWN",
		1: "TENSORFLOW_GRAPHDEF",
		2: "TFLITE",
		3: "GRAPHVIZ_DOT",
	}
	FileFormat_value = map[string]int32{
		"FILE_FORMAT_UNKNOWN": 0,
		"TENSORFLOW_GRAPHDEF": 1,
		"TFLITE":              2,
		"GRAPHVIZ_DOT":        3,
	}
)

func (x FileFormat) Enum() *FileFormat {
	p := new(FileFormat)
	*p = x
	return p
}

func (x FileFormat) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (FileFormat) Descriptor() protoreflect.EnumDescriptor {
	return file_tensorflow_lite_toco_toco_flags_proto_enumTypes[0].Descriptor()
}

func (FileFormat) Type() protoreflect.EnumType {
	return &file_tensorflow_lite_toco_toco_flags_proto_enumTypes[0]
}

func (x FileFormat) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Do not use.
func (x *FileFormat) UnmarshalJSON(b []byte) error {
	num, err := protoimpl.X.UnmarshalJSONEnum(x.Descriptor(), b)
	if err != nil {
		return err
	}
	*x = FileFormat(num)
	return nil
}

// Deprecated: Use FileFormat.Descriptor instead.
func (FileFormat) EnumDescriptor() ([]byte, []int) {
	return file_tensorflow_lite_toco_toco_flags_proto_rawDescGZIP(), []int{0}
}

// TocoFlags encodes extra parameters that drive tooling operations, that
// are not normally encoded in model files and in general may not be thought
// of as properties of models, instead describing how models are to be
// processed in the context of the present tooling job.
//
// Next ID to use: 53.
type TocoFlags struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// Input file format
	InputFormat *FileFormat `protobuf:"varint,1,opt,name=input_format,json=inputFormat,enum=toco.FileFormat" json:"input_format,omitempty"`
	// Output file format
	OutputFormat *FileFormat `protobuf:"varint,2,opt,name=output_format,json=outputFormat,enum=toco.FileFormat" json:"output_format,omitempty"`
	// Similar to inference_type, but allows to control specifically the
	// quantization of input arrays, separately from other arrays.
	//
	// If not set, then the value of inference_type is implicitly used, i.e.
	// by default input arrays are quantized like other arrays.
	//
	// Like inference_type, this only affects real-number arrays. By "real-number"
	// we mean float arrays, and quantized arrays. This excludes plain
	// integer arrays, strings arrays, and every other data type.
	//
	// The typical use for this flag is for vision models taking a bitmap
	// as input, typically with uint8 channels, yet still requiring floating-point
	// inference. For such image models, the uint8 input is quantized, i.e.
	// the uint8 values are interpreted as real numbers, and the quantization
	// parameters used for such input arrays are their mean_value, std_value
	// parameters.
	InferenceInputType *IODataType `protobuf:"varint,11,opt,name=inference_input_type,json=inferenceInputType,enum=toco.IODataType" json:"inference_input_type,omitempty"`
	// Sets the type of real-number arrays in the output file, that is, controls
	// the representation (quantization) of real numbers in the output file,
	// except for input arrays, which are controlled by inference_input_type.
	//
	// NOTE: this flag only impacts real-number arrays. By "real-number"
	// we mean float arrays, and quantized arrays. This excludes plain
	// integer arrays, strings arrays, and every other data type.
	//
	// For real-number arrays, the impact of this flag is to allow the output
	// file to choose a different real-numbers representation (quantization)
	// from what the input file used. For any other types of arrays, changing
	// the data type would not make sense.
	//
	// Specifically:
	//   - If FLOAT, then real-numbers arrays will be of type float in
	//     the output file. If they were quantized in the input file, then
	//     they get dequantized.
	//   - If QUANTIZED_UINT8, then real-numbers arrays will be quantized
	//     as uint8 in the output file. If they were float in the input file,
	//     then they get quantized.
	//   - If not set, then all real-numbers arrays retain the same type in the
	//     output file as they have in the input file.
	InferenceType *IODataType `protobuf:"varint,4,opt,name=inference_type,json=inferenceType,enum=toco.IODataType" json:"inference_type,omitempty"`
	// default_ranges_min and default_ranges_max are helpers to experiment
	// with quantization of models. Normally, quantization requires the input
	// model to have (min, max) range information for every activations array.
	// This is needed in order to know how to quantize arrays and still achieve
	// satisfactory accuracy. However, in some circumstances one would just like
	// to estimate the performance of quantized inference, without caring about
	// accuracy. That is what default_ranges_min and default_ranges_max are for:
	// when specified, they will be used as default (min, max) range boundaries
	// for all activation arrays that lack (min, max) range information, thus
	// allowing for quantization to proceed.
	//
	// It should be clear from the above explanation that these parameters are
	// for experimentation purposes only and should not be used in production:
	// they make it easy to quantize models, but the resulting quantized model
	// will be inaccurate.
	//
	// These values only apply to arrays quantized with the kUint8 data type.
	DefaultRangesMin *float32 `protobuf:"fixed32,5,opt,name=default_ranges_min,json=defaultRangesMin" json:"default_ranges_min,omitempty"`
	DefaultRangesMax *float32 `protobuf:"fixed32,6,opt,name=default_ranges_max,json=defaultRangesMax" json:"default_ranges_max,omitempty"`
	// Equivalent versions of default_ranges_min/_max for arrays quantized with
	// the kInt16 data type.
	DefaultInt16RangesMin *float32 `protobuf:"fixed32,15,opt,name=default_int16_ranges_min,json=defaultInt16RangesMin" json:"default_int16_ranges_min,omitempty"`
	DefaultInt16RangesMax *float32 `protobuf:"fixed32,16,opt,name=default_int16_ranges_max,json=defaultInt16RangesMax" json:"default_int16_ranges_max,omitempty"`
	// Ignore and discard FakeQuant nodes. For instance, that can be used to
	// generate plain float code without fake-quantization from a quantized
	// graph.
	DropFakeQuant *bool `protobuf:"varint,7,opt,name=drop_fake_quant,json=dropFakeQuant" json:"drop_fake_quant,omitempty"`
	// Normally, FakeQuant nodes must be strict boundaries for graph
	// transformations, in order to ensure that quantized inference has the
	// exact same arithmetic behavior as quantized training --- which is the
	// whole point of quantized training and of FakeQuant nodes in the first
	// place. However, that entails subtle requirements on where exactly
	// FakeQuant nodes must be placed in the graph. Some quantized graphs
	// have FakeQuant nodes at unexpected locations, that prevent graph
	// transformations that are necessary in order to generate inference
	// code for these graphs. Such graphs should be fixed, but as a
	// temporary work-around, setting this reorder_across_fake_quant flag
	// allows toco to perform necessary graph transformations on them,
	// at the cost of no longer faithfully matching inference and training
	// arithmetic.
	ReorderAcrossFakeQuant *bool `protobuf:"varint,8,opt,name=reorder_across_fake_quant,json=reorderAcrossFakeQuant" json:"reorder_across_fake_quant,omitempty"`
	// If true, allow TOCO to create TF Lite Custom operators for all the
	// unsupported Tensorflow ops.
	AllowCustomOps *bool `protobuf:"varint,10,opt,name=allow_custom_ops,json=allowCustomOps" json:"allow_custom_ops,omitempty"`
	// Applies only to the case when the input format is TENSORFLOW_GRAPHDEF.
	// If true, then control dependencies will be immediately dropped during
	// import.
	// If not set, the default behavior is as follows:
	//   - Default to false if the output format is TENSORFLOW_GRAPHDEF.
	//   - Default to true in all other cases.
	DropControlDependency *bool `protobuf:"varint,12,opt,name=drop_control_dependency,json=dropControlDependency" json:"drop_control_dependency,omitempty"`
	// Disables transformations that fuse subgraphs such as known LSTMs (not all
	// LSTMs are identified).
	DebugDisableRecurrentCellFusion *bool `protobuf:"varint,13,opt,name=debug_disable_recurrent_cell_fusion,json=debugDisableRecurrentCellFusion" json:"debug_disable_recurrent_cell_fusion,omitempty"`
	// Uses the FakeQuantWithMinMaxArgs.num_bits attribute to adjust quantized
	// array data types throughout the graph. The graph must be properly annotated
	// with FakeQuant* ops on at least the edges and may contain additional ops on
	// the interior of the graph to widen/narrow as desired.
	//
	// Input and output array data types may change because of this propagation
	// and users must be sure to query the final data_type values.
	PropagateFakeQuantNumBits *bool `protobuf:"varint,14,opt,name=propagate_fake_quant_num_bits,json=propagateFakeQuantNumBits" json:"propagate_fake_quant_num_bits,omitempty"`
	// Some fast uint8 GEMM kernels require uint8 weights to avoid the value 0.
	// This flag allows nudging them to 1 to allow proceeding, with moderate
	// inaccuracy.
	AllowNudgingWeightsToUseFastGemmKernel *bool `protobuf:"varint,17,opt,name=allow_nudging_weights_to_use_fast_gemm_kernel,json=allowNudgingWeightsToUseFastGemmKernel" json:"allow_nudging_weights_to_use_fast_gemm_kernel,omitempty"`
	// Minimum size of constant arrays to deduplicate; arrays smaller will not be
	// deduplicated.
	DedupeArrayMinSizeBytes *int64 `protobuf:"varint,18,opt,name=dedupe_array_min_size_bytes,json=dedupeArrayMinSizeBytes,def=64" json:"dedupe_array_min_size_bytes,omitempty"`
	// Split the LSTM inputs from 5 tensors to 18 tensors for TFLite.
	// Ignored if the output format is not TFLite.
	SplitTfliteLstmInputs *bool `protobuf:"varint,19,opt,name=split_tflite_lstm_inputs,json=splitTfliteLstmInputs,def=1" json:"split_tflite_lstm_inputs,omitempty"`
	// Store weights as quantized weights followed by dequantize operations.
	// Computation is still done in float, but reduces model size (at the cost of
	// accuracy and latency).
	// DEPRECATED: Please use post_training_quantize instead.
	QuantizeWeights *bool `protobuf:"varint,20,opt,name=quantize_weights,json=quantizeWeights,def=0" json:"quantize_weights,omitempty"`
	// Full filepath of folder to dump the graphs at various stages of processing
	// GraphViz .dot files. Preferred over --output_format=GRAPHVIZ_DOT in order
	// to keep the requirements of the output file.
	DumpGraphvizDir *string `protobuf:"bytes,24,opt,name=dump_graphviz_dir,json=dumpGraphvizDir" json:"dump_graphviz_dir,omitempty"`
	// Boolean indicating whether to dump the graph after every graph
	// transformation.
	DumpGraphvizIncludeVideo *bool `protobuf:"varint,25,opt,name=dump_graphviz_include_video,json=dumpGraphvizIncludeVideo" json:"dump_graphviz_include_video,omitempty"`
	// Boolean indicating whether to quantize the weights of the converted float
	// model. Model size will be reduced and there will be latency improvements
	// (at the cost of accuracy).
	PostTrainingQuantize *bool `protobuf:"varint,26,opt,name=post_training_quantize,json=postTrainingQuantize,def=0" json:"post_training_quantize,omitempty"`
	// This flag only works when converting to TensorFlow Lite format.
	// When enabled, unsupported ops will be converted to select TensorFlow ops.
	// TODO(ycling): Consider to rename the following 2 flags and don't call it
	// "Flex".
	// `enable_select_tf_ops` should always be used with `allow_custom_ops`.
	// WARNING: Experimental interface, subject to change
	EnableSelectTfOps *bool `protobuf:"varint,27,opt,name=enable_select_tf_ops,json=enableSelectTfOps,def=0" json:"enable_select_tf_ops,omitempty"`
	// This flag only works when converting to TensorFlow Lite format.
	// When enabled, all TensorFlow ops will be converted to select TensorFlow
	// ops.
	// This will force `enable_select_tf_ops` to true.
	// `force_select_tf_ops` should always be used with `enable_select_tf_ops`.
	// WARNING: Experimental interface, subject to change
	ForceSelectTfOps *bool `protobuf:"varint,28,opt,name=force_select_tf_ops,json=forceSelectTfOps,def=0" json:"force_select_tf_ops,omitempty"`
	// Boolean indicating whether to convert float32 constant buffers to
	// float16. This is typically done to reduce model size. Delegates may also
	// wish to implement kernels on reduced precision floats for performance
	// gains.
	QuantizeToFloat16 *bool `protobuf:"varint,29,opt,name=quantize_to_float16,json=quantizeToFloat16,def=0" json:"quantize_to_float16,omitempty"`
	// Boolean flag indicating whether the converter should allow models with
	// dynamic Tensor shape. When set to False, the converter will generate
	// runtime memory offsets for activation Tensors (with 128 bits alignment)
	// and error out on models with undetermined Tensor shape. (Default: True)
	AllowDynamicTensors *bool `protobuf:"varint,30,opt,name=allow_dynamic_tensors,json=allowDynamicTensors,def=1" json:"allow_dynamic_tensors,omitempty"`
	// Full filepath of the folder to dump conversion logs. This includes a global
	// view of the conversion process, and user can choose to submit those logs.
	ConversionSummaryDir *string `protobuf:"bytes,31,opt,name=conversion_summary_dir,json=conversionSummaryDir" json:"conversion_summary_dir,omitempty"`
	// String representing the custom ops OpDefs that are included in the
	// GraphDef.
	// Deprecated do not use.
	//
	// Deprecated: Do not use.
	CustomOpdefs []string `protobuf:"bytes,32,rep,name=custom_opdefs,json=customOpdefs" json:"custom_opdefs,omitempty"`
	// Name of user's defined Tensorflow ops required in the TensorFlow Lite
	// runtime. These ops will be supported as select TensorFlow ops.
	SelectUserTfOps []string `protobuf:"bytes,33,rep,name=select_user_tf_ops,json=selectUserTfOps" json:"select_user_tf_ops,omitempty"`
	// Whether to enable tflite resource variables during conversion or not.
	// Note: This is an experimental feature.
	EnableTfliteResourceVariables *bool `protobuf:"varint,34,opt,name=enable_tflite_resource_variables,json=enableTfliteResourceVariables,def=1" json:"enable_tflite_resource_variables,omitempty"`
	// Whether to unfold tf.BatchMatMul to a set of tfl.fully_connected ops. If
	// not, translate to tfl.batch_matmul.
	// WARNING: Experimental interface, subject to change.
	UnfoldBatchmatmul *bool `protobuf:"varint,35,opt,name=unfold_batchmatmul,json=unfoldBatchmatmul,def=1" json:"unfold_batchmatmul,omitempty"`
	// Whether to lower static Tensor List ops to builtin ops. If not, use Flex
	// tensor list ops.
	// WARNING: Experimental interface, subject to change.
	LowerTensorListOps *bool `protobuf:"varint,36,opt,name=lower_tensor_list_ops,json=lowerTensorListOps,def=1" json:"lower_tensor_list_ops,omitempty"`
	// The accumulation type to use when quantize_to_float16 is true. Typical
	// choices would be either float16 or float32.
	AccumulationType *IODataType `protobuf:"varint,37,opt,name=accumulation_type,json=accumulationType,enum=toco.IODataType" json:"accumulation_type,omitempty"`
	// Whether this model supports inference in bfloat16.
	// Note: This is an experimental feature.
	AllowBfloat16 *bool `protobuf:"varint,38,opt,name=allow_bfloat16,json=allowBfloat16,def=0" json:"allow_bfloat16,omitempty"`
	// If true, automatically adds all tf ops into the model as select Tensorflow
	// ops.
	AllowAllSelectTfOps *bool `protobuf:"varint,39,opt,name=allow_all_select_tf_ops,json=allowAllSelectTfOps" json:"allow_all_select_tf_ops,omitempty"`
	// Whether to unfold large splat constant tensors in the flatbuffer to reduce
	// model size.
	UnfoldLargeSplatConstant *bool `protobuf:"varint,40,opt,name=unfold_large_splat_constant,json=unfoldLargeSplatConstant,def=0" json:"unfold_large_splat_constant,omitempty"`
	// Name of TFLite backends which are needed to check compatibility.
	// WARNING: Experimental interface, subject to change.
	SupportedBackends []string `protobuf:"bytes,41,rep,name=supported_backends,json=supportedBackends" json:"supported_backends,omitempty"`
	// Whether to force to use batch size one when the batch size is None during
	// lowering tensor list ops.
	DefaultToSingleBatchInTensorListOps *bool `protobuf:"varint,42,opt,name=default_to_single_batch_in_tensor_list_ops,json=defaultToSingleBatchInTensorListOps,def=0" json:"default_to_single_batch_in_tensor_list_ops,omitempty"`
	// Disable per_channel quantization for dynamic range quantization.
	// Note: This is an experimental feature
	DisablePerChannelQuantization *bool `protobuf:"varint,43,opt,name=disable_per_channel_quantization,json=disablePerChannelQuantization,def=0" json:"disable_per_channel_quantization,omitempty"`
	// If false, the old TOCO dynamic range quantization is used.
	// Note: This is an experimental feature
	EnableMlirDynamicRangeQuantizer *bool `protobuf:"varint,44,opt,name=enable_mlir_dynamic_range_quantizer,json=enableMlirDynamicRangeQuantizer,def=0" json:"enable_mlir_dynamic_range_quantizer,omitempty"`
	// When the output model is used for TF Quantization, this flag indicates the
	// mode of TF Quantization. Ex: DEFAULT, LEGACY_INTEGER,...
	TfQuantizationMode *string `protobuf:"bytes,45,opt,name=tf_quantization_mode,json=tfQuantizationMode" json:"tf_quantization_mode,omitempty"`
	// Disable inferring tensor range for quantization.
	// Note: This is an experimental feature
	DisableInferTensorRange *bool `protobuf:"varint,46,opt,name=disable_infer_tensor_range,json=disableInferTensorRange,def=0" json:"disable_infer_tensor_range,omitempty"`
	// Enable using num bits set in fake quant attributes for quantization.
	// Note: This is an experimental feature
	UseFakeQuantNumBits *bool `protobuf:"varint,47,opt,name=use_fake_quant_num_bits,json=useFakeQuantNumBits,def=0" json:"use_fake_quant_num_bits,omitempty"`
	// Enable converting to DynamicUpdateSlice op (for ops like TensorListSetItem)
	// Note: This is an experimental feature
	EnableDynamicUpdateSlice *bool `protobuf:"varint,48,opt,name=enable_dynamic_update_slice,json=enableDynamicUpdateSlice,def=0" json:"enable_dynamic_update_slice,omitempty"`
	// Whether to preserve `TF::AssertOp`.
	PreserveAssertOp *bool `protobuf:"varint,49,opt,name=preserve_assert_op,json=preserveAssertOp,def=0" json:"preserve_assert_op,omitempty"`
	// Whether to ensure each function has a single use.
	GuaranteeAllFuncsOneUse *bool `protobuf:"varint,50,opt,name=guarantee_all_funcs_one_use,json=guaranteeAllFuncsOneUse,def=0" json:"guarantee_all_funcs_one_use,omitempty"`
	// Whether to convert model to stablehlo.
	ConvertToStablehlo *bool `protobuf:"varint,51,opt,name=convert_to_stablehlo,json=convertToStablehlo,def=0" json:"convert_to_stablehlo,omitempty"`
	// If false, skip the variable quantization passes.
	// Note: This is an experimental feature
	EnableMlirVariableQuantization *bool `protobuf:"varint,52,opt,name=enable_mlir_variable_quantization,json=enableMlirVariableQuantization,def=0" json:"enable_mlir_variable_quantization,omitempty"`
}

// Default values for TocoFlags fields.
const (
	Default_TocoFlags_DedupeArrayMinSizeBytes             = int64(64)
	Default_TocoFlags_SplitTfliteLstmInputs               = bool(true)
	Default_TocoFlags_QuantizeWeights                     = bool(false)
	Default_TocoFlags_PostTrainingQuantize                = bool(false)
	Default_TocoFlags_EnableSelectTfOps                   = bool(false)
	Default_TocoFlags_ForceSelectTfOps                    = bool(false)
	Default_TocoFlags_QuantizeToFloat16                   = bool(false)
	Default_TocoFlags_AllowDynamicTensors                 = bool(true)
	Default_TocoFlags_EnableTfliteResourceVariables       = bool(true)
	Default_TocoFlags_UnfoldBatchmatmul                   = bool(true)
	Default_TocoFlags_LowerTensorListOps                  = bool(true)
	Default_TocoFlags_AllowBfloat16                       = bool(false)
	Default_TocoFlags_UnfoldLargeSplatConstant            = bool(false)
	Default_TocoFlags_DefaultToSingleBatchInTensorListOps = bool(false)
	Default_TocoFlags_DisablePerChannelQuantization       = bool(false)
	Default_TocoFlags_EnableMlirDynamicRangeQuantizer     = bool(false)
	Default_TocoFlags_DisableInferTensorRange             = bool(false)
	Default_TocoFlags_UseFakeQuantNumBits                 = bool(false)
	Default_TocoFlags_EnableDynamicUpdateSlice            = bool(false)
	Default_TocoFlags_PreserveAssertOp                    = bool(false)
	Default_TocoFlags_GuaranteeAllFuncsOneUse             = bool(false)
	Default_TocoFlags_ConvertToStablehlo                  = bool(false)
	Default_TocoFlags_EnableMlirVariableQuantization      = bool(false)
)

func (x *TocoFlags) Reset() {
	*x = TocoFlags{}
	if protoimpl.UnsafeEnabled {
		mi := &file_tensorflow_lite_toco_toco_flags_proto_msgTypes[0]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *TocoFlags) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TocoFlags) ProtoMessage() {}

func (x *TocoFlags) ProtoReflect() protoreflect.Message {
	mi := &file_tensorflow_lite_toco_toco_flags_proto_msgTypes[0]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TocoFlags.ProtoReflect.Descriptor instead.
func (*TocoFlags) Descriptor() ([]byte, []int) {
	return file_tensorflow_lite_toco_toco_flags_proto_rawDescGZIP(), []int{0}
}

func (x *TocoFlags) GetInputFormat() FileFormat {
	if x != nil && x.InputFormat != nil {
		return *x.InputFormat
	}
	return FileFormat_FILE_FORMAT_UNKNOWN
}

func (x *TocoFlags) GetOutputFormat() FileFormat {
	if x != nil && x.OutputFormat != nil {
		return *x.OutputFormat
	}
	return FileFormat_FILE_FORMAT_UNKNOWN
}

func (x *TocoFlags) GetInferenceInputType() IODataType {
	if x != nil && x.InferenceInputType != nil {
		return *x.InferenceInputType
	}
	return IODataType_IO_DATA_TYPE_UNKNOWN
}

func (x *TocoFlags) GetInferenceType() IODataType {
	if x != nil && x.InferenceType != nil {
		return *x.InferenceType
	}
	return IODataType_IO_DATA_TYPE_UNKNOWN
}

func (x *TocoFlags) GetDefaultRangesMin() float32 {
	if x != nil && x.DefaultRangesMin != nil {
		return *x.DefaultRangesMin
	}
	return 0
}

func (x *TocoFlags) GetDefaultRangesMax() float32 {
	if x != nil && x.DefaultRangesMax != nil {
		return *x.DefaultRangesMax
	}
	return 0
}

func (x *TocoFlags) GetDefaultInt16RangesMin() float32 {
	if x != nil && x.DefaultInt16RangesMin != nil {
		return *x.DefaultInt16RangesMin
	}
	return 0
}

func (x *TocoFlags) GetDefaultInt16RangesMax() float32 {
	if x != nil && x.DefaultInt16RangesMax != nil {
		return *x.DefaultInt16RangesMax
	}
	return 0
}

func (x *TocoFlags) GetDropFakeQuant() bool {
	if x != nil && x.DropFakeQuant != nil {
		return *x.DropFakeQuant
	}
	return false
}

func (x *TocoFlags) GetReorderAcrossFakeQuant() bool {
	if x != nil && x.ReorderAcrossFakeQuant != nil {
		return *x.ReorderAcrossFakeQuant
	}
	return false
}

func (x *TocoFlags) GetAllowCustomOps() bool {
	if x != nil && x.AllowCustomOps != nil {
		return *x.AllowCustomOps
	}
	return false
}

func (x *TocoFlags) GetDropControlDependency() bool {
	if x != nil && x.DropControlDependency != nil {
		return *x.DropControlDependency
	}
	return false
}

func (x *TocoFlags) GetDebugDisableRecurrentCellFusion() bool {
	if x != nil && x.DebugDisableRecurrentCellFusion != nil {
		return *x.DebugDisableRecurrentCellFusion
	}
	return false
}

func (x *TocoFlags) GetPropagateFakeQuantNumBits() bool {
	if x != nil && x.PropagateFakeQuantNumBits != nil {
		return *x.PropagateFakeQuantNumBits
	}
	return false
}

func (x *TocoFlags) GetAllowNudgingWeightsToUseFastGemmKernel() bool {
	if x != nil && x.AllowNudgingWeightsToUseFastGemmKernel != nil {
		return *x.AllowNudgingWeightsToUseFastGemmKernel
	}
	return false
}

func (x *TocoFlags) GetDedupeArrayMinSizeBytes() int64 {
	if x != nil && x.DedupeArrayMinSizeBytes != nil {
		return *x.DedupeArrayMinSizeBytes
	}
	return Default_TocoFlags_DedupeArrayMinSizeBytes
}

func (x *TocoFlags) GetSplitTfliteLstmInputs() bool {
	if x != nil && x.SplitTfliteLstmInputs != nil {
		return *x.SplitTfliteLstmInputs
	}
	return Default_TocoFlags_SplitTfliteLstmInputs
}

func (x *TocoFlags) GetQuantizeWeights() bool {
	if x != nil && x.QuantizeWeights != nil {
		return *x.QuantizeWeights
	}
	return Default_TocoFlags_QuantizeWeights
}

func (x *TocoFlags) GetDumpGraphvizDir() string {
	if x != nil && x.DumpGraphvizDir != nil {
		return *x.DumpGraphvizDir
	}
	return ""
}

func (x *TocoFlags) GetDumpGraphvizIncludeVideo() bool {
	if x != nil && x.DumpGraphvizIncludeVideo != nil {
		return *x.DumpGraphvizIncludeVideo
	}
	return false
}

func (x *TocoFlags) GetPostTrainingQuantize() bool {
	if x != nil && x.PostTrainingQuantize != nil {
		return *x.PostTrainingQuantize
	}
	return Default_TocoFlags_PostTrainingQuantize
}

func (x *TocoFlags) GetEnableSelectTfOps() bool {
	if x != nil && x.EnableSelectTfOps != nil {
		return *x.EnableSelectTfOps
	}
	return Default_TocoFlags_EnableSelectTfOps
}

func (x *TocoFlags) GetForceSelectTfOps() bool {
	if x != nil && x.ForceSelectTfOps != nil {
		return *x.ForceSelectTfOps
	}
	return Default_TocoFlags_ForceSelectTfOps
}

func (x *TocoFlags) GetQuantizeToFloat16() bool {
	if x != nil && x.QuantizeToFloat16 != nil {
		return *x.QuantizeToFloat16
	}
	return Default_TocoFlags_QuantizeToFloat16
}

func (x *TocoFlags) GetAllowDynamicTensors() bool {
	if x != nil && x.AllowDynamicTensors != nil {
		return *x.AllowDynamicTensors
	}
	return Default_TocoFlags_AllowDynamicTensors
}

func (x *TocoFlags) GetConversionSummaryDir() string {
	if x != nil && x.ConversionSummaryDir != nil {
		return *x.ConversionSummaryDir
	}
	return ""
}

// Deprecated: Do not use.
func (x *TocoFlags) GetCustomOpdefs() []string {
	if x != nil {
		return x.CustomOpdefs
	}
	return nil
}

func (x *TocoFlags) GetSelectUserTfOps() []string {
	if x != nil {
		return x.SelectUserTfOps
	}
	return nil
}

func (x *TocoFlags) GetEnableTfliteResourceVariables() bool {
	if x != nil && x.EnableTfliteResourceVariables != nil {
		return *x.EnableTfliteResourceVariables
	}
	return Default_TocoFlags_EnableTfliteResourceVariables
}

func (x *TocoFlags) GetUnfoldBatchmatmul() bool {
	if x != nil && x.UnfoldBatchmatmul != nil {
		return *x.UnfoldBatchmatmul
	}
	return Default_TocoFlags_UnfoldBatchmatmul
}

func (x *TocoFlags) GetLowerTensorListOps() bool {
	if x != nil && x.LowerTensorListOps != nil {
		return *x.LowerTensorListOps
	}
	return Default_TocoFlags_LowerTensorListOps
}

func (x *TocoFlags) GetAccumulationType() IODataType {
	if x != nil && x.AccumulationType != nil {
		return *x.AccumulationType
	}
	return IODataType_IO_DATA_TYPE_UNKNOWN
}

func (x *TocoFlags) GetAllowBfloat16() bool {
	if x != nil && x.AllowBfloat16 != nil {
		return *x.AllowBfloat16
	}
	return Default_TocoFlags_AllowBfloat16
}

func (x *TocoFlags) GetAllowAllSelectTfOps() bool {
	if x != nil && x.AllowAllSelectTfOps != nil {
		return *x.AllowAllSelectTfOps
	}
	return false
}

func (x *TocoFlags) GetUnfoldLargeSplatConstant() bool {
	if x != nil && x.UnfoldLargeSplatConstant != nil {
		return *x.UnfoldLargeSplatConstant
	}
	return Default_TocoFlags_UnfoldLargeSplatConstant
}

func (x *TocoFlags) GetSupportedBackends() []string {
	if x != nil {
		return x.SupportedBackends
	}
	return nil
}

func (x *TocoFlags) GetDefaultToSingleBatchInTensorListOps() bool {
	if x != nil && x.DefaultToSingleBatchInTensorListOps != nil {
		return *x.DefaultToSingleBatchInTensorListOps
	}
	return Default_TocoFlags_DefaultToSingleBatchInTensorListOps
}

func (x *TocoFlags) GetDisablePerChannelQuantization() bool {
	if x != nil && x.DisablePerChannelQuantization != nil {
		return *x.DisablePerChannelQuantization
	}
	return Default_TocoFlags_DisablePerChannelQuantization
}

func (x *TocoFlags) GetEnableMlirDynamicRangeQuantizer() bool {
	if x != nil && x.EnableMlirDynamicRangeQuantizer != nil {
		return *x.EnableMlirDynamicRangeQuantizer
	}
	return Default_TocoFlags_EnableMlirDynamicRangeQuantizer
}

func (x *TocoFlags) GetTfQuantizationMode() string {
	if x != nil && x.TfQuantizationMode != nil {
		return *x.TfQuantizationMode
	}
	return ""
}

func (x *TocoFlags) GetDisableInferTensorRange() bool {
	if x != nil && x.DisableInferTensorRange != nil {
		return *x.DisableInferTensorRange
	}
	return Default_TocoFlags_DisableInferTensorRange
}

func (x *TocoFlags) GetUseFakeQuantNumBits() bool {
	if x != nil && x.UseFakeQuantNumBits != nil {
		return *x.UseFakeQuantNumBits
	}
	return Default_TocoFlags_UseFakeQuantNumBits
}

func (x *TocoFlags) GetEnableDynamicUpdateSlice() bool {
	if x != nil && x.EnableDynamicUpdateSlice != nil {
		return *x.EnableDynamicUpdateSlice
	}
	return Default_TocoFlags_EnableDynamicUpdateSlice
}

func (x *TocoFlags) GetPreserveAssertOp() bool {
	if x != nil && x.PreserveAssertOp != nil {
		return *x.PreserveAssertOp
	}
	return Default_TocoFlags_PreserveAssertOp
}

func (x *TocoFlags) GetGuaranteeAllFuncsOneUse() bool {
	if x != nil && x.GuaranteeAllFuncsOneUse != nil {
		return *x.GuaranteeAllFuncsOneUse
	}
	return Default_TocoFlags_GuaranteeAllFuncsOneUse
}

func (x *TocoFlags) GetConvertToStablehlo() bool {
	if x != nil && x.ConvertToStablehlo != nil {
		return *x.ConvertToStablehlo
	}
	return Default_TocoFlags_ConvertToStablehlo
}

func (x *TocoFlags) GetEnableMlirVariableQuantization() bool {
	if x != nil && x.EnableMlirVariableQuantization != nil {
		return *x.EnableMlirVariableQuantization
	}
	return Default_TocoFlags_EnableMlirVariableQuantization
}

var File_tensorflow_lite_toco_toco_flags_proto protoreflect.FileDescriptor

var file_tensorflow_lite_toco_toco_flags_proto_rawDesc = []byte{
	0x0a, 0x25, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2f, 0x6c, 0x69, 0x74,
	0x65, 0x2f, 0x74, 0x6f, 0x63, 0x6f, 0x2f, 0x74, 0x6f, 0x63, 0x6f, 0x5f, 0x66, 0x6c, 0x61, 0x67,
	0x73, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x12, 0x04, 0x74, 0x6f, 0x63, 0x6f, 0x1a, 0x20, 0x74,
	0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77, 0x2f, 0x6c, 0x69, 0x74, 0x65, 0x2f, 0x74,
	0x6f, 0x63, 0x6f, 0x2f, 0x74, 0x79, 0x70, 0x65, 0x73, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x22,
	0x94, 0x16, 0x0a, 0x09, 0x54, 0x6f, 0x63, 0x6f, 0x46, 0x6c, 0x61, 0x67, 0x73, 0x12, 0x33, 0x0a,
	0x0c, 0x69, 0x6e, 0x70, 0x75, 0x74, 0x5f, 0x66, 0x6f, 0x72, 0x6d, 0x61, 0x74, 0x18, 0x01, 0x20,
	0x01, 0x28, 0x0e, 0x32, 0x10, 0x2e, 0x74, 0x6f, 0x63, 0x6f, 0x2e, 0x46, 0x69, 0x6c, 0x65, 0x46,
	0x6f, 0x72, 0x6d, 0x61, 0x74, 0x52, 0x0b, 0x69, 0x6e, 0x70, 0x75, 0x74, 0x46, 0x6f, 0x72, 0x6d,
	0x61, 0x74, 0x12, 0x35, 0x0a, 0x0d, 0x6f, 0x75, 0x74, 0x70, 0x75, 0x74, 0x5f, 0x66, 0x6f, 0x72,
	0x6d, 0x61, 0x74, 0x18, 0x02, 0x20, 0x01, 0x28, 0x0e, 0x32, 0x10, 0x2e, 0x74, 0x6f, 0x63, 0x6f,
	0x2e, 0x46, 0x69, 0x6c, 0x65, 0x46, 0x6f, 0x72, 0x6d, 0x61, 0x74, 0x52, 0x0c, 0x6f, 0x75, 0x74,
	0x70, 0x75, 0x74, 0x46, 0x6f, 0x72, 0x6d, 0x61, 0x74, 0x12, 0x42, 0x0a, 0x14, 0x69, 0x6e, 0x66,
	0x65, 0x72, 0x65, 0x6e, 0x63, 0x65, 0x5f, 0x69, 0x6e, 0x70, 0x75, 0x74, 0x5f, 0x74, 0x79, 0x70,
	0x65, 0x18, 0x0b, 0x20, 0x01, 0x28, 0x0e, 0x32, 0x10, 0x2e, 0x74, 0x6f, 0x63, 0x6f, 0x2e, 0x49,
	0x4f, 0x44, 0x61, 0x74, 0x61, 0x54, 0x79, 0x70, 0x65, 0x52, 0x12, 0x69, 0x6e, 0x66, 0x65, 0x72,
	0x65, 0x6e, 0x63, 0x65, 0x49, 0x6e, 0x70, 0x75, 0x74, 0x54, 0x79, 0x70, 0x65, 0x12, 0x37, 0x0a,
	0x0e, 0x69, 0x6e, 0x66, 0x65, 0x72, 0x65, 0x6e, 0x63, 0x65, 0x5f, 0x74, 0x79, 0x70, 0x65, 0x18,
	0x04, 0x20, 0x01, 0x28, 0x0e, 0x32, 0x10, 0x2e, 0x74, 0x6f, 0x63, 0x6f, 0x2e, 0x49, 0x4f, 0x44,
	0x61, 0x74, 0x61, 0x54, 0x79, 0x70, 0x65, 0x52, 0x0d, 0x69, 0x6e, 0x66, 0x65, 0x72, 0x65, 0x6e,
	0x63, 0x65, 0x54, 0x79, 0x70, 0x65, 0x12, 0x2c, 0x0a, 0x12, 0x64, 0x65, 0x66, 0x61, 0x75, 0x6c,
	0x74, 0x5f, 0x72, 0x61, 0x6e, 0x67, 0x65, 0x73, 0x5f, 0x6d, 0x69, 0x6e, 0x18, 0x05, 0x20, 0x01,
	0x28, 0x02, 0x52, 0x10, 0x64, 0x65, 0x66, 0x61, 0x75, 0x6c, 0x74, 0x52, 0x61, 0x6e, 0x67, 0x65,
	0x73, 0x4d, 0x69, 0x6e, 0x12, 0x2c, 0x0a, 0x12, 0x64, 0x65, 0x66, 0x61, 0x75, 0x6c, 0x74, 0x5f,
	0x72, 0x61, 0x6e, 0x67, 0x65, 0x73, 0x5f, 0x6d, 0x61, 0x78, 0x18, 0x06, 0x20, 0x01, 0x28, 0x02,
	0x52, 0x10, 0x64, 0x65, 0x66, 0x61, 0x75, 0x6c, 0x74, 0x52, 0x61, 0x6e, 0x67, 0x65, 0x73, 0x4d,
	0x61, 0x78, 0x12, 0x37, 0x0a, 0x18, 0x64, 0x65, 0x66, 0x61, 0x75, 0x6c, 0x74, 0x5f, 0x69, 0x6e,
	0x74, 0x31, 0x36, 0x5f, 0x72, 0x61, 0x6e, 0x67, 0x65, 0x73, 0x5f, 0x6d, 0x69, 0x6e, 0x18, 0x0f,
	0x20, 0x01, 0x28, 0x02, 0x52, 0x15, 0x64, 0x65, 0x66, 0x61, 0x75, 0x6c, 0x74, 0x49, 0x6e, 0x74,
	0x31, 0x36, 0x52, 0x61, 0x6e, 0x67, 0x65, 0x73, 0x4d, 0x69, 0x6e, 0x12, 0x37, 0x0a, 0x18, 0x64,
	0x65, 0x66, 0x61, 0x75, 0x6c, 0x74, 0x5f, 0x69, 0x6e, 0x74, 0x31, 0x36, 0x5f, 0x72, 0x61, 0x6e,
	0x67, 0x65, 0x73, 0x5f, 0x6d, 0x61, 0x78, 0x18, 0x10, 0x20, 0x01, 0x28, 0x02, 0x52, 0x15, 0x64,
	0x65, 0x66, 0x61, 0x75, 0x6c, 0x74, 0x49, 0x6e, 0x74, 0x31, 0x36, 0x52, 0x61, 0x6e, 0x67, 0x65,
	0x73, 0x4d, 0x61, 0x78, 0x12, 0x26, 0x0a, 0x0f, 0x64, 0x72, 0x6f, 0x70, 0x5f, 0x66, 0x61, 0x6b,
	0x65, 0x5f, 0x71, 0x75, 0x61, 0x6e, 0x74, 0x18, 0x07, 0x20, 0x01, 0x28, 0x08, 0x52, 0x0d, 0x64,
	0x72, 0x6f, 0x70, 0x46, 0x61, 0x6b, 0x65, 0x51, 0x75, 0x61, 0x6e, 0x74, 0x12, 0x39, 0x0a, 0x19,
	0x72, 0x65, 0x6f, 0x72, 0x64, 0x65, 0x72, 0x5f, 0x61, 0x63, 0x72, 0x6f, 0x73, 0x73, 0x5f, 0x66,
	0x61, 0x6b, 0x65, 0x5f, 0x71, 0x75, 0x61, 0x6e, 0x74, 0x18, 0x08, 0x20, 0x01, 0x28, 0x08, 0x52,
	0x16, 0x72, 0x65, 0x6f, 0x72, 0x64, 0x65, 0x72, 0x41, 0x63, 0x72, 0x6f, 0x73, 0x73, 0x46, 0x61,
	0x6b, 0x65, 0x51, 0x75, 0x61, 0x6e, 0x74, 0x12, 0x28, 0x0a, 0x10, 0x61, 0x6c, 0x6c, 0x6f, 0x77,
	0x5f, 0x63, 0x75, 0x73, 0x74, 0x6f, 0x6d, 0x5f, 0x6f, 0x70, 0x73, 0x18, 0x0a, 0x20, 0x01, 0x28,
	0x08, 0x52, 0x0e, 0x61, 0x6c, 0x6c, 0x6f, 0x77, 0x43, 0x75, 0x73, 0x74, 0x6f, 0x6d, 0x4f, 0x70,
	0x73, 0x12, 0x36, 0x0a, 0x17, 0x64, 0x72, 0x6f, 0x70, 0x5f, 0x63, 0x6f, 0x6e, 0x74, 0x72, 0x6f,
	0x6c, 0x5f, 0x64, 0x65, 0x70, 0x65, 0x6e, 0x64, 0x65, 0x6e, 0x63, 0x79, 0x18, 0x0c, 0x20, 0x01,
	0x28, 0x08, 0x52, 0x15, 0x64, 0x72, 0x6f, 0x70, 0x43, 0x6f, 0x6e, 0x74, 0x72, 0x6f, 0x6c, 0x44,
	0x65, 0x70, 0x65, 0x6e, 0x64, 0x65, 0x6e, 0x63, 0x79, 0x12, 0x4c, 0x0a, 0x23, 0x64, 0x65, 0x62,
	0x75, 0x67, 0x5f, 0x64, 0x69, 0x73, 0x61, 0x62, 0x6c, 0x65, 0x5f, 0x72, 0x65, 0x63, 0x75, 0x72,
	0x72, 0x65, 0x6e, 0x74, 0x5f, 0x63, 0x65, 0x6c, 0x6c, 0x5f, 0x66, 0x75, 0x73, 0x69, 0x6f, 0x6e,
	0x18, 0x0d, 0x20, 0x01, 0x28, 0x08, 0x52, 0x1f, 0x64, 0x65, 0x62, 0x75, 0x67, 0x44, 0x69, 0x73,
	0x61, 0x62, 0x6c, 0x65, 0x52, 0x65, 0x63, 0x75, 0x72, 0x72, 0x65, 0x6e, 0x74, 0x43, 0x65, 0x6c,
	0x6c, 0x46, 0x75, 0x73, 0x69, 0x6f, 0x6e, 0x12, 0x40, 0x0a, 0x1d, 0x70, 0x72, 0x6f, 0x70, 0x61,
	0x67, 0x61, 0x74, 0x65, 0x5f, 0x66, 0x61, 0x6b, 0x65, 0x5f, 0x71, 0x75, 0x61, 0x6e, 0x74, 0x5f,
	0x6e, 0x75, 0x6d, 0x5f, 0x62, 0x69, 0x74, 0x73, 0x18, 0x0e, 0x20, 0x01, 0x28, 0x08, 0x52, 0x19,
	0x70, 0x72, 0x6f, 0x70, 0x61, 0x67, 0x61, 0x74, 0x65, 0x46, 0x61, 0x6b, 0x65, 0x51, 0x75, 0x61,
	0x6e, 0x74, 0x4e, 0x75, 0x6d, 0x42, 0x69, 0x74, 0x73, 0x12, 0x5d, 0x0a, 0x2d, 0x61, 0x6c, 0x6c,
	0x6f, 0x77, 0x5f, 0x6e, 0x75, 0x64, 0x67, 0x69, 0x6e, 0x67, 0x5f, 0x77, 0x65, 0x69, 0x67, 0x68,
	0x74, 0x73, 0x5f, 0x74, 0x6f, 0x5f, 0x75, 0x73, 0x65, 0x5f, 0x66, 0x61, 0x73, 0x74, 0x5f, 0x67,
	0x65, 0x6d, 0x6d, 0x5f, 0x6b, 0x65, 0x72, 0x6e, 0x65, 0x6c, 0x18, 0x11, 0x20, 0x01, 0x28, 0x08,
	0x52, 0x26, 0x61, 0x6c, 0x6c, 0x6f, 0x77, 0x4e, 0x75, 0x64, 0x67, 0x69, 0x6e, 0x67, 0x57, 0x65,
	0x69, 0x67, 0x68, 0x74, 0x73, 0x54, 0x6f, 0x55, 0x73, 0x65, 0x46, 0x61, 0x73, 0x74, 0x47, 0x65,
	0x6d, 0x6d, 0x4b, 0x65, 0x72, 0x6e, 0x65, 0x6c, 0x12, 0x40, 0x0a, 0x1b, 0x64, 0x65, 0x64, 0x75,
	0x70, 0x65, 0x5f, 0x61, 0x72, 0x72, 0x61, 0x79, 0x5f, 0x6d, 0x69, 0x6e, 0x5f, 0x73, 0x69, 0x7a,
	0x65, 0x5f, 0x62, 0x79, 0x74, 0x65, 0x73, 0x18, 0x12, 0x20, 0x01, 0x28, 0x03, 0x3a, 0x02, 0x36,
	0x34, 0x52, 0x17, 0x64, 0x65, 0x64, 0x75, 0x70, 0x65, 0x41, 0x72, 0x72, 0x61, 0x79, 0x4d, 0x69,
	0x6e, 0x53, 0x69, 0x7a, 0x65, 0x42, 0x79, 0x74, 0x65, 0x73, 0x12, 0x3d, 0x0a, 0x18, 0x73, 0x70,
	0x6c, 0x69, 0x74, 0x5f, 0x74, 0x66, 0x6c, 0x69, 0x74, 0x65, 0x5f, 0x6c, 0x73, 0x74, 0x6d, 0x5f,
	0x69, 0x6e, 0x70, 0x75, 0x74, 0x73, 0x18, 0x13, 0x20, 0x01, 0x28, 0x08, 0x3a, 0x04, 0x74, 0x72,
	0x75, 0x65, 0x52, 0x15, 0x73, 0x70, 0x6c, 0x69, 0x74, 0x54, 0x66, 0x6c, 0x69, 0x74, 0x65, 0x4c,
	0x73, 0x74, 0x6d, 0x49, 0x6e, 0x70, 0x75, 0x74, 0x73, 0x12, 0x30, 0x0a, 0x10, 0x71, 0x75, 0x61,
	0x6e, 0x74, 0x69, 0x7a, 0x65, 0x5f, 0x77, 0x65, 0x69, 0x67, 0x68, 0x74, 0x73, 0x18, 0x14, 0x20,
	0x01, 0x28, 0x08, 0x3a, 0x05, 0x66, 0x61, 0x6c, 0x73, 0x65, 0x52, 0x0f, 0x71, 0x75, 0x61, 0x6e,
	0x74, 0x69, 0x7a, 0x65, 0x57, 0x65, 0x69, 0x67, 0x68, 0x74, 0x73, 0x12, 0x2a, 0x0a, 0x11, 0x64,
	0x75, 0x6d, 0x70, 0x5f, 0x67, 0x72, 0x61, 0x70, 0x68, 0x76, 0x69, 0x7a, 0x5f, 0x64, 0x69, 0x72,
	0x18, 0x18, 0x20, 0x01, 0x28, 0x09, 0x52, 0x0f, 0x64, 0x75, 0x6d, 0x70, 0x47, 0x72, 0x61, 0x70,
	0x68, 0x76, 0x69, 0x7a, 0x44, 0x69, 0x72, 0x12, 0x3d, 0x0a, 0x1b, 0x64, 0x75, 0x6d, 0x70, 0x5f,
	0x67, 0x72, 0x61, 0x70, 0x68, 0x76, 0x69, 0x7a, 0x5f, 0x69, 0x6e, 0x63, 0x6c, 0x75, 0x64, 0x65,
	0x5f, 0x76, 0x69, 0x64, 0x65, 0x6f, 0x18, 0x19, 0x20, 0x01, 0x28, 0x08, 0x52, 0x18, 0x64, 0x75,
	0x6d, 0x70, 0x47, 0x72, 0x61, 0x70, 0x68, 0x76, 0x69, 0x7a, 0x49, 0x6e, 0x63, 0x6c, 0x75, 0x64,
	0x65, 0x56, 0x69, 0x64, 0x65, 0x6f, 0x12, 0x3b, 0x0a, 0x16, 0x70, 0x6f, 0x73, 0x74, 0x5f, 0x74,
	0x72, 0x61, 0x69, 0x6e, 0x69, 0x6e, 0x67, 0x5f, 0x71, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x65,
	0x18, 0x1a, 0x20, 0x01, 0x28, 0x08, 0x3a, 0x05, 0x66, 0x61, 0x6c, 0x73, 0x65, 0x52, 0x14, 0x70,
	0x6f, 0x73, 0x74, 0x54, 0x72, 0x61, 0x69, 0x6e, 0x69, 0x6e, 0x67, 0x51, 0x75, 0x61, 0x6e, 0x74,
	0x69, 0x7a, 0x65, 0x12, 0x36, 0x0a, 0x14, 0x65, 0x6e, 0x61, 0x62, 0x6c, 0x65, 0x5f, 0x73, 0x65,
	0x6c, 0x65, 0x63, 0x74, 0x5f, 0x74, 0x66, 0x5f, 0x6f, 0x70, 0x73, 0x18, 0x1b, 0x20, 0x01, 0x28,
	0x08, 0x3a, 0x05, 0x66, 0x61, 0x6c, 0x73, 0x65, 0x52, 0x11, 0x65, 0x6e, 0x61, 0x62, 0x6c, 0x65,
	0x53, 0x65, 0x6c, 0x65, 0x63, 0x74, 0x54, 0x66, 0x4f, 0x70, 0x73, 0x12, 0x34, 0x0a, 0x13, 0x66,
	0x6f, 0x72, 0x63, 0x65, 0x5f, 0x73, 0x65, 0x6c, 0x65, 0x63, 0x74, 0x5f, 0x74, 0x66, 0x5f, 0x6f,
	0x70, 0x73, 0x18, 0x1c, 0x20, 0x01, 0x28, 0x08, 0x3a, 0x05, 0x66, 0x61, 0x6c, 0x73, 0x65, 0x52,
	0x10, 0x66, 0x6f, 0x72, 0x63, 0x65, 0x53, 0x65, 0x6c, 0x65, 0x63, 0x74, 0x54, 0x66, 0x4f, 0x70,
	0x73, 0x12, 0x35, 0x0a, 0x13, 0x71, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x65, 0x5f, 0x74, 0x6f,
	0x5f, 0x66, 0x6c, 0x6f, 0x61, 0x74, 0x31, 0x36, 0x18, 0x1d, 0x20, 0x01, 0x28, 0x08, 0x3a, 0x05,
	0x66, 0x61, 0x6c, 0x73, 0x65, 0x52, 0x11, 0x71, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x65, 0x54,
	0x6f, 0x46, 0x6c, 0x6f, 0x61, 0x74, 0x31, 0x36, 0x12, 0x38, 0x0a, 0x15, 0x61, 0x6c, 0x6c, 0x6f,
	0x77, 0x5f, 0x64, 0x79, 0x6e, 0x61, 0x6d, 0x69, 0x63, 0x5f, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72,
	0x73, 0x18, 0x1e, 0x20, 0x01, 0x28, 0x08, 0x3a, 0x04, 0x74, 0x72, 0x75, 0x65, 0x52, 0x13, 0x61,
	0x6c, 0x6c, 0x6f, 0x77, 0x44, 0x79, 0x6e, 0x61, 0x6d, 0x69, 0x63, 0x54, 0x65, 0x6e, 0x73, 0x6f,
	0x72, 0x73, 0x12, 0x34, 0x0a, 0x16, 0x63, 0x6f, 0x6e, 0x76, 0x65, 0x72, 0x73, 0x69, 0x6f, 0x6e,
	0x5f, 0x73, 0x75, 0x6d, 0x6d, 0x61, 0x72, 0x79, 0x5f, 0x64, 0x69, 0x72, 0x18, 0x1f, 0x20, 0x01,
	0x28, 0x09, 0x52, 0x14, 0x63, 0x6f, 0x6e, 0x76, 0x65, 0x72, 0x73, 0x69, 0x6f, 0x6e, 0x53, 0x75,
	0x6d, 0x6d, 0x61, 0x72, 0x79, 0x44, 0x69, 0x72, 0x12, 0x27, 0x0a, 0x0d, 0x63, 0x75, 0x73, 0x74,
	0x6f, 0x6d, 0x5f, 0x6f, 0x70, 0x64, 0x65, 0x66, 0x73, 0x18, 0x20, 0x20, 0x03, 0x28, 0x09, 0x42,
	0x02, 0x18, 0x01, 0x52, 0x0c, 0x63, 0x75, 0x73, 0x74, 0x6f, 0x6d, 0x4f, 0x70, 0x64, 0x65, 0x66,
	0x73, 0x12, 0x2b, 0x0a, 0x12, 0x73, 0x65, 0x6c, 0x65, 0x63, 0x74, 0x5f, 0x75, 0x73, 0x65, 0x72,
	0x5f, 0x74, 0x66, 0x5f, 0x6f, 0x70, 0x73, 0x18, 0x21, 0x20, 0x03, 0x28, 0x09, 0x52, 0x0f, 0x73,
	0x65, 0x6c, 0x65, 0x63, 0x74, 0x55, 0x73, 0x65, 0x72, 0x54, 0x66, 0x4f, 0x70, 0x73, 0x12, 0x4d,
	0x0a, 0x20, 0x65, 0x6e, 0x61, 0x62, 0x6c, 0x65, 0x5f, 0x74, 0x66, 0x6c, 0x69, 0x74, 0x65, 0x5f,
	0x72, 0x65, 0x73, 0x6f, 0x75, 0x72, 0x63, 0x65, 0x5f, 0x76, 0x61, 0x72, 0x69, 0x61, 0x62, 0x6c,
	0x65, 0x73, 0x18, 0x22, 0x20, 0x01, 0x28, 0x08, 0x3a, 0x04, 0x74, 0x72, 0x75, 0x65, 0x52, 0x1d,
	0x65, 0x6e, 0x61, 0x62, 0x6c, 0x65, 0x54, 0x66, 0x6c, 0x69, 0x74, 0x65, 0x52, 0x65, 0x73, 0x6f,
	0x75, 0x72, 0x63, 0x65, 0x56, 0x61, 0x72, 0x69, 0x61, 0x62, 0x6c, 0x65, 0x73, 0x12, 0x33, 0x0a,
	0x12, 0x75, 0x6e, 0x66, 0x6f, 0x6c, 0x64, 0x5f, 0x62, 0x61, 0x74, 0x63, 0x68, 0x6d, 0x61, 0x74,
	0x6d, 0x75, 0x6c, 0x18, 0x23, 0x20, 0x01, 0x28, 0x08, 0x3a, 0x04, 0x74, 0x72, 0x75, 0x65, 0x52,
	0x11, 0x75, 0x6e, 0x66, 0x6f, 0x6c, 0x64, 0x42, 0x61, 0x74, 0x63, 0x68, 0x6d, 0x61, 0x74, 0x6d,
	0x75, 0x6c, 0x12, 0x37, 0x0a, 0x15, 0x6c, 0x6f, 0x77, 0x65, 0x72, 0x5f, 0x74, 0x65, 0x6e, 0x73,
	0x6f, 0x72, 0x5f, 0x6c, 0x69, 0x73, 0x74, 0x5f, 0x6f, 0x70, 0x73, 0x18, 0x24, 0x20, 0x01, 0x28,
	0x08, 0x3a, 0x04, 0x74, 0x72, 0x75, 0x65, 0x52, 0x12, 0x6c, 0x6f, 0x77, 0x65, 0x72, 0x54, 0x65,
	0x6e, 0x73, 0x6f, 0x72, 0x4c, 0x69, 0x73, 0x74, 0x4f, 0x70, 0x73, 0x12, 0x3d, 0x0a, 0x11, 0x61,
	0x63, 0x63, 0x75, 0x6d, 0x75, 0x6c, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x5f, 0x74, 0x79, 0x70, 0x65,
	0x18, 0x25, 0x20, 0x01, 0x28, 0x0e, 0x32, 0x10, 0x2e, 0x74, 0x6f, 0x63, 0x6f, 0x2e, 0x49, 0x4f,
	0x44, 0x61, 0x74, 0x61, 0x54, 0x79, 0x70, 0x65, 0x52, 0x10, 0x61, 0x63, 0x63, 0x75, 0x6d, 0x75,
	0x6c, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x54, 0x79, 0x70, 0x65, 0x12, 0x2c, 0x0a, 0x0e, 0x61, 0x6c,
	0x6c, 0x6f, 0x77, 0x5f, 0x62, 0x66, 0x6c, 0x6f, 0x61, 0x74, 0x31, 0x36, 0x18, 0x26, 0x20, 0x01,
	0x28, 0x08, 0x3a, 0x05, 0x66, 0x61, 0x6c, 0x73, 0x65, 0x52, 0x0d, 0x61, 0x6c, 0x6c, 0x6f, 0x77,
	0x42, 0x66, 0x6c, 0x6f, 0x61, 0x74, 0x31, 0x36, 0x12, 0x34, 0x0a, 0x17, 0x61, 0x6c, 0x6c, 0x6f,
	0x77, 0x5f, 0x61, 0x6c, 0x6c, 0x5f, 0x73, 0x65, 0x6c, 0x65, 0x63, 0x74, 0x5f, 0x74, 0x66, 0x5f,
	0x6f, 0x70, 0x73, 0x18, 0x27, 0x20, 0x01, 0x28, 0x08, 0x52, 0x13, 0x61, 0x6c, 0x6c, 0x6f, 0x77,
	0x41, 0x6c, 0x6c, 0x53, 0x65, 0x6c, 0x65, 0x63, 0x74, 0x54, 0x66, 0x4f, 0x70, 0x73, 0x12, 0x44,
	0x0a, 0x1b, 0x75, 0x6e, 0x66, 0x6f, 0x6c, 0x64, 0x5f, 0x6c, 0x61, 0x72, 0x67, 0x65, 0x5f, 0x73,
	0x70, 0x6c, 0x61, 0x74, 0x5f, 0x63, 0x6f, 0x6e, 0x73, 0x74, 0x61, 0x6e, 0x74, 0x18, 0x28, 0x20,
	0x01, 0x28, 0x08, 0x3a, 0x05, 0x66, 0x61, 0x6c, 0x73, 0x65, 0x52, 0x18, 0x75, 0x6e, 0x66, 0x6f,
	0x6c, 0x64, 0x4c, 0x61, 0x72, 0x67, 0x65, 0x53, 0x70, 0x6c, 0x61, 0x74, 0x43, 0x6f, 0x6e, 0x73,
	0x74, 0x61, 0x6e, 0x74, 0x12, 0x2d, 0x0a, 0x12, 0x73, 0x75, 0x70, 0x70, 0x6f, 0x72, 0x74, 0x65,
	0x64, 0x5f, 0x62, 0x61, 0x63, 0x6b, 0x65, 0x6e, 0x64, 0x73, 0x18, 0x29, 0x20, 0x03, 0x28, 0x09,
	0x52, 0x11, 0x73, 0x75, 0x70, 0x70, 0x6f, 0x72, 0x74, 0x65, 0x64, 0x42, 0x61, 0x63, 0x6b, 0x65,
	0x6e, 0x64, 0x73, 0x12, 0x5e, 0x0a, 0x2a, 0x64, 0x65, 0x66, 0x61, 0x75, 0x6c, 0x74, 0x5f, 0x74,
	0x6f, 0x5f, 0x73, 0x69, 0x6e, 0x67, 0x6c, 0x65, 0x5f, 0x62, 0x61, 0x74, 0x63, 0x68, 0x5f, 0x69,
	0x6e, 0x5f, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x5f, 0x6c, 0x69, 0x73, 0x74, 0x5f, 0x6f, 0x70,
	0x73, 0x18, 0x2a, 0x20, 0x01, 0x28, 0x08, 0x3a, 0x05, 0x66, 0x61, 0x6c, 0x73, 0x65, 0x52, 0x23,
	0x64, 0x65, 0x66, 0x61, 0x75, 0x6c, 0x74, 0x54, 0x6f, 0x53, 0x69, 0x6e, 0x67, 0x6c, 0x65, 0x42,
	0x61, 0x74, 0x63, 0x68, 0x49, 0x6e, 0x54, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x4c, 0x69, 0x73, 0x74,
	0x4f, 0x70, 0x73, 0x12, 0x4e, 0x0a, 0x20, 0x64, 0x69, 0x73, 0x61, 0x62, 0x6c, 0x65, 0x5f, 0x70,
	0x65, 0x72, 0x5f, 0x63, 0x68, 0x61, 0x6e, 0x6e, 0x65, 0x6c, 0x5f, 0x71, 0x75, 0x61, 0x6e, 0x74,
	0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x18, 0x2b, 0x20, 0x01, 0x28, 0x08, 0x3a, 0x05, 0x66,
	0x61, 0x6c, 0x73, 0x65, 0x52, 0x1d, 0x64, 0x69, 0x73, 0x61, 0x62, 0x6c, 0x65, 0x50, 0x65, 0x72,
	0x43, 0x68, 0x61, 0x6e, 0x6e, 0x65, 0x6c, 0x51, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x61, 0x74,
	0x69, 0x6f, 0x6e, 0x12, 0x53, 0x0a, 0x23, 0x65, 0x6e, 0x61, 0x62, 0x6c, 0x65, 0x5f, 0x6d, 0x6c,
	0x69, 0x72, 0x5f, 0x64, 0x79, 0x6e, 0x61, 0x6d, 0x69, 0x63, 0x5f, 0x72, 0x61, 0x6e, 0x67, 0x65,
	0x5f, 0x71, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x65, 0x72, 0x18, 0x2c, 0x20, 0x01, 0x28, 0x08,
	0x3a, 0x05, 0x66, 0x61, 0x6c, 0x73, 0x65, 0x52, 0x1f, 0x65, 0x6e, 0x61, 0x62, 0x6c, 0x65, 0x4d,
	0x6c, 0x69, 0x72, 0x44, 0x79, 0x6e, 0x61, 0x6d, 0x69, 0x63, 0x52, 0x61, 0x6e, 0x67, 0x65, 0x51,
	0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x65, 0x72, 0x12, 0x30, 0x0a, 0x14, 0x74, 0x66, 0x5f, 0x71,
	0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x5f, 0x6d, 0x6f, 0x64, 0x65,
	0x18, 0x2d, 0x20, 0x01, 0x28, 0x09, 0x52, 0x12, 0x74, 0x66, 0x51, 0x75, 0x61, 0x6e, 0x74, 0x69,
	0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x4d, 0x6f, 0x64, 0x65, 0x12, 0x42, 0x0a, 0x1a, 0x64, 0x69,
	0x73, 0x61, 0x62, 0x6c, 0x65, 0x5f, 0x69, 0x6e, 0x66, 0x65, 0x72, 0x5f, 0x74, 0x65, 0x6e, 0x73,
	0x6f, 0x72, 0x5f, 0x72, 0x61, 0x6e, 0x67, 0x65, 0x18, 0x2e, 0x20, 0x01, 0x28, 0x08, 0x3a, 0x05,
	0x66, 0x61, 0x6c, 0x73, 0x65, 0x52, 0x17, 0x64, 0x69, 0x73, 0x61, 0x62, 0x6c, 0x65, 0x49, 0x6e,
	0x66, 0x65, 0x72, 0x54, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x52, 0x61, 0x6e, 0x67, 0x65, 0x12, 0x3b,
	0x0a, 0x17, 0x75, 0x73, 0x65, 0x5f, 0x66, 0x61, 0x6b, 0x65, 0x5f, 0x71, 0x75, 0x61, 0x6e, 0x74,
	0x5f, 0x6e, 0x75, 0x6d, 0x5f, 0x62, 0x69, 0x74, 0x73, 0x18, 0x2f, 0x20, 0x01, 0x28, 0x08, 0x3a,
	0x05, 0x66, 0x61, 0x6c, 0x73, 0x65, 0x52, 0x13, 0x75, 0x73, 0x65, 0x46, 0x61, 0x6b, 0x65, 0x51,
	0x75, 0x61, 0x6e, 0x74, 0x4e, 0x75, 0x6d, 0x42, 0x69, 0x74, 0x73, 0x12, 0x44, 0x0a, 0x1b, 0x65,
	0x6e, 0x61, 0x62, 0x6c, 0x65, 0x5f, 0x64, 0x79, 0x6e, 0x61, 0x6d, 0x69, 0x63, 0x5f, 0x75, 0x70,
	0x64, 0x61, 0x74, 0x65, 0x5f, 0x73, 0x6c, 0x69, 0x63, 0x65, 0x18, 0x30, 0x20, 0x01, 0x28, 0x08,
	0x3a, 0x05, 0x66, 0x61, 0x6c, 0x73, 0x65, 0x52, 0x18, 0x65, 0x6e, 0x61, 0x62, 0x6c, 0x65, 0x44,
	0x79, 0x6e, 0x61, 0x6d, 0x69, 0x63, 0x55, 0x70, 0x64, 0x61, 0x74, 0x65, 0x53, 0x6c, 0x69, 0x63,
	0x65, 0x12, 0x33, 0x0a, 0x12, 0x70, 0x72, 0x65, 0x73, 0x65, 0x72, 0x76, 0x65, 0x5f, 0x61, 0x73,
	0x73, 0x65, 0x72, 0x74, 0x5f, 0x6f, 0x70, 0x18, 0x31, 0x20, 0x01, 0x28, 0x08, 0x3a, 0x05, 0x66,
	0x61, 0x6c, 0x73, 0x65, 0x52, 0x10, 0x70, 0x72, 0x65, 0x73, 0x65, 0x72, 0x76, 0x65, 0x41, 0x73,
	0x73, 0x65, 0x72, 0x74, 0x4f, 0x70, 0x12, 0x43, 0x0a, 0x1b, 0x67, 0x75, 0x61, 0x72, 0x61, 0x6e,
	0x74, 0x65, 0x65, 0x5f, 0x61, 0x6c, 0x6c, 0x5f, 0x66, 0x75, 0x6e, 0x63, 0x73, 0x5f, 0x6f, 0x6e,
	0x65, 0x5f, 0x75, 0x73, 0x65, 0x18, 0x32, 0x20, 0x01, 0x28, 0x08, 0x3a, 0x05, 0x66, 0x61, 0x6c,
	0x73, 0x65, 0x52, 0x17, 0x67, 0x75, 0x61, 0x72, 0x61, 0x6e, 0x74, 0x65, 0x65, 0x41, 0x6c, 0x6c,
	0x46, 0x75, 0x6e, 0x63, 0x73, 0x4f, 0x6e, 0x65, 0x55, 0x73, 0x65, 0x12, 0x37, 0x0a, 0x14, 0x63,
	0x6f, 0x6e, 0x76, 0x65, 0x72, 0x74, 0x5f, 0x74, 0x6f, 0x5f, 0x73, 0x74, 0x61, 0x62, 0x6c, 0x65,
	0x68, 0x6c, 0x6f, 0x18, 0x33, 0x20, 0x01, 0x28, 0x08, 0x3a, 0x05, 0x66, 0x61, 0x6c, 0x73, 0x65,
	0x52, 0x12, 0x63, 0x6f, 0x6e, 0x76, 0x65, 0x72, 0x74, 0x54, 0x6f, 0x53, 0x74, 0x61, 0x62, 0x6c,
	0x65, 0x68, 0x6c, 0x6f, 0x12, 0x50, 0x0a, 0x21, 0x65, 0x6e, 0x61, 0x62, 0x6c, 0x65, 0x5f, 0x6d,
	0x6c, 0x69, 0x72, 0x5f, 0x76, 0x61, 0x72, 0x69, 0x61, 0x62, 0x6c, 0x65, 0x5f, 0x71, 0x75, 0x61,
	0x6e, 0x74, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x18, 0x34, 0x20, 0x01, 0x28, 0x08, 0x3a,
	0x05, 0x66, 0x61, 0x6c, 0x73, 0x65, 0x52, 0x1e, 0x65, 0x6e, 0x61, 0x62, 0x6c, 0x65, 0x4d, 0x6c,
	0x69, 0x72, 0x56, 0x61, 0x72, 0x69, 0x61, 0x62, 0x6c, 0x65, 0x51, 0x75, 0x61, 0x6e, 0x74, 0x69,
	0x7a, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x2a, 0x5c, 0x0a, 0x0a, 0x46, 0x69, 0x6c, 0x65, 0x46, 0x6f,
	0x72, 0x6d, 0x61, 0x74, 0x12, 0x17, 0x0a, 0x13, 0x46, 0x49, 0x4c, 0x45, 0x5f, 0x46, 0x4f, 0x52,
	0x4d, 0x41, 0x54, 0x5f, 0x55, 0x4e, 0x4b, 0x4e, 0x4f, 0x57, 0x4e, 0x10, 0x00, 0x12, 0x17, 0x0a,
	0x13, 0x54, 0x45, 0x4e, 0x53, 0x4f, 0x52, 0x46, 0x4c, 0x4f, 0x57, 0x5f, 0x47, 0x52, 0x41, 0x50,
	0x48, 0x44, 0x45, 0x46, 0x10, 0x01, 0x12, 0x0a, 0x0a, 0x06, 0x54, 0x46, 0x4c, 0x49, 0x54, 0x45,
	0x10, 0x02, 0x12, 0x10, 0x0a, 0x0c, 0x47, 0x52, 0x41, 0x50, 0x48, 0x56, 0x49, 0x5a, 0x5f, 0x44,
	0x4f, 0x54, 0x10, 0x03, 0x42, 0x81, 0x01, 0x0a, 0x08, 0x63, 0x6f, 0x6d, 0x2e, 0x74, 0x6f, 0x63,
	0x6f, 0x42, 0x0e, 0x54, 0x6f, 0x63, 0x6f, 0x46, 0x6c, 0x61, 0x67, 0x73, 0x50, 0x72, 0x6f, 0x74,
	0x6f, 0x48, 0x02, 0x50, 0x01, 0x5a, 0x33, 0x67, 0x69, 0x74, 0x65, 0x65, 0x2e, 0x63, 0x6f, 0x6d,
	0x2f, 0x71, 0x63, 0x69, 0x69, 0x70, 0x2d, 0x69, 0x63, 0x70, 0x2f, 0x74, 0x66, 0x2d, 0x73, 0x65,
	0x72, 0x76, 0x69, 0x6e, 0x67, 0x2f, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x66, 0x6c, 0x6f, 0x77,
	0x2f, 0x6c, 0x69, 0x74, 0x65, 0x2f, 0x74, 0x6f, 0x63, 0x6f, 0xa2, 0x02, 0x03, 0x54, 0x58, 0x58,
	0xaa, 0x02, 0x04, 0x54, 0x6f, 0x63, 0x6f, 0xca, 0x02, 0x04, 0x54, 0x6f, 0x63, 0x6f, 0xe2, 0x02,
	0x10, 0x54, 0x6f, 0x63, 0x6f, 0x5c, 0x47, 0x50, 0x42, 0x4d, 0x65, 0x74, 0x61, 0x64, 0x61, 0x74,
	0x61, 0xea, 0x02, 0x04, 0x54, 0x6f, 0x63, 0x6f,
}

var (
	file_tensorflow_lite_toco_toco_flags_proto_rawDescOnce sync.Once
	file_tensorflow_lite_toco_toco_flags_proto_rawDescData = file_tensorflow_lite_toco_toco_flags_proto_rawDesc
)

func file_tensorflow_lite_toco_toco_flags_proto_rawDescGZIP() []byte {
	file_tensorflow_lite_toco_toco_flags_proto_rawDescOnce.Do(func() {
		file_tensorflow_lite_toco_toco_flags_proto_rawDescData = protoimpl.X.CompressGZIP(file_tensorflow_lite_toco_toco_flags_proto_rawDescData)
	})
	return file_tensorflow_lite_toco_toco_flags_proto_rawDescData
}

var file_tensorflow_lite_toco_toco_flags_proto_enumTypes = make([]protoimpl.EnumInfo, 1)
var file_tensorflow_lite_toco_toco_flags_proto_msgTypes = make([]protoimpl.MessageInfo, 1)
var file_tensorflow_lite_toco_toco_flags_proto_goTypes = []interface{}{
	(FileFormat)(0),   // 0: toco.FileFormat
	(*TocoFlags)(nil), // 1: toco.TocoFlags
	(IODataType)(0),   // 2: toco.IODataType
}
var file_tensorflow_lite_toco_toco_flags_proto_depIdxs = []int32{
	0, // 0: toco.TocoFlags.input_format:type_name -> toco.FileFormat
	0, // 1: toco.TocoFlags.output_format:type_name -> toco.FileFormat
	2, // 2: toco.TocoFlags.inference_input_type:type_name -> toco.IODataType
	2, // 3: toco.TocoFlags.inference_type:type_name -> toco.IODataType
	2, // 4: toco.TocoFlags.accumulation_type:type_name -> toco.IODataType
	5, // [5:5] is the sub-list for method output_type
	5, // [5:5] is the sub-list for method input_type
	5, // [5:5] is the sub-list for extension type_name
	5, // [5:5] is the sub-list for extension extendee
	0, // [0:5] is the sub-list for field type_name
}

func init() { file_tensorflow_lite_toco_toco_flags_proto_init() }
func file_tensorflow_lite_toco_toco_flags_proto_init() {
	if File_tensorflow_lite_toco_toco_flags_proto != nil {
		return
	}
	file_tensorflow_lite_toco_types_proto_init()
	if !protoimpl.UnsafeEnabled {
		file_tensorflow_lite_toco_toco_flags_proto_msgTypes[0].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*TocoFlags); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: file_tensorflow_lite_toco_toco_flags_proto_rawDesc,
			NumEnums:      1,
			NumMessages:   1,
			NumExtensions: 0,
			NumServices:   0,
		},
		GoTypes:           file_tensorflow_lite_toco_toco_flags_proto_goTypes,
		DependencyIndexes: file_tensorflow_lite_toco_toco_flags_proto_depIdxs,
		EnumInfos:         file_tensorflow_lite_toco_toco_flags_proto_enumTypes,
		MessageInfos:      file_tensorflow_lite_toco_toco_flags_proto_msgTypes,
	}.Build()
	File_tensorflow_lite_toco_toco_flags_proto = out.File
	file_tensorflow_lite_toco_toco_flags_proto_rawDesc = nil
	file_tensorflow_lite_toco_toco_flags_proto_goTypes = nil
	file_tensorflow_lite_toco_toco_flags_proto_depIdxs = nil
}
